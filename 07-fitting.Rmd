# Fitting

```{r, echo=FALSE}
knitr::opts_chunk$set(warning = FALSE, message=FALSE)
```

The `a4a` stock assessment framework is implemented in `R` through the method `sca()`. The method call requires as a minimum a `FLStock` object and a `FLIndices` or `FLindex` object, in which case the default submodels will be set by the method.

Having described building blocks, basic formulations and effects available to build a submodel's model, it's important to look into specific formulations and relate them to commonly known representations. Note that although a large number of formulations are available for each submodel, the user must carefully decide on the full stock assessment model being build and avoid over-parameterize. Over-parametrization may lead to non-convergence, but may also end up not being very useful for prediction/forecasting, which is one of the main objectives of stock assessment.

```{r}
library(FLa4a)
data(ple4)
data(ple4.indices)
data(ple4.index)
fmod <- ~ s(age, k=8) + s(year, k=30) + te(age, year, k = c(5, 15))
fit <- sca(ple4, ple4.indices, fmodel=fmod)
stk <- ple4 + fit
```

```{r, plt01, fig.cap="Stock summary", echo=FALSE}
plot(stk)
```

Submodels that are not explicitly defined will be set by default using the relevant call to `defaultFmod()`, `defaultQmod`, `defaultSRmod()`, `defaultN1mod` or `defaultVmod()`. These methods will use the length of the time series and number of age groups to define the models. The `show` method for `a4aFit` objects display the models used for the fit.

```{r, echo=FALSE}
fit
```

To set specific submodels the user has to write the relevant `R` formula and include it in the call. The arguments for each submodel are self-explanatory: fishing mortality is `fmodel`, indices' catchability is `qmodel`, stock-recruitment is `srmodel`, observation variance is `vmodel` and for initial year's abundance is `n1model`. The following model comes closer to the official stock assessment of North Sea plaice, as such we'll name it `fit0` and keep it for future comparisons.

```{r, fit0}
fmod0 <- ~s(age, k=6)+s(year, k=10)+te(age, year, k=c(3,8))
qmod0 <- list(~s(age, k = 4),
       ~s(age, k = 3),
       ~s(age, k = 3) + year,
       ~s(age, k = 3),
       ~s(age, k = 4),
       ~s(age, k = 6))
srmod0 <- ~ s(year, k=20)
vmod0 <- list(~s(age, k=4), ~1,  ~1, ~1, ~1, ~1, ~1, ~1)
n1mod0 <- ~ s(age, k=3)
fit0 <- sca(ple4, ple4.indices,
       fmodel=fmod0,
       qmodel=qmod0,
       srmodel=srmod0,
       n1model=n1mod0,
       vmodel=vmod0)
stk0 <- ple4 + fit0
```

```{r, plt02, fig.cap="Stock summary - close to official assessment", echo=FALSE}
plot(stk0)
```

As before by calling the fitted object, the submodels' formulas are printed in the console:

```{r, echo=FALSE}
fit0
```

There are a set of methods for `a4a` fit objects which help manipulating `sca()` results, namely `+`, that updates the stock object with the fitted fishing mortalities, population abundance and catch in numbers at age. This method can be applied to `FLStocks` and `a4aFits` objects as well.

The following subsections describe common formulations used to define submodels. Although the formulas are tailored to specific submodels — *e.g.*, a separable model for $F$ — they can, in principle, be applied to any submodel. The `sca` method is agnostic to the model setup and will attempt to fit the model regardless of its specification. However, from a statistical standpoint, convergence may fail if the model is not well specified. From a fisheries modeling perspective, limitations arise in how the model is interpreted. For example, if a scientific survey is modeled with a year effect, the user is implicitly assuming that the survey’s selectivity has changed over time. Consequently, the model may attribute part of the observed trend in the survey data to changes in selectivity rather than to changes in abundance.

## Fishing mortality submodel ($F_{ay}$)

### Separable model

One of the most useful models for fishing mortality is one in which 'age' and 'year' effects are independent, that is, where the shape of the selection pattern does not change over time, but the overall level of fishing mortality do. Commonly called a 'separable model'.

A full separable model in `a4a` is written using the `factor` function which converts age and year effects into categorical values, forcing a different coefficient to be estimated for each level of both effects. This model has $age \times year$ number of parameters.

```{r}
fmod1 <- ~ factor(age) + factor(year)
fit1 <- sca(ple4, ple4.indices, fmodel=fmod1, fit="MP")
```

One can reduce the number of parameters and add dependency along both effects, although still keeping independence of each other, by using smoothers rather than `factor`. We're using the North Sea Plaice data, and since it has 10 ages we will use a simple rule of thumb that the spline should have fewer than $\frac{10}{2} = 5$ degrees of freedom, and so we opt for 4 degrees of freedom. We will also do the same for year and model the change in $F$ through time as a smoother with 20 degrees of freedom.

```{r}
fmod2 <- ~ s(age, k=4) + s(year, k=20)
fit2 <- sca(ple4, ple4.indices, fmodel=fmod2, fit="MP")
```

An interesting extension of the separable model is the 'double separable' where a third factor or smoother is added for the cohort effect.

```{r, warning=FALSE}
fmod3 <- ~ s(age, k=4) + s(year, k=20) + s(as.numeric(year-age), k=10)
fit3 <- sca(ple4, ple4.indices, fmodel=fmod3, fit="MP")
```

Figures \@ref(fig:sep00) and \@ref(fig:sep01) depicts the three models selectivities for each year. Each separable model has a single selectivity that changes it's overall scale in each year, while the double separable introduces some variability over time by modeling the cohort factor.

```{r, sep00, fig.cap="Selection pattern of separable models. Each line represents the selection pattern in a specific year. Independent age and year effects (factor), internally dependent age and year (smooth), double separable (double).", echo=FALSE}
flqs <- FLQuants(factor=harvest(fit1), smooth=harvest(fit2), double=harvest(fit3))
pset <- list(strip.background=list(col="gray90"))
xyplot(data~age|qname, groups=year, data=flqs, type="l", col=1, layout=c(3,1), ylab="fishing mortality", par.settings=pset)
```

```{r, sep01, fig.cap="Fishing mortality of separable models. Independent age and year effects (factor), internally dependent age and year (smooth), double separable (double).", echo=FALSE}
wireframe(data~age+year|qname, data=as.data.frame(flqs), layout=c(3,1))
```

### Model with age-year interaction

A non-separable model, where we consider age and year to interact can be modeled by a smooth interaction term with a tensor product of cubic splines, the `te` method (Figure \@ref(fig:te1)), again borrowed from `mgcv` (@R-mgcv).

```{r}
fmod <- ~ te(age, year, k = c(4,20))
fit <- sca(ple4, ple4.indices, fmodel=fmod)
```

```{r, te1, fig.cap="Fishing mortality smoothed non-separable model", echo=FALSE}
wireframe(harvest(fit), zlab="F")
```

In this example fishing mortalities are linked across age and time. What if we want to free up a specific age class because in the residuals we see a consistent pattern. This can happen, for example, if the spatial distribution of juveniles is disconnected to the distribution of adults.  The fishery focuses on the adult fish, and therefore the $F$ on young fish is a function of the distribution of the juveniles and could deserve a specific model. This can be achieved by adding a component for the year effect on age 1 (Figure \@ref(fig:age1)). We'll use `s`'s argument `by` to define the ages that the model will apply to. The `as.numeric` method over `age==1`, will result in a matrix that will be $1$ for ages 1 and $0$ for the other ages, effectively removing those ages from the `s` model. Furthermore, by not removing age 1 from the `te` component we're in effect adding the two estimates for age 1.

```{r}
fmod <- ~ te(age, year, k = c(4,20)) + s(year, k = 5, by = as.numeric(age==1))
fit2 <- sca(ple4, ple4.indices, fmodel=fmod)
```

```{r, age1, fig.cap="Fishing mortality age-year interaction model with extra age 1 smoother.", echo=FALSE}
wireframe(harvest(fit2), zlab="F")
```

### Constant selectivity for contiguous ages or years

To set these models we'll use the method `replace()` to define which ages or years will be modelled together. The following example shows `replace()` in operation. The dependent variables used in the model will be changed and attributed the same age or year, as such during the fit observations of those ages or years with will be seen as replicates. One can think of it as sharing the same mean value, which will be estimated by the model.

```{r}
age <- 1:10
# last age same as previous
replace(age, age>9, 9)
# all ages after age 6
replace(age, age>6, 6)
year <- 1950:2010
replace(year, year>2005, 2005)
```

In the $F$ submodel one can use this method to fix the estimation of $F$ in the plus group to be the same as in the last non-aggregated age.

```{r}
fmod <- ~ s(replace(age, age>9, 9), k=4) + s(year, k=20)
fit <- sca(ple4, ple4.indices, fmod)
```

```{r, ctsselage, fig.cap="F-at-age fixed above age 9", echo=FALSE}
wireframe(harvest(fit), zlab="F")
```

Or estimate the average $F$ in the most recent years, instead of averaging after the assessment to compute the _statu quo_ selection pattern.

```{r}
fmod <- ~ s(age, k=4) + s(replace(year, year>2013, 2013), k=20)
fit <- sca(ple4, ple4.indices, fmod)
```

```{r, ctsselyear, fig.cap="F-at-age fixed for the most recent 5 years", echo=FALSE}
wireframe(data~age+year, data=harvest(fit), screen=c(z=-130, y=0, x=-60), zlab="F")
```

### Time blocks selectivity

To define blocks of data `sca()` uses the method `breakpts()`, which creates a factor from a vector with levels defined by the second argument.

```{r}
year <- 1950:2010
# two levels separated in 2000
breakpts(year, 2000)
# five periods with equal interval
breakpts(year, seq(1949, 2010, length=6))
```

Note `seq()` computes 'left-open' intervals, which means that to include 1950 the sequence must start one year earlier.

These methods can be used to create discrete time series, for which a different selection pattern is allowed in each block. This is called an interaction in statistical modelling parlance, and typically a `*` denotes an interaction term, for smoothers an interaction is achieved using the `by` argument. When this argument is a `factor` a replicate of the smooth is produced for each factor level.

In the next case we'll use the `breakpts()` to split the time series at 1990, although keeping the same shape in both periods, a thin plate spline with 3 knots (Figure \@ref(fig:brk)).

```{r}
fmod <- ~s(age, k = 3, by = breakpts(year, 1990))
fit <- sca(ple4, ple4.indices, fmod)
```

```{r, brk, echo=FALSE, fig.cap="F-at-age in two periods using in both cases a thin plate spline with 3 knots", echo=FALSE}
wireframe(harvest(fit), zlab="F")
```

### Time changing selectivity

In many cases, it may be desirable to allow the selection pattern to evolve over time, from year to year. Again there are several ways to do this, one way is to estimate a mean selection pattern, while also allowing $F$ to vary over time for each age. This is like a separable smoother over year, with 'age blocks' so, looking back at previous examples, we have:

```{r}
fmodel <- ~ s(year, k = 15, by = factor(age)) + s(age, k = 4)
```

This is a type of interaction between age and year, but the only connection (or correlation) across ages is via the smoother on age, however there are still 15 degrees of freedom for each age, so the model 10 x 15 + 4 = 154 degrees of freedom.

To include correlation across ages and years together the tensor product (`te()`) is used, this has the effect of restricting the flexibility of the model for $F$. In the following, there is a smoother in 2 dimensions (age and year) where there is 5 degrees of freedom in the age direction, and 15 in the year dimension, resulting in a total of 5 x 15 = 65 degrees of freedom

```{r}
fmodel <- ~ te(age, year, k = c(5, 15))
```

Often the above formulations provide too much flexibility, and a more complicated specification, but simpler model is preferable:

```{r}
fmodel <- ~ s(age, k = 4) + s(year, k = 15) + te(age, year, k = c(3, 5))
```

in the above model, the main effects for age and year still have similar flexibility to the full tensor model, however, the interaction (or the change in F at age over time) has been restricted, so that the full model now has 4 + 15 + 3 x 5 = 34 degrees of freedom.

### Closed form selection pattern

One can use a closed form for the selection pattern. The only requirement is to be able to write it as a `R` formula, the example below uses a logistic form.

```{r}
fmod <- ~ I(1/(1+exp(-age)))
fit <- sca(ple4, ple4.indices, fmod)
```

```{r, logistic, fig.cap="F-at-age logistic", echo=FALSE}
wireframe(harvest(fit), zlab="F")
```

## Abundance indices catchability submodel ($Q_{ays}$)

The catchability submodel is set up the same way as the $F$ submodel. The only difference is that the submodel is set up as a list of formulas, where each formula relates with one abundance index. There's no limitation in the number of indices or type that can be used for a fit. It's the analyst that has to decide based on her/his expertise and knowledge of the stock and fleet dynamics.

In the following examples we'll use a single index instead of all available indices for plaice in ICES area 4, to simplify the code and examples.

### Catchability submodel for age based indices

The first model shown is simply a dummy effect on age, which means that one coefficient will be estimated for each age. Note this kind of model considers each level of the factor to be independent from the others levels (Figure \@ref(fig:dummyage)).

```{r}
qmod <- list(~factor(age))
fit <- sca(ple4, ple4.index, qmodel=qmod)
```

```{r, dummyage, fig.cap="Catchability age independent model", echo=FALSE}
qhat <- predict(fit)$qmodel[[1]]
wireframe(qhat, zlab="q")
```

If one considers catchability at a specific age to be dependent on catchability on the other ages, similar to a selectivity modelling approach, one option is to use a smoother at age, and let the data 'speak' regarding the shape (Figure \@ref(fig:smoothage)).

```{r}
qmod <- list(~ s(age, k=4))
fit <- sca(ple4, ple4.indices[1], qmodel=qmod)
```

```{r, smoothage, fig.cap="Catchability smoother age model", echo=FALSE}
qhat <- predict(fit)$qmodel[[1]]
wireframe(qhat, zlab="q")
```

Finally, one may want to investigate a trend in catchability with time, very common in indices built from CPUE data. In the example given here we'll use a linear trend in time, set up by a simple linear model (Figure \@ref(fig:qtrend)).

```{r}
qmod <- list( ~ s(age, k=4) + year)
fit <- sca(ple4, ple4.indices[1], qmodel=qmod)
```

```{r, qtrend, fig.cap="Catchability with a linear trend in year", echo=FALSE}
qhat <- predict(fit)$qmodel[[1]]
wireframe(qhat, zlab="q")
```

### Catchability submodel for age aggregated biomass indices

The previous section focused on age-disaggregated indices, which are most often reported as standardized number of individuals, *e.g.* number of individuals caught per hour. Age-aggregated indices (such as CPUE, biomass, DEPM, etc.) may also be used to tune the population's biomass in terms of weight. These indices are linked either to the total biomass or to the weight of a specific group of age classes, defined by the age range set in the object.

In such cases, a different index class must be used: FLIndexBiomass. This class uses a vector named index with an age dimension labeled as 'all'. The qmodel should be specified without age-specific factors, although it may still include a 'year' component and relevant covariates, if needed.

```{r}
# simulating a biomass index (note the name of the first dimension element) using
# the ple4 biomass and an arbritary catchability of 0.001 plus a lognormal error.
dnms <- list(age="all", year=range(ple4)["minyear"]:range(ple4)["maxyear"])
bioidx <- FLIndexBiomass(FLQuant(NA, dimnames=dnms))
index(bioidx) <- stock(ple4)*0.001
index(bioidx) <- index(bioidx)*exp(rnorm(index(bioidx), sd=0.1))
range(bioidx)[c("startf","endf")] <- c(0,0)
# note the name of the first dimension element
index(bioidx)
# fitting the model
fit <- sca(ple4, FLIndices(bioidx), qmodel=list(~1))
```

To estimate a constant selectivity over time one used the model $\sim 1$, resulting in the following estimate:

```{r}
predict(fit)$qmodel[[1]][1,drop=TRUE]
```

The next code shows an example where the biomass index refers to age groups 2 to 4, *e.g.* the CPUE of a fleet that targets these particular ages.

```{r}
# creating the index
dnms <- list(age="all", year=range(ple4)["minyear"]:range(ple4)["maxyear"])
bioidx <- FLIndexBiomass(FLQuant(NA, dimnames=dnms))
# but now use only ages 2:4
index(bioidx) <- tsb(ple4[ac(2:4)])*0.001
index(bioidx) <- index(bioidx)*exp(rnorm(index(bioidx), sd=0.1))
range(bioidx)[c("startf","endf")] <- c(0,0)
# to pass this information to the model one needs to specify an age range
range(bioidx)[c("min","max")] <- c(2,4)
# fitting the model
fit <- sca(ple4, FLIndices(bioidx), qmodel=list(~1))
```

Once more the estimate value is not very far from the simulated one, 0.001.

```{r}
predict(fit)$qmodel[[1]][1,drop=TRUE]
```

### Catchability submodel for single age indices

Similar to age aggregated indices one may have an index that relates only to one age, like a recruitment index. In this case the `FLIndex` object must have in the first dimension the age it refers to. The fit uses the index to tune the population abundance for the specific age. As for biomass indices, the qmodel should be set without age factors, although it can have a 'year' component and covariates if needed.

```{r}
idx <- ple4.index[1]
fit <- sca(ple4, FLIndices(recidx=idx), qmodel=list(~1))
# the estimated catchability is
predict(fit)$qmodel[[1]][1,drop=TRUE]
```

## Stock-recruitment submodel ($R_y$)

The S/R submodel is a special case, in the sense that it can be set up with the same linear tools as the $F$ and $Q$ models, but it can also use some hard coded models. The example shows how to set up a simple dummy model with `factor()`, a smooth model with `s()`, a Ricker model (`ricker()`), a Beverton and Holt model (`bevholt()`), a hockey stick model (`hockey()`), and a geometric mean model (`geomean()`). See Figure \@ref(fig:srmod) for results. As mentioned before, the 'structural' models have a fixed variance, which must be set by defining the coefficient of variation.

```{r}
srmod <- ~ factor(year)
fit <- sca(ple4, ple4.indices, srmodel=srmod)
srmod <- ~ s(year, k=15)
fit1 <- sca(ple4, ple4.indices, srmodel=srmod)
srmod <- ~ ricker(CV=0.1)
fit2 <- sca(ple4, ple4.indices, srmodel=srmod)
srmod <- ~ bevholt(CV=0.1)
fit3 <- sca(ple4, ple4.indices, srmodel=srmod)
srmod <- ~ hockey(CV=0.1)
fit4 <- sca(ple4, ple4.indices, srmodel=srmod)
srmod <- ~ geomean(CV=0.1)
fit5 <- sca(ple4, ple4.indices, srmodel=srmod)
```

```{r, srmod, fig.cap="Recruitment estimates since 1960 by each stock-recruitment model.", echo=FALSE}
flqs <- FLQuants(factor=stock.n(fit)[1], smother=stock.n(fit1)[1], ricker=stock.n(fit2)[1], bevholt=stock.n(fit3)[1], hockey=stock.n(fit4)[1], geomean=stock.n(fit5)[1])
flqs <- lapply(flqs, "[", j=ac(1960:2017))
xyplot(data~year, groups=qname, data=flqs, type="l", auto.key=list(points=FALSE, lines=TRUE, columns=3), ylab="No. recruits")
```

## Observation variance submodel ($\{\sigma^2_{ay}, \tau^2_{ays}\}$)

The variance model allows the user to set up the shape of the observation variances $\sigma^2_{ay}$ and $\tau^2_{ays}$. This is an important subject for fisheries data used as input to stock assessment models.

The defaults assume a U-shape like model for catch-at-age and constant variance for abundance indices. The first relies on the fact that it's common to have more precision on the most represented ages and less precision on the less frequent ages which tend to  be the younger and older individuals. These sizes are less caught by the fleets and as such do not appear as often at the auction markets samples. With regards to the abundance indices, one assumes a scientific survey to have a well designed sampling scheme and protocols which keep observation error at similar levels across ages.

```{r}
# reference model with constant variance for the survey index
vmod <- list(~s(age, k=3), ~1)
fit1 <- sca(ple4, ple4.index, vmodel=vmod)
# to compare - survey index variance modelled has a U-shape smoother
vmod <- list(~s(age, k=3), ~s(age, k=3))
fit2 <- sca(ple4, ple4.index, vmodel=vmod)
```

Variance estimated for the survey is constant at `r round(predict(fit)$vmodel[[2]][1,drop=TRUE],3)` while for catches using the U-shape model, fitted with a smoother, changes with ages (Figure \@ref(fig:vmod)).

```{r, vmod, fig.cap="Abundance index observation variance estimate", echo=FALSE}
wireframe(predict(fit1)$vmodel[[1]], zlab="variance")
```

Observation variance options have an impact in the final estimates of population abundance, which can be seen in Figure \@ref(fig:vmodimpact).

```{r, vmodimpact, fig.cap="Population estimates using two different variance models for the survey", echo=FALSE}
flqs <- FLQuants(constant=stock.n(window(fit1, start=1990)), smoother=stock.n(window(fit2, start=1990)))
xyplot(data~year|factor(age), groups=qname, data=flqs, type="l",
       scales=list(y=list(relation="free", draw=FALSE)),
       auto.key=list(points=FALSE, lines=TRUE, columns=2),
       par.settings=list(superpose.line=list(col=c("red", "blue"), lwd=1.5),
       strip.background=list(col="gray90")), ylab="", layout=c(5,2))
```

## Initial year abundance submodel ($N_{a,y=1}$)

The submodel for the stock number at age in the first year of the time series is set with the usual tools. The model deals with the shape of the population abundance in a single year and as such the year effect shouldn't be included (Figure \@ref(fig:ny1)).

This model has its influence limited to the initial lower triangle of the population matrix, which in assessments with long time series doesn't make much difference. Nevertheless, when modelling stocks with short time series in relation to the number of ages present, it becomes more important and should be given proper attention.

```{r}
# model with smoother
n1mod <- ~s(age, k=4)
fit1 <- sca(ple4, ple4.indices, n1model=n1mod)
# model with factor
n1mod <- ~factor(age)
fit2 <- sca(ple4, ple4.indices, n1model=n1mod)
```

```{r, ny1, fig.cap="Nay=1 models", echo=FALSE}
flqs <- FLQuants(smother=stock.n(fit1)[,1], factor=stock.n(fit2)[,1])
pset <- list(superpose.line=list(col=c("red", "blue")))
lgnd <- list(points=FALSE, lines=TRUE, space='right')
xyplot(data~age, groups=qname, data=flqs, type="l", auto.key=lgnd, par.settings=pset, ylab="")
```

The impact in the overall perspective of the stock status is depicted in Figure \@ref(fig:n1modimpact). Most of the changes happen in the beginning of the time series, although due to the impact on the estimates of other submodels' parameters it can have an impact over the full time series.

```{r, n1modimpact, fig.cap="Population estimates using two different variance models", echo=FALSE}
flqs <- FLQuants(smother=stock.n(fit1), factor=stock.n(fit2))
xyplot(data~year|factor(age), groups=qname, data=flqs, type="l",
       scales=list(y=list(relation="free", draw=FALSE)),
       auto.key=list(points=FALSE, lines=TRUE, columns=2),
       par.settings=list(superpose.line=list(col=c("red", "blue"), lwd=1.5),
       strip.background=list(col="gray90")), ylab="", layout=c(5,2))
```

## More models

More complicated models can be built with these tools. The limitation is going to be the potential overparametrization of the model and the failure to fit if the data isn't informative enough.

For example, Figure \@ref(fig:ageind) shows a model where the age effect is modelled as a smoother throughout years independent from each other, with the exception of ages 9 and 10 which share their parameters.

```{r}
fmod <- ~ factor(age) + s(year, k=10, by = breakpts(age, c(0:8)))
fit <- sca(ple4, ple4.indices, fmod)
```

```{r, ageind, fig.cap="F-at-age as thin plate spline with 3 knots for each age", echo=FALSE}
wireframe(harvest(fit), zlab="F")
```

A quite complex model that implements a cohort effect can be set through the following formula. Figure \@ref(fig:coh) shows the resulting fishing mortality. Note that in this case we end up with a variable $F$ pattern over time, but rather than using 4 * 10 = 40 parameters, it uses, 4 + 10 + 10 = 24.

```{r}
fmodel <- ~ s(age, k = 4) + s(pmax(year - age, 1957), k = 10) + s(year, k = 10)
fit <- sca(ple4, ple4.indices, fmodel=fmodel)
```

```{r, coh, echo=FALSE, fig.cap="F-at-age with a cohort effect.", echo=FALSE}
wireframe(harvest(fit), zlab="F")
```

The following model is applied to the vmodel and it introduces an time trend to reflect the increase in precision in more recent years with improvements in sampling design and increase in sampling effort.

```{r}
vmod <- list(
       ~ s(age, k = 3) + year,
       ~1, ~1, ~1, ~1, ~1, ~1
       )
fit <- sca(ple4, ple4.indices, vmodel=vmod)
```

```{r, vm, echo=FALSE, fig.cap="Catch at age variance model with a year effect.", echo=FALSE}
wireframe(predict(fit)$vmodel[[1]], zlab="variance")
```

This model fits two smoothers to different sets of ages.

```{r}
fmod <- ~s(age, k = 3, by = breakpts(age, 5)) + s(year, k = 10)
fit <- sca(ple4, ple4.indices, fmodel = fmod)
```

```{r, danai01, echo=FALSE, fig.cap="Smoothers fitted to two sets of ages, 1 to 4 and 5 to 10.", echo=FALSE}
wireframe(harvest(fit), zlab="F")
```

## Data weigthing

By default the likelihood components are not weighted and the contribution of each to the maximum likelihood depends on their own likelihood score. However, the user may change these weights by penalizing data points, the $w_{ays}$ in section \@ref(sec:maths). The likelihood score of each data point will be multiplied by the inverted weights normalized to have a mean of 1. This is done by adding a variance matrix to the `catch.n` and `index.n` slots of the stock and index objects. One pragmatic way to look at this scores is to think of them as coefficients of variation, the smaller values will reflect higher weight in the fitting process, and since CVs are unitless one can compare across data points. Figures \@ref(fig:likwgt) and \@ref(fig:likwgtimpact) show the results of the two fits in the population abundance and stock summary.

```{r}
stk <- ple4
idx <- ple4.indices[1]
# cv of observed catches
varslt <- catch.n(stk)
varslt[] <- 0.4
catch.n(stk) <- FLQuantDistr(catch.n(stk), varslt)
# cv of observed indices
varslt <- index(idx[[1]])
varslt[] <- 0.2
index.var(idx[[1]]) <- varslt
# run
fit1 <- sca(stk, idx, fmodel=fmod0, qmodel=qmod0, srmodel=srmod0, vmodel=vmod0, n1model=n1mod0)
flqs <- FLQuants(nowgt=stock.n(fit0), extwgt=stock.n(fit1))
```

```{r, likwgt, fig.cap="Stock summary of distinct likelihood weightings", echo=FALSE}
#xyplot(data~year|factor(age), groups=qname, data=flqs, type="l", scales=scl, auto.key=lgnd, par.settings=pset, ylab="")
```

```{r, likwgtimpact, fig.cap="Population estimates using two different variance models", eho=FALSE}
flsts <- FLStocks(nowgt=ple4+fit0, wgt=ple4 + fit1)
plot(flsts)
```

Note that by using a smaller CV for the index, one is increasing the contribution of the survey and penalizing catch at age, in relative terms. The ratio between likelihood scores of both fits show this effect with catch at age increasing by 2.3 while the index increases almost 8 fold.

```{r, echo=FALSE}
fit0 <- sca(ple4, ple4.indices[1], fmodel=fmod0, qmodel=qmod0, srmodel=srmod0, vmodel=vmod0, n1model=n1mod0)
(fitSumm(fit1)/fitSumm(fit0))[c(2,8,9),]
```

## Working with covariates

In linear model one can use covariates to explain part of the variance observed on the data that the 'core' model does not explain. The same can be done in the `a4a` framework. The example below uses the North Atlantic Oscillation (NAO) index to model recruitment.

```{r}
nao <- read.table("https://www.cpc.ncep.noaa.gov/products/precip/CWlink/pna/norm.nao.monthly.b5001.current.ascii.table", skip=1, fill=TRUE, na.strings="-99.90")
dnms <- list(quant="nao", year=1950:2024, unit="unique", season=1:12, area="unique")
nao <- FLQuant(unlist(nao[,-1]), dimnames=dnms, units="nao")
nao <- seasonMeans(trim(nao, year=dimnames(stock.n(ple4))$year))
```

First by simply assuming that the NAO index drives recruitment (Figure \@ref(fig:naor)).

```{r}
srmod <- ~ s(nao, k=10)
fit2 <- sca(ple4, ple4.indices[1], qmodel=list(~s(age, k=4)), srmodel=srmod, covar=FLQuants(nao=nao))
```

```{r, naor, echo=FALSE, fig.cap="Recruitment model with covariates. Using the NAO index as a recruitment index.", echo=FALSE}
flqs <- FLQuants(simple=stock.n(fit)[1], covar=stock.n(fit2)[1])
xyplot(data~year, groups=qname, data=flqs, type="l",
       auto.key=list(points=FALSE, lines=TRUE, columns=2),
       par.settings=list(superpose.line=list(col=c("red", "blue"), lwd=1.5),
       strip.background=list(col="gray90")), ylab="")
```

In a second model we're using the NAO index not to model recruitment directly but to model one of the parameters of the S/R function (Figure \@ref(fig:naor2)).

```{r}
srmod <- ~ ricker(a=~nao, CV=0.25)
fit3 <- sca(ple4, ple4.indices[1], qmodel=list(~s(age, k=4)), srmodel=srmod, covar=FLQuants(nao=nao))
```

```{r, naor2, echo=FALSE, fig.cap="Recruitment model with covariates. Using the NAO index as a covariate for the stock-recruitment model parameters.", echo=FALSE}
flqs <- FLQuants(simple=stock.n(fit)[1], covar=stock.n(fit3)[1])
xyplot(data~year, groups=qname, data=flqs, type="l",
       auto.key=list(points=FALSE, lines=TRUE, columns=2),
       par.settings=list(superpose.line=list(col=c("red", "blue"), lwd=1.5),
       strip.background=list(col="gray90")), ylab="")
```

Note that covariates can be added to any submodel using the linear model capabilities of `R`.

## Assessing `ADMB` files

The framework gives access to all files produced to run the `ADMB` fitting routine through the argument `wkdir`. When set up, all the `ADMB` files will be left in the directory. Note that the `ADMB` tpl file is distributed with the `FLa4a`. One can get it from your `R` library, under the folder `[myRlib]/FLa4a/admb/`.

```{r, eval=FALSE}
fit1 <- sca(ple4, ple4.indices, wkdir="fit1run")
```

## Missing observations in the catch matrix or index

Missing observations are encoded as `NA`, and usually occur if there was no sampling for a year, or, since we model observations on the log scale, if the observation was zero. The `a4a` framework can deal with missing observations in the catches and indices.

The example below shows how to set up a model with missing observations in the catch matrix, to demonstrate the effect of missing observations, using the default model settings.

```{r missing obs}
fit <- sca(ple4, ple4.indices)
ple4_missing <- ple4
catch.n(ple4_missing)[ac(1:2), "2013"] <- NA
fit_missing <- sca(ple4_missing, ple4.indices)
```

In effect, the information on $F$ and $Q$ for the missing observations is inferred from the structural assumptions of the model. If a separable $F$ model is used, the value of $F$ at a given age is derived from its relationship with $F$ at other ages in the same year, as well as from the temporal relationship of $F$ across years for ages with available data. The same principle applies to any other submodel.

The impact of missing observations is illustrated in Figure \@ref(fig:obsmissing), which shows box plots of the predicted catch at age, incorporating estimation error. When observations are missing, the resulting estimates for those ages are both different and more uncertain. Additionally, the estimates for nearby years are affected, although the influence of the missing data diminishes with time—estimates from years further away converge toward those obtained using the full dataset.

```{r, obsmissing, echo = FALSE, fig.cap="Stock estimates with missing observations."}
pred <- ple4 + simulate(fit, 1000)
pred_missing <- ple4 + simulate(fit_missing, 1000)
flqs <- FLQuants(base = catch.n(pred)[ac(1:2), ac(2011:2015)], missing = catch.n(pred_missing)[ac(1:2), ac(2011:2015)])
bwplot(data ~ qname | factor(year) + factor(age), data = as.data.frame(flqs), scales = "free", auto.key = T, ylab = "Catch at age", layout=c(5,2), par.settings=list(box.rectangle = list(col = "black"), box.umbrella = list(col = "black"), plot.symbol = list(col = "black")))
```

This is a simple example, but the same principle applies to more complex models. However, if there are many missing observations, the model cannot be too flexible; otherwise, it won’t be able to reliably estimate the missing data.

In any case, one can always add more structure to the model to help address missing information. A common approach is to include a stock-recruitment relationship, which links the spawning stock biomass to recruitment. The example above would definitely benefit from this approach, as the missing information pertains to the first age group. See Figure \@ref(fit:obsmissing2), estimates are much more similar, although estimates from the fit to the missing data dataset show more uncertainty, as expected.

```{r}
# bevholt s/r CV was tweaked to give best results for the example
fit2 <- sca(ple4, ple4.indices, srmodel=~bevholt(CV=0.16))
fit_missing2 <- sca(ple4_missing, ple4.indices, srmodel=~bevholt(CV=0.16))
```

```{r, obsmissing2, echo = FALSE, fig.cap="Stock estimates with missing observations."}
pred <- ple4 + simulate(fit2, 1000)
pred_missing <- ple4 + simulate(fit_missing2, 1000)
flqs2 <- FLQuants(base = catch.n(pred)[ac(1:2), ac(2011:2015)], missing = catch.n(pred_missing)[ac(1:2), ac(2011:2015)])
bwplot(data ~ qname | factor(year) + factor(age), data = as.data.frame(flqs2), scales = "free", auto.key = T, ylab = "Catch at age", layout=c(5,2), par.settings=list(box.rectangle = list(col = "black"), box.umbrella = list(col = "black"), plot.symbol = list(col = "black")))
```

Another point to note, is that if observations are systematically missing, for example due to the actual observation being below a detection limit, or zero, then the model may overestimate the true catch at age. This is a common problem in stock assessment models, and is not unique to the `a4a` framework. Proposed solutions to this issue are to replace zeros with a small number, or half of the smallest observed value.
