# Fitting

The `a4a` stock assessment framework is implemented in `R` through the method `sca()`. The method call requires as a minimum a FLStock object and a FLIndices object, in which case the default submodels will be set by the method.

Having described building blocks, basic formulations and effects available to build a submodel's model, it's important to look into specific formulations and relate them to commonly known representations. Note that although a large number of formulations are available for each submodel, the user must carefuly decide on the full stock assessment model being build and avoid over-paramerizing. Over-parametrization may lead to non-convergence, but may also end up not being very useful for prediction/forecasting, which is one of the main objectives of stock assessment.

```{r}
data(ple4)
data(ple4.indices)
fit <- sca(ple4, ple4.indices)
stk <- ple4 + fit
plot(stk)
```

By calling the fitted object the default submodel formulas are printed in the console:

```{r}
fit
```

To set specific submodels the user has to write the relevant R formula and include it in the call. The arguments for each submodel are self-explanatory: fishing mortality is 'fmodel', indices' catchability is 'qmodel', stock-recruitment is 'srmodel', observation variance is 'vmodel' and for initial year's abundance is 'n1model'. The following model comes closer to the official stock assessment of North Sea plaice, as such we'll name it $0$ and keep it for future comparisons:


For future referencing we'll start with a base fit to be used for future comparisons, named fit 0.

```{r, fit0}
fmod0 <- ~s(age, k=6)+s(year, k=10)+te(age, year, k=c(3,8))
qmod0 <- list(~s(age, k = 4), ~s(age, k = 3), ~s(age, k = 3)+year, ~s(age, k = 3), ~s(age, k = 4), ~s(age, k = 6))
srmod0 <- ~ s(year, k=20)
vmod0 <- list(~s(age, k=4), ~1,  ~1, ~1, ~1, ~1, ~1, ~1)
n1mod0 <- ~ s(age, k=3)
fit0 <- sca(ple4, ple4.indices, fmodel=fmod0, qmodel=qmod0, srmodel=srmod0, n1model=n1mod0, vmodel=vmod0)
stk0 <- ple4 + fit0
plot(stk0)
```

As before by calling the fitted object submodels' formulas are printed in the console:

```{r}
fit
```

The method `sca` has other arguments which may be set by the user:

- [covar:] a `FLQuant} with covariates; 
- [wkdir:] a folder (character) where the \ADMB files will be saved for posterior inspection by the user;
- [verbose:] be more verbose (logical);
- [fit:] type of fit (character), 
  - 'MP' runs the minimizer without trying to invert the hessian and as such doesn't return the covariance matrix of the parameters, normally used inside \MSE loops where parameter variance may not be relevant; 
  - 'assessment' runs minimizer and inverts hessian, returns the covariance matrix of the estimated parameters and the convergence criteria set in \ADMB; 
  - 'MCMC' runs \ADMB's MCMC fit
- [center:] shall observations be centered before fitting (logical);
- [mcmc:] \ADMB's MCMC arguments (character vector), must be paired with `fit="MCMC"}. 

There are a set of methods for `a4a` fit objects which help manipulating `sca()` results, namely:

- [+:] update the stock object with the fitted fishing mortalities, population abundance and catch in numbers at age; 

## Fishing mortality submodel ($F_{ay}$)

```{r, echo=FALSE}
data(ple4)
data(ple4.indices)
```

We will now take a look at some examples for $F$ models and the forms that we can get.

A non-separable model, where we consider age and year to interact can be modeled using a smooth interaction term in the F model using a tensor product of cubic splines with the `te` method (Figure \@ref(fig:te1)), again borrowed from [mgcv](http://cran.r-project.org/web/packages/mgcv/index.html).

```{r}
fmod <- ~ te(age, year, k = c(4,20))
fit <- sca(ple4, ple4.indices[1], fmod)
```

```{r, te1, fig.cap="Fishing mortality smoothed non-separable model"}
wireframe(harvest(fit), zlab="F")
```

In the last examples the fishing mortalities (Fs') are linked across age and time.  What if we want to free up a specific age class because in the residuals we see a consistent pattern.  This can happen, for example, if the spatial distribution of juveniles is disconnected to the distribution of adults.  The fishery focuses on the adult fish, and therefore the the F on young fish is a function of the distribution of the juveniles and could deserve a specific model. This can be achieved by adding a component for the year effect on age 1 (Figure \@ref(fig:age1)).

```{r}
fmod <- ~ te(age, year, k = c(4,20)) + s(year, k = 5, by = as.numeric(age==1))
fit <- sca(ple4, ple4.indices[1], fmod)
```

```{r, age1, fig.cap="Fishing mortality age-year interaction model with extra age 1 smoother."} 
wireframe(harvest(fit), zlab="F")
```

### Separable model

One of the most useful models for fishing mortality is one in which 'age' and 'year' effects are independent, that is, where the shape of the selection pattern does not change over time, but the overall level of fishing mortality do. Commonly called a 'separable model'. 

A full separable model in `a4a` is written using the `factor` function which converts age and year effects into categorical values, forcing a different coefficient to be estimated for each level of both effects. This model has `age x year` number of parameters.

```{r}
fmod1 <- ~ factor(age) + factor(year)
fit1 <- sca(ple4, ple4.indices, fmodel=fmod1, fit="MP")
```

One can reduce the number of parameters and add dependency along both effects, although still keeping independence of each other, by using smoothers rather than `factor`. We'll use a (unpenalised) thin plate spline provided by package [mgcv](http://cran.r-project.org/web/packages/mgcv/) method `s()`. We're using the North Sea Plaice data, and since it has 10 ages we will use a simple rule of thumb that the spline should have fewer than $\frac{10}{2} = 5$ degrees of freedom, and so we opt for 4 degrees of freedom. We will also do the same for year and model the change in $F$ through time as a smoother with 20 degrees of freedom.

```{r}
fmod2 <- ~ s(age, k=4) + s(year, k=20)
fit2 <- sca(ple4, ple4.indices, fmodel=fmod2, fit="MP")
```

An interesting extension of the separable model is the 'double separable' where a third factor or smoother is added for the cohort effect.

```{r}
fmod3 <- ~ s(age, k=4) + s(year, k=20) + s(as.numeric(year-age), k=10)
fit3 <- sca(ple4, ple4.indices, fmodel=fmod3, fit="MP")
```

Figures \@ref(fig:sep00) and \@ref(fig:sep01) depicts the three models selectivities for each year. Each separable model has a single selectivity that changes it's overall scale in each year, while the double separable introduces some variability over time by modeling the cohort factor.

```{r, sep00, fig.cap="Selection pattern of separable models. Each line represents the selection pattern in a specific year. Independent age and year effects (factor), internally dependent age and year (smooth), double separable (double)."}
flqs <- FLQuants(factor=harvest(fit1), smooth=harvest(fit2), double=harvest(fit3))
pset <- list(strip.background=list(col="gray90"))
xyplot(data~age|qname, groups=year, data=flqs, type="l", col=1, layout=c(3,1), ylab="fishing mortality", par.settings=pset)
```

```{r, sep01, fig.cap="Fishing mortality of separable models. Independent age and year effects (factor), internally dependent age and year (smooth), double separable (double)."}
wireframe(data~age+year|qname, data=as.data.frame(flqs), layout=c(3,1))
```

### Constant selectivity for contiguous ages or years

To set these models we'll use the method `replace()` to define which ages or years will be modelled together with a single coefficient. The following example shows `replace()` in operation. The dependent variables used in the model will be changed and attributed the same age or year, as such during the fit observations of those age or year with will be seen as replicates. One can think of it as sharing the same mean value, which will be estimated by the model.

```{r}
age <- 1:10
# last age same as previous
replace(age, age>9, 9)
# all ages after age 6
replace(age, age>6, 6)

year <- 1950:2010
replace(year, year>2005, 2005)
```

In the $F$ submodel one can use this method to fix the estimation of $F$ in the plus group to be the same as in the last non-aggregated age.

```{r}
fmod <- ~ s(replace(age, age>9, 9), k=4) + s(year, k=20)
fit <- sca(ple4, ple4.indices, fmod)
```

```{r, ctsselage, fig.cap="F-at-age fixed above age 9"}
wireframe(harvest(fit), zlab="F")
```

Or estimate the average $F$ in the most recent years, instead of averaging after the assessment to compute the _statu quo_ selection pattern.

```{r}
fmod <- ~ s(age, k=4) + s(replace(year, year>2013, 2013), k=20)
fit <- sca(ple4, ple4.indices, fmod)
```

```{r, ctsselyear, fig.cap="F-at-age fixed for the most recent 5 years"}
wireframe(data~age+year, data=harvest(fit)[,ac(2010:2017)], screen=c(z=-130, y=0, x=-60), zlab="F")
```

### Time blocks selectivity

To define blocks of data `sca()` uses the method `breakpts()`, which creates a factor from a vector with levels defined by the second argument.

```{r}
year <- 1950:2010
# two levels separated in 2000
breakpts(year, 2000)
# five periods with equal interval
breakpts(year, seq(1949, 2010, length=6))
```

Note `seq()` computes 'left-open' intervals, which means that to include 1950 the sequence must start one year earlier. 

These methods can be used to create discrete time series, for which a different selection pattern is allowed in each block. This is called an interaction in statistical modelling parlance, and typically a `*` denotes an interaction term; for smoothers an interaction is achieved using the `by` argument. When this argument is a `factor` a replicate of the smooth is produced for each factor level. 

In the next case we'll use the `breakpts()` to split the time series at 1990, although keeping the same shape in both periods, a thin plate spline with 3 knots (Figure \@ref(fig:brk)).

```{r}
fmod <- ~s(age, k = 3, by = breakpts(year, 1990))
fit <- sca(ple4, ple4.indices, fmod)
```

```{r, brk, echo=FALSE, fig.cap="F-at-age in two periods using in both cases a thin plate spline with 3 knots"}
wireframe(harvest(fit), zlab="F")
```

### Time changing selectivity

In many cases, it may be desirable to allow the selection pattern to evolve over time, from year to year. Again there are several ways to do this, one way is to estimate a mean selection pattern, while also allowing F to vary over time for each age. This is like a seperate smoother over year, with 'age blocks' so, looking back at previous examples, we have:

```{r} 
fmodel <- ~ s(year, k = 15, by = factor(age)) + s(age, k = 4)
```

This is a type of interaction between age and year, but the only connection (or correlation) across ages is via the smoother on age, however there are still 15 degrees of freedom for each age, so the model 5 x 15 + 4 = 69 degrees of freedom.  To include correlation across ages and years together then the tensor product (`te()` function) is used, this has the effect of restricting the flexibility of the model for F.  In the following, there is a smoother in 2 dimensions (age and year) where there is 5 degrees of freedom in the age direction, and 15 in the year dimension, resulting in a total of 5 x 15 = 65 degrees of freedom

```{r}
fmodel <- ~ te(age, year, k = c(5, 15))
```

Often the above formulations provide too much flexibility, and a more complicated, but simpler model is preferable:

```{r}
fmodel <- ~ s(age, k = 4) + s(year, k = 15) + te(age, year, k = c(3, 5))
```

in the above model, the main effects for age and year still have similar flexibility to the full tensor model, however, the interaction (or the change in F at age over time) has been restricted, so that the full model now has 4 + 15 + 3 x 5 = 34 degrees of freedom.

### Trawl fleets}

### Nets and Liners fleets}

### Multigear fleets}

### Trawl surveys}

### Closed form selection pattern}

One can use a closed form for the selection pattern. The only requirement is to be able to write it as a \R formula, the example below uses a logistic form.

```{r}
fmod <- ~ I(1/(1+exp(-age)))
fit <- sca(ple4, ple4.indices, fmod)
```

```{r, logistic, fig.cap="F-at-age logistic"}
wireframe(harvest(fit), zlab="F")
```

### More models

More complicated models can be built with these tools. For example, Figure \@ref(fig:ageind) shows a model where the age effect is modelled as a smoother (the same thin plate spline) throughout years but independent from each other.

```{r}
fmod <- ~ factor(age) + s(year, k=10, by = breakpts(age, c(2:8)))
fit <- sca(ple4, ple4.indices, fmod)
```

```{r, ageind, fig.cap="F-at-age as thin plate spline with 3 knots for each age"}
wireframe(harvest(fit), zlab="F")
```

A quite complex model that implements a cohort effect can be set through the following formula. Figure \@ref(fig:coh) shows the resulting fishing mortality. Note that in this case we end up with a variable F pattern over time, but rather than using 4 * 10 = 40 parameters, it uses, 4 + 10 + 10 = 24.

```{r}
fmodel <- ~ s(age, k = 4) + s(pmax(year - age, 1957), k = 10) + s(year, k = 10)
fit <- sca(ple4, ple4.indices, fmodel=fmodel)
```

```{r, coh, echo=FALSE, fig.cap="F-at-age with a cohort effect."}
wireframe(harvest(fit), zlab="F")
```

## Abundance indices catchability submodel ($Q_{ays}$)

The catchability submodel is set up the same way as the $F$ submodel and the tools available are the same. The only difference is that the submodel is set up as a list of formulas, where each formula relates with one abundance index. There's no limitation in the number of indices or type that can be used for a fit. It's the analyst that has to decide based on her/his expertise and knowledge of the stock and fleet dynamics.

### Catchability submodel for age based indices

A first model is simply a dummy effect on age, which means that a coefficient will be estimated for each age. Note that this kind of model considers that levels of the factor are independent (Figure \@ref(fig:dummyage)).

```{r, dummyage, fig.cap="Catchability age independent model"}
qmod <- list(~factor(age))
fit <- sca(ple4, ple4.indices[1], qmodel=qmod)
qhat <- predict(fit)$qmodel[[1]]
wireframe(qhat, zlab="q")
```

If one considers catchability at a specific age to be dependent on catchability on the other ages, similar to a selectivity modelling approach, one option is to use a smoother at age, and let the data 'speak' regarding the shape (Figure \@ref(fig:smoothage)).

```{r, smoothage, fig.cap="Catchability smoother age model"}
qmod <- list(~ s(age, k=4))
fit <- sca(ple4, ple4.indices[1], qmodel=qmod)
qhat <- predict(fit)$qmodel[[1]]
wireframe(qhat, zlab="q")
```

Finally, one may want to investigate a trend in catchability with time, very common in indices built from CPUE data. In the example given here we'll use a linear trend in time, set up by a simple linear model (Figure \@ref(fig:qtrend)).

```{r, qtrend, fig.cap="Catchability with a linear trend in year"}
qmod <- list( ~ s(age, k=4) + year)
fit <- sca(ple4, ple4.indices[1], qmodel=qmod)
qhat <- predict(fit)$qmodel[[1]]
wireframe(qhat, zlab="q")
```

### Catchability submodel for age aggregated biomass indices}

The previous section was focused on age disaggregated indices, but age aggregated indices (CPUE, biomass, DEPM, etc) may also be used to tune the total biomass of the population. In these cases a different class for the index must be used, the `FLIndexBiomass`, which uses a vector `index` with the age dimension called 'all'. Note that in this case the qmodel should be set without age factors, although it can have a 'year' component and covariates if needed. An interesting feature with biomass indices is the age range they refer to can be specified.

```{r}
# simulating a biomass index (note the name of the first dimension element) using 
# the ple4 biomass and an arbritary catchability of 0.001 plus a lognormal error.
dnms <- list(age="all", year=range(ple4)["minyear"]:range(ple4)["maxyear"])
bioidx <- FLIndexBiomass(FLQuant(NA, dimnames=dnms))
index(bioidx) <- stock(ple4)*0.001
index(bioidx) <- index(bioidx)*exp(rnorm(index(bioidx), sd=0.1))
range(bioidx)[c("startf","endf")] <- c(0,0)
# note the name of the first dimension element
index(bioidx)
# fitting the model
fit <- sca(ple4, FLIndices(bioidx), qmodel=list(~1))
```

To estimate a constant selectivity over time one used the model $\sim 1$. As a matter of fact the estimate value, `r round(predict(fit)$qmodel[[1]][1,drop=TRUE],5)`, is not very far from the simulated one, 0.001.

An example where the biomass index refers only to age 2 to 4 (for example a CPUE that targets these particular ages).

```{r}
# creating the index
dnms <- list(age="all", year=range(ple4)["minyear"]:range(ple4)["maxyear"])
bioidx <- FLIndexBiomass(FLQuant(NA, dimnames=dnms))
# but now use only ages 2:4
index(bioidx) <- tsb(ple4[ac(2:4)])*0.001
index(bioidx) <- index(bioidx)*exp(rnorm(index(bioidx), sd=0.1))
range(bioidx)[c("startf","endf")] <- c(0,0)
# to pass this information to the model one needs to specify an age range
range(bioidx)[c("min","max")] <- c(2,4)
# fitting the model
fit <- sca(ple4, FLIndices(bioidx), qmodel=list(~1))
```

Once more the estimate value, `r round(predict(fit)$qmodel[[1]][1,drop=TRUE],5)`, is not very far from the simulated one, 0.001.

### Catchability submodel for single age indices

Similar to age aggregated indices one may have an index that relates only to one age, like a recruitment index. In this case the `FLIndex} object must have in the first dimension the age it referes to. The fit is then done relating the index with the proper age in numbers. Note that in this case the qmodel should be set without age factors, although it can have a 'year' component and covariates if needed.

```{r}
idx <- ple4.indices[[1]][1]
fit <- sca(ple4, FLIndices(recidx=idx), qmodel=list(~1))
# the estimated catchability is
predict(fit)$qmodel[[1]]
```

## Stock-recruitment submodel ($R_y$)}

The S/R submodel is a special case, in the sense that it can be set up with the same linear tools as the $F$ and $Q$ models, but it can also use some hard coded models. The example shows how to set up a simple dummy model with `factor()`, a smooth model with `s()`, a Ricker model (`ricker()`), a Beverton and Holt model (`bevholt()`), a hockey stick model (`hockey()`), and a geometric mean model (`geomean()`). See Figure \@ref(fig:srmod) for results. As mentioned before, the 'structural' models have a fixed variance, which must be set by defining the coefficient of variation.

```{r}
srmod <- ~ factor(year)
fit <- sca(ple4, ple4.indices, srmodel=srmod)
srmod <- ~ s(year, k=10)
fit1 <- sca(ple4, ple4.indices, srmodel=srmod)
srmod <- ~ ricker(CV=0.05)
fit2 <- sca(ple4, ple4.indices, srmodel=srmod)
srmod <- ~ bevholt(CV=0.05)
fit3 <- sca(ple4, ple4.indices, srmodel=srmod)
srmod <- ~ hockey(CV=0.05)
fit4 <- sca(ple4, ple4.indices, srmodel=srmod)
srmod <- ~ geomean(CV=0.05)
fit5 <- sca(ple4, ple4.indices, srmodel=srmod)
```

```{r, srmod, fig.cap="Stock-recruitment models fits"}
flqs <- FLQuants(factor=stock.n(fit)[1], smother=stock.n(fit1)[1], ricker=stock.n(fit2)[1], bevholt=stock.n(fit3)[1], hockey=stock.n(fit4)[1], geomean=stock.n(fit5)[1])
xyplot(data~year, groups=qname, data=flqs, type="l", auto.key=list(points=FALSE, lines=TRUE, columns=3), ylab="No. recruits")
```

## Observation variance submodel ($\{\sigma^2_{ay}, \tau^2_{ays}\}$)

The variance model allows the user to set up the shape of the observation variances $\sigma^2_{ay}$ and $\tau^2_{ays}$. This is an important subject related with fisheries data used for input to stock assessment models. 

The defaults assume a U-shape model for catch-at-age and constant variance for abundance indices. The first relies on the fact that it's common to have more precision on the most represented ages and less precision on the less frequent ages which tend to  be the younger and older individuals. These sizes are less caught by the fleets and as such do not appear as often at the auction markets samples. With regards to the abundance indices, one assumes a scientific survey to have a well designed sampling scheme and protocols which keep observation error at similar levels across ages.

```{r}
vmod <- list(~s(age, k=3), ~1)
fit1 <- sca(ple4, ple4.indices[1], vmodel=vmod)
vmod <- list(~s(age, k=3), ~s(age, k=3))
fit2 <- sca(ple4, ple4.indices[1], vmodel=vmod)
```

Variance estimated for the constant model is `r round(predict(fit)$vmodel[[2]][1,drop=TRUE],3)` while for the U-shape model, fitted with a smoother, changes with ages (Figure \@ref(fig:vmod)).

```{r, vmod, fig.cap="Abundance index observation variance estimate"}
wireframe(predict(fit2)$vmodel[[2]], zlab="variance")
```

Observation variance options have an impact in the final estimates of population abundance, which can be seen in Figure \@ref(fig:vmodimpact). 

```{r, vmodimpact, fig.cap="Population estimates using two different variance models"}
flqs <- FLQuants(smother=stock.n(fit1), factor=stock.n(fit2))
xyplot(data~year|age, groups=qname, data=flqs, type="l",
       scales=list(y=list(relation="free", draw=FALSE)),
       auto.key=list(points=FALSE, lines=TRUE, columns=2),
       par.settings=list(superpose.line=list(col=c("gray35", "black")),
       strip.background=list(col="gray90")), ylab="")
```

## Initial year abundance submodel ($N_{a,y=1}$)}

The submodel for the stock number at age in the first year of the time series is set up with the usual modelling tools (Figure \@ref(fig:ny1)). Beare in mind that the year effect does not make sense here since it refers to a single year, the first in the time series of data available. This model has its influence limited to the initial lower triangle of the population matrix, which in assessments with long time series doesn't make much difference. Nevertheless, when modelling stocks with short time series in relation to the number of ages present, it becomes more important and should be given proper attention.

```{r}
n1mod <- ~s(age, k=3)
fit1 <- sca(ple4, ple4.indices, fmodel=fmod0, qmodel=qmod0, srmodel=srmod0, vmodel=vmod0, n1model=n1mod)
n1mod <- ~factor(age)
fit2 <- sca(ple4, ple4.indices, fmodel=fmod0, qmodel=qmod0, srmodel=srmod0, vmodel=vmod0, n1model=n1mod)
flqs <- FLQuants(smother=stock.n(fit1)[,1], factor=stock.n(fit2)[,1])
```

```{r, ny1, fig.cap="Nay=1 models"}
pset <- list(superpose.line=list(col=c("gray50", "black"), lty=c(1,2)))
xyplot(data~age, groups=qname, data=flqs, type="l", auto.key=lgnd, par.settings=pset, ylab="")
```

The impact in the overall perspective of the stock status is depicted in Figure \@ref(fig:n1modimpact). As time goes by the effect of this model vanishes and the fits become similar. 

```{r, n1modimpact, fig.cap="Population estimates using two different variance models"}
flqs <- FLQuants(smother=stock.n(fit1), factor=stock.n(fit2))
pset$strip.background <- list(col="gray90")
scl <- list(y=list(relation="free", draw=FALSE))
xyplot(data~year|factor(age), groups=qname, data=flqs, type="l", scales=scl, auto.key=lgnd, par.settings=pset, ylab="")
```

## Data weigthing

%====================================================================
% COLIN TO CHECK THE SECTION
%====================================================================

By default the likelihood components are not weighted and the contribution of each to the maximum likelihood depends on their own likelihood score. However, the user may change these weights by penalizing data points, the $w_{ays}$ in section \@ref(sec:maths). The likelihood score of each data point will be multiplied by the normalized weights ($\sum w_{ays} = 1$). This is done by adding a variance matrix to the `catch.n` and `index.n` slots of the stock and index objects. The values should be given as coefficients of variation on the log scale, so that variance is $\log{({CV}^2 + 1)}$. Figures \@ref(fig:likwgt) and \@ref(fig:likwgtimpact) show the results of the two fits in the population abundance and stock summary.

```{r}
stk <- ple4
idx <- ple4.indices[1]
# cv of observed catches
varslt <- catch.n(stk)
varslt[] <- 0.4
catch.n(stk) <- FLQuantDistr(catch.n(stk), varslt)
# cv of observed indices
varslt <- index(idx[[1]])
varslt[] <- 0.1
index.var(idx[[1]]) <- varslt
# run
fit1 <- sca(stk, idx, fmodel=fmod0, qmodel=qmod0, srmodel=srmod0, vmodel=vmod0, n1model=n1mod0)
flqs <- FLQuants(nowgt=stock.n(fit0), extwgt=stock.n(fit1))
```

```{r, likwgt, fig.cap="Stock summary of distinct likelihood weightings"}
xyplot(data~year|factor(age), groups=qname, data=flqs, type="l", scales=scl, auto.key=lgnd, par.settings=pset, ylab="")
```

```{r, likwgtimpact, fig.cap="Population estimates using two different variance models"}
flsts <- FLStocks(nowgt=ple4+fit0, wgt=ple4 + fit1)
plot(flsts)
```

Note that by using a smaller CV for the index, one is increasing the contribution of the survey and penalizing catch at age, in relative terms. The ratio between likelihood scores of both fits show this effect with catch at age increasing by 2.3 while the index increases almost 8 fold.

```{r}
fit0 <- sca(ple4, ple4.indices[1], fmodel=fmod0, qmodel=qmod0, srmodel=srmod0, vmodel=vmod0, n1model=n1mod0)
(fitSumm(fit1)/fitSumm(fit0))[c(2,8,9),]
```

## Working with covariates

In linear model one can use covariates to explain part of the variance observed on the data that the 'core' model does not explain. The same can be done in the `a4a` framework. The example below uses the North Atlantic Oscillation (NAO) index to model recruitment.

```{r}
nao <- read.table("https://www.cpc.ncep.noaa.gov/products/precip/CWlink/pna/norm.nao.monthly.b5001.current.ascii.table", skip=1, fill=TRUE, na.strings="-99.90")
dnms <- list(quant="nao", year=1950:2024, unit="unique", season=1:12, area="unique")
nao <- FLQuant(unlist(nao[,-1]), dimnames=dnms, units="nao")
nao <- seasonMeans(trim(nao, year=dimnames(stock.n(ple4))$year))
```

First by simply assuming that the NAO index drives recruitment (Figure \@ref(fig:naor)).

```{r}
srmod <- ~ nao
fit2 <- sca(ple4, ple4.indices[1], qmodel=list(~s(age, k=4)), srmodel=srmod, covar=FLQuants(nao=nao))
flqs <- FLQuants(simple=stock.n(fit)[1], covar=stock.n(fit2)[1])
```
 
```{r, naor, echo=FALSE, fig.cap="Recruitment model with covariates. Using the NAO index as a recruitment index."}
xyplot(data~year, groups=qname, data=flqs, type="l",
       auto.key=list(points=FALSE, lines=TRUE, columns=2),
       par.settings=list(superpose.line=list(col=c("gray35", "black"), lty=c(2,1), lwd=c(1,1.5)),
       strip.background=list(col="gray90")), ylab="")
```

In a second model we're using the NAO index not to model recruitment directly but to model one of the parameters of the S/R function (Figure \@ref(fig:naor2)).

```{r}
srmod <- ~ ricker(a=~nao, CV=0.25)
fit3 <- sca(ple4, ple4.indices[1], qmodel=list(~s(age, k=4)), srmodel=srmod, covar=FLQuants(nao=nao))
flqs <- FLQuants(simple=stock.n(fit)[1], covar=stock.n(fit3)[1])
```

```{r, naor2, echo=FALSE, fig.cap="Recruitment model with covariates. Using the NAO index as a covariate for the stock-recruitment model parameters."}
xyplot(data~year, groups=qname, data=flqs, type="l",
       auto.key=list(points=FALSE, lines=TRUE, columns=2),
       par.settings=list(superpose.line=list(col=c("gray35", "black"), lty=c(2,1), lwd=c(1,1.5)),
       strip.background=list(col="gray90")), ylab="")
```

Note that covariates can be added to any submodel using the linear model capabilities of R.

## Assessing \ADMB files

The framework gives access to the files produced to run the `ADMB` fitting routine through the argument `wkdir`. When set up all the `ADMB` files will be left in the directory. Note that the `ADMB` tpl file is distributed with the `FLa4a`. One can get it from your `R` library, under the folder `myRlib/FLa4a/admb/`.

```{r, eval=FALSE}
fit1 <- sca(ple4, ple4.indices, wkdir="fit1run")
```

## Missing observations in the catch matrix or index

%====================================================================
% COLIN TO CHECK THE SECTION
%====================================================================

How are the data interpolated etc ...



