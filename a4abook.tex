% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{book}
\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newlength{\cslentryspacingunit} % times entry-spacing
\setlength{\cslentryspacingunit}{\parskip}
\newenvironment{CSLReferences}[2] % #1 hanging-ident, #2 entry spacing
 {% don't indent paragraphs
  \setlength{\parindent}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1
  \let\oldpar\par
  \def\par{\hangindent=\cslhangindent\oldpar}
  \fi
  % set entry spacing
  \setlength{\parskip}{#2\cslentryspacingunit}
 }%
 {}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{#1\hfill\break}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{#1}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{#1}\break}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\hypersetup{
  pdftitle={Fish stock assessment with R - DRAFT},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}

\title{Fish stock assessment with R - DRAFT}
\usepackage{etoolbox}
\makeatletter
\providecommand{\subtitle}[1]{% add subtitle to \maketitle
  \apptocmd{\@title}{\par {\large #1 \par}}{}{}
}
\makeatother
\subtitle{The a4a Initiative}
\author{true \and true \and true \and true}
\date{2025-06-05}

\begin{document}
\maketitle

{
\setcounter{tocdepth}{1}
\tableofcontents
}
\hypertarget{before-starting}{%
\chapter{Before starting}\label{before-starting}}

\hypertarget{installing-and-loading-libraries}{%
\section{Installing and loading libraries}\label{installing-and-loading-libraries}}

To run the methods in this book the reader will need to install the \texttt{FLa4a} package (\protect\hyperlink{ref-fla4a}{Millar and Jardim 2025}), \texttt{FLCore} (\protect\hyperlink{ref-flr}{L. T. Kell et al. 2007}), some FLR packages, and relevant dependencies. Some datasets are distributed with the package and as such need to be loaded too. \texttt{R} packages used throughout the book will have to be installed if not yet available in the \texttt{R} environment.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# FLR packages used in the book}
\FunctionTok{install.packages}\NormalTok{(}
  \FunctionTok{c}\NormalTok{(}\StringTok{"FLCore"}\NormalTok{, }\StringTok{"FLa4a"}\NormalTok{, }\StringTok{"FLBRP"}\NormalTok{, }\StringTok{"FLasher"}\NormalTok{, }\StringTok{"a4adiags"}\NormalTok{, }\StringTok{"ggplotFL"}\NormalTok{),}
  \AttributeTok{repos=}\FunctionTok{c}\NormalTok{(}\AttributeTok{FLR=}\StringTok{"https://flr.r{-}universe.dev"}\NormalTok{, }\AttributeTok{CRAN=}\StringTok{"https://cloud.r{-}project.org"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# libraries}
\FunctionTok{library}\NormalTok{(devtools)}
\FunctionTok{library}\NormalTok{(FLa4a)}
\FunctionTok{library}\NormalTok{(XML)}
\FunctionTok{library}\NormalTok{(reshape2)}
\FunctionTok{library}\NormalTok{(ggplotFL)}
\CommentTok{\# datasets}
\FunctionTok{data}\NormalTok{(ple4)}
\FunctionTok{data}\NormalTok{(ple4.indices)}
\FunctionTok{data}\NormalTok{(ple4.index)}
\FunctionTok{data}\NormalTok{(rfLen)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{packageVersion}\NormalTok{(}\StringTok{"FLCore"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] '2.6.20.9333'
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{packageVersion}\NormalTok{(}\StringTok{"FLa4a"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] '1.9.4'
\end{verbatim}

\hypertarget{how-to-read-this-document}{%
\section{How to read this document}\label{how-to-read-this-document}}

The target audience for this document are readers with some experience in R and some background on stock assessment.

The document explains the approach being developed by the Assessment for All Initiative (a4a) for fish stock assessment and scientific advice. It presents a mixture of text and code, where the first explains the concepts behind the methods, while the last shows how these can be run with the software provided. Moreover, having the code allows the reader to copy/paste and replicate the analysis presented here.

The sections and subsections are as independent as possible, so they can be used as a reference document for \texttt{FLa4a}.

\hypertarget{how-to-get-help}{%
\section{How to get help}\label{how-to-get-help}}

\texttt{FLa4a} is build using \texttt{R}'s object oriented implementation with S4 classes, and \texttt{FLCore}'s (\protect\hyperlink{ref-flr}{L. T. Kell et al. 2007}) class structures and methods. In order to access S4 methods and classes documentation the user needs to use specific terminology.

For example, \texttt{FLStock} is one of our main components in order to run our stock assessment model. We can check the structure of an \texttt{FLStock} object as follows:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{showClass}\NormalTok{(}\StringTok{"FLStock"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Class "FLStock" [package "FLCore"]
## 
## Slots:
##                                                                        
## Name:         catch      catch.n     catch.wt     discards   discards.n
## Class:      FLQuant      FLQuant      FLQuant      FLQuant      FLQuant
##                                                                        
## Name:   discards.wt     landings   landings.n  landings.wt        stock
## Class:      FLQuant      FLQuant      FLQuant      FLQuant      FLQuant
##                                                                        
## Name:       stock.n     stock.wt            m          mat      harvest
## Class:      FLQuant      FLQuant      FLQuant      FLQuant      FLQuant
##                                                                        
## Name:  harvest.spwn       m.spwn         name         desc        range
## Class:      FLQuant      FLQuant    character    character      numeric
## 
## Extends: 
## Class "FLS", directly
## Class "FLComp", by class "FLS", distance 2
## 
## Known Subclasses: 
## Class "FLStockR", directly, with explicit coerce
\end{verbatim}

The object oriented structure of \texttt{FLa4a} gives the opportunity to change the behavior of a function according to the object that is applied to. For example we can check the available methods of the function \texttt{plot}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{showMethods}\NormalTok{(}\StringTok{"plot"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Function: plot (package base)
## x="a4aFit", y="FLIndices"
## x="a4aFit", y="FLStock"
## x="a4aFitCatchDiagn", y="missing"
## x="a4aFitMCMCs", y="missing"
## x="a4aFitResiduals", y="missing"
## x="a4aFits", y="missing"
## x="ANY", y="ANY"
## x="color", y="ANY"
## x="Copula", y="ANY"
## x="FLBiol", y="missing"
## x="FLBiols", y="missing"
## x="FLCohort", y="missing"
## x="FLIndex", y="missing"
## x="FLIndexBiomass", y="missing"
## x="FLIndices", y="missing"
## x="FLPar", y="missing"
## x="FLQuant", y="FLQuant"
## x="FLQuant", y="missing"
## x="FLQuantPoint", y="FLQuant"
## x="FLQuantPoint", y="FLQuants"
## x="FLQuantPoint", y="missing"
## x="FLQuants", y="FLPar"
## x="FLQuants", y="FLPars"
## x="FLQuants", y="missing"
## x="FLSR", y="missing"
## x="FLSRs", y="ANY"
## x="FLStock", y="FLPar"
## x="FLStock", y="FLStock"
## x="FLStock", y="FLStocks"
## x="FLStock", y="missing"
## x="FLStocks", y="FLPar"
## x="FLStocks", y="missing"
## x="mvdc", y="ANY"
## x="profile.mle", y="missing"
\end{verbatim}

By calling \texttt{showMethods} R prints all the possible uses of the \texttt{plot} function. We want to see what it does when it is called on an \texttt{FLStock} object with no other object. We observe that \texttt{plot} takes two arguments, \texttt{x} and \texttt{y}. So, in the signature of the \texttt{getMethod} function we are going to use, we need to define both \texttt{x} and \texttt{y}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{getMethod}\NormalTok{(}\StringTok{\textquotesingle{}plot\textquotesingle{}}\NormalTok{, }\AttributeTok{signature =} \FunctionTok{list}\NormalTok{(}\StringTok{"FLStock"}\NormalTok{,}\StringTok{"missing"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Method Definition:
## 
## function (x, y, ...) 
## {
##     .local <- function (x, metrics = list(Rec = rec, SSB = ssb, 
##         Catch = catch, F = fbar), na.rm = TRUE, ...) 
##     {
##         metrics <- metrics(x, metrics = metrics)
##         if ("F" %in% names(metrics)) 
##             units(metrics$F) <- paste0(range(x, c("minfbar", 
##                 "maxfbar")), collapse = "-")
##         if ("SSB" %in% names(metrics)) {
##             if (all(dimnames(metrics$SSB)$unit %in% c("F", "M"))) {
##                 metrics$SSB <- metrics$SSB[, , "F"] + metrics$SSB[, 
##                   , "M"]
##                 if ("Rec" %in% names(metrics)) 
##                   metrics$Rec <- unitSums(metrics$Rec)
##             }
##         }
##         if ("Rec" %in% names(metrics)) {
##             if (dim(metrics$Rec)[4] > 1) {
##                 metrics$Rec[metrics$Rec == 0] <- NA
##             }
##         }
##         p <- plot(metrics, na.rm = na.rm, ...) + ylim(c(0, NA))
##         if ("SSB" %in% names(metrics)) 
##             if (all(dimnames(metrics$SSB)$unit %in% c("F", "M"))) {
##                 return(p + theme(legend.position = "bottom", 
##                   legend.key = element_blank()) + labs(color = "Sex") + 
##                   scale_color_manual(name = "", labels = c("Both", 
##                     "F", "M"), values = flpalette_colours(3)))
##             }
##         return(p)
##     }
##     .local(x, ...)
## }
## <bytecode: 0x6447c1e7b128>
## <environment: namespace:ggplotFL>
## 
## Signatures:
##         x         y        
## target  "FLStock" "missing"
## defined "FLStock" "missing"
\end{verbatim}

More information can be found in \texttt{R}'s documentation (\url{https://www.r-project.org/}).

\hypertarget{acknowledgements}{%
\section{Acknowledgements}\label{acknowledgements}}

To be complete with version 1.0.

To write this book we used AI agents (chatGPT) for some bibliographic research and grammar revisions.

\hypertarget{license}{%
\section{License}\label{license}}

This book is released under a Creative Commons license \href{https://creativecommons.org/licenses/by-sa/4.0/}{CC BY-SA 4.0}.

The \texttt{FLa4a} package is released under the \href{https://joinup.ec.europa.eu/community/eupl/home}{EUPL 1.1}.

\hypertarget{introduction}{%
\chapter{Introduction}\label{introduction}}

\hypertarget{the-assessment-for-all-initiative-a4a}{%
\section{The ``Assessment for All'' Initiative (a4a)}\label{the-assessment-for-all-initiative-a4a}}

The European Commission Joint Research Centre's (JRC) ``Assessment for All'' Initiative (a4a) was launched to simplify and standardize the complex methodologies often employed in fisheries science. The a4a philosophy focuses on creating flexible, modular frameworks that can accommodate various levels of data availability, different regional needs, and stakeholder objectives. The main aim was to develop, test, and distribute methods able to be used to assess a large number of stocks in an operational time frame, and to build the necessary expertise on stock assessment and advice provision.

According to Jardim et al. (\protect\hyperlink{ref-EJ_etal_2014}{2014}), the long-term strategy of a4a is to increase the number of stock assessments by reducing the workload required to run each analysis and by bringing more scientists into fisheries management advice. The first is achieved by developing a working framework with the methods required to run all the analyses a stock assessment needs. Such approach should make the model exploration and selection processes easier, as well as decreasing the burden of moving between software platforms. The second can be achieved by making the analysis more intuitive, thereby attracting more experts to join stock assessment teams.

One major step to achieve the a4a goals was the development of a stock assessment model that could be applied rapidly to a large number of stocks and for a wide range of applications: traditional stock assessment, conditioning of operating models, forecasting, or informing harvest control rules in MSE algorithms.

The modular nature of a4a allows for the integration of data from diverse sources, including biological, environmental, and socioeconomic datasets, ensuring comprehensive assessments. This inclusivity enhances the ability to predict stock dynamics and evaluate the impacts of fishing and environmental changes.

While a4a simplifies traditional assessment approaches, it faces challenges such as ensuring the quality and consistency of input data, especially in regions with limited monitoring infrastructure. To address this, the initiative incorporates uncertainty into its models, leveraging MCMC frameworks and other statistical tools to account for variability in data quality and ecosystem processes.

The a4a framework has been applied in various European fisheries to improve stock assessment practices. In the Mediterranean Sea it has been used for more than 200 stock assessments, as of 2024 in \href{https://www.fao.org/gfcm/data/star/en/}{(GFCM)} and \href{https://stecf.ec.europa.eu/data-dissemination/medbs_en}{(STECF)}.

Some of the key elements of stock assessment are the quantity, quality and aggregation level of the data available. As in many other models the data will condition the type of models that can be used. In a4a the minimum set of data, loosely defined as a ``moderate data'' level, consists of:

\begin{itemize}
\tightlist
\item
  volume of catches in weight (which should both include landings and discards);
\item
  length structure of the catches (based on selectivity studies or direct observations);
\item
  natural mortality by length;
\item
  proportion of mature individuals by length;
\item
  age-length key or growth model;
\item
  length-weight relationship;
\item
  index or indices of abundance and its length structure, or indices of biomass, which could originate from either a scientific survey or a commercial CPUE series;
\end{itemize}

\hypertarget{multi-stage-modelling-approach}{%
\section{Multi-stage modelling approach}\label{multi-stage-modelling-approach}}

In ecological and population dynamics modeling, one can choose between integrated models, which estimate correlated parameters together, and multi-stage models, which separate estimation into distinct steps. These approaches differ in complexity, data requirements, interpretability, and their ability to address various uncertainties. The selection depends largely on the study objectives, the available data, and the system's ecological complexity.

Integrated models estimate all parameters within a unified framework, accounting for correlations and interactions between variables such as growth, natural mortality, recruitment, and environmental factors. This approach can provide a realistic depiction of biological systems by preserving dependencies and feedback loops, which are crucial for understanding processes like density dependence or predator-prey interactions (\protect\hyperlink{ref-MCAPAM2023}{Hamel et al. 2023}). Integrated models are particularly advantageous for ecosystem-based management, where interactions among multiple factors need to be captured. However, the complexity of these models makes them computationally intensive and sensitive to data quality.

On the other hand, multi-stage approaches estimate parameters such as growth or natural mortality independently before incorporating them into broader models. This step-wise approach simplifies estimation, reducing computational demands and mitigating issues like parameter confounding. For example, fisheries often use empirical relationships to estimate natural mortality (\(M\)) based on growth parameters or life history traits before including M in stock assessment models (\protect\hyperlink{ref-Maceina_etal_2016}{Maceina and Sammons 2016}). However, this decoupling may overlook dynamic interactions, such as how growth influences mortality, potentially leading to biased or incomplete inferences about ecosystem dynamics (\protect\hyperlink{ref-Jacobsen_etal_2018}{Jacobsen and Essington 2018}).

Dealing with uncertainty is a critical aspect of both approaches. Integrated models explicitly quantify and propagate uncertainties across correlated parameters. These models incorporate multiple sources of variability, including observation, process, and structural uncertainties, enhancing the robustness of predictions (\protect\hyperlink{ref-Luxf3pez_etal_2017}{LÃ³pez Quintero, Contreras-Reyes, and Wiff 2017}). Conversely, multi-stage models often treat parameter estimates as fixed values, which can underestimate uncertainty propagation in subsequent analyses. However, by treating initial stage estimates as distributions rather than point estimates, multi-stage models can partially address this limitation.

For fisheries science, the choice between these models often depends on management goals and data availability. Integrated models are better suited for forecasting fish abundance or evaluating complex ecological interactions, such as predator-prey dynamics or responses to environmental variability (\protect\hyperlink{ref-Robertson_etal_2022}{Robertson, Regular, and Cadigan 2022}). Meanwhile, multi-stage models are advantageous for practical applications, such as fisheries stock assessment and scientific advice, where simplicity and robustness take precedence over ecological nuance. For example, empirical estimates of \(M\), derived from life-history traits, provide reliable inputs for subsequent models, avoiding the parameter confounding that often occurs in integrated frameworks.

Despite the intuitive advantages of integrated models, they are not a panacea for poor quality data or model structure uncertainty in stock assessment. There are also several disadvantages, mostly related to the potential for model misspecification, the complexity of the resulting model, and the associated, often considerable, computational requirements (e.g.~the use of remotely sensed environmental information). Consequently, in some situations, the traditional two-stage model remains a better approach (\protect\hyperlink{ref-maunderPunt2013}{Mark N. Maunder and Punt 2013}).

\hypertarget{stock-assessment-process}{%
\section{Stock Assessment Process}\label{stock-assessment-process}}

The following table breaks down the stock assessment process into three stages: (i) input data preparation, (ii) stock assessment model fitting, and (iii) provision of scientific advice. This breakdown is designed to explain the a4a approach, offering a general framework that outlines the sequence of analyses in the stock assessment process. Each stage includes a plethora of analyses and procedures tailored to an specific stock, considering the available data, time, and resources.

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 2\tabcolsep) * \real{0.5000}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 2\tabcolsep) * \real{0.5000}}@{}}
\caption{\label{tab:sastages} Stock assessment process stages}\tabularnewline
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Stage
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Description
\end{minipage} \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Stage
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Description
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\textbf{Input data preparation} & Preparation of catch data, potentially computing both landings and discards. Preparation of biological data, including maturity, length-weight relationships, natural mortality, and individual growth. Conversion of length data into age data. \\
\textbf{Stock assessment model fit} & Fitting the model to data, inspecting diagnostics such as residuals, retrospective analyses, and hindcasts. Fitting the stock-recruitment model to recruitment and spawning stock biomass (SSB) estimates from the stock assessment model fit or within the model itself. \\
\textbf{Scientific advice provision} & Estimation of reference points. Assessment of stock status based on reference points and model estimates of SSB and fishing mortality. Running projections under different scenarios. Providing reports with policy outcome evaluations. \\
\end{longtable}

The main purpose of the above table is to clarify a4a's multi-stage approach to stock assessment. For instance, parameters like natural mortality and individual growth are estimated outside the stock assessment model fitting process, unlike how it is often done in integrated analyses. The stock-recruitment relationship, however, can be estimated within the model, as is common in integrated analyses. This mixed approach seeks to exclude highly correlated processes from the model while incorporating those that can enhance the robustness of the stock assessment model fit.

On the other hand, since natural mortality and individual growth are very important processes acting at a very low level in terms of data processing, there are specific methods to deal with conditioning those processes, in those cases when there is no data or very limited data is available, and to provide the opportunity to propagate their uncertainty into stock assessment.

\hypertarget{data-used-in-the-book}{%
\section{Data used in the book}\label{data-used-in-the-book}}

\hypertarget{plaice-in-area-fao-27-ices-area-iv}{%
\subsection{Plaice in area FAO 27, ICES area IV}\label{plaice-in-area-fao-27-ices-area-iv}}

North sea plaice is an important demersal flatfish that has been targeted by different fleets operating in the area, but most importantly by beam and otter trawlers. This fishery has always had a large discard rate, which currently accounts for more than 60\% of the catch. The stock has grown in recent years with the decrease of fishing mortality. A number of scientific surveys sample plaice, both in coastal areas, where spawning takes place, and in deeper waters.

\hypertarget{european-hake-in-fao-37-gsas-1567}{%
\subsection{European hake in FAO 37, GSAs 1,5,6,7}\label{european-hake-in-fao-37-gsas-1567}}

European hake is an important demersal species targeted by Mediterranean fishing fleets in several regions, mainly by bottom trawling, with In GSA 5 (Balearic Islands), bottom trawlers use different fishing tactics depending on the depth, with hake being targeted mainly on the deep shelf and the upper slope. In GSA 6, the fishery is also dominated by trawlers, with a large fleet operating on the shelf and slope and showing relatively stable catches. In GSA 7 (Gulf of Lions), hake is targeted by both French and Spanish vessels using a variety of gear types, including trawlers, gillnets and longlines.

\hypertarget{red-mullet-in-fao-37-gsa-9}{%
\subsection{Red mullet in FAO 37, GSA 9}\label{red-mullet-in-fao-37-gsa-9}}

Red mullets is a key commercial species in GSA 9.They can be found in sandy and muddy areas, and most are caught by bottom trawlers. Small scale fisheries also catch some using nets. The amount of discards reported is very low and considered to be negligible. Trawl fisheries developed along the continental shelf and upper slope. Smaller vessels operate almost exclusively on the continental shelf. Red mullet is intensively exploited during its recruitment from September to November

\hypertarget{redfish-simulated-length-data}{%
\subsection{Redfish simulated length data}\label{redfish-simulated-length-data}}

This is a length-based dataset simulated with GADGET (\protect\hyperlink{ref-gadget}{Begley and Howell 2004}).

\hypertarget{notation}{%
\section{Notation}\label{notation}}

Along this book the notation presented in Table \ref{tab:mathsnotation} will be used. Mathematical descriptions will be kept as simple as possible for readability.

\begin{longtable}[]{@{}lrl@{}}
\caption{\label{tab:mathsnotation} Mathematical notation}\tabularnewline
\toprule\noalign{}
Type & Symbol & Description \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
Type & Symbol & Description \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
variables & & \\
& \(C\) & catches \\
& \(F\) & fishing mortality \\
& \(M\) & natural mortality \\
& \(R\) & recruitment \\
& \(Q\) & vessel or fleet catchability \\
& \(w\) & weights \\
& \(l\) & likelihood \\
& \(I\) & abundance index \\
& \(S\) & spawning stock biomass \\
& \(CV\) & coefficient of variation \\
& \(D\) & residuals or deviances \\
& \(N\) & population numbers \\
& \(\beta, \gamma\) & parameters \\
& \(a\) & stock-recruitment parameter \\
& \(b\) & stock-recruitment parameter \\
& \(\sigma^2\) & variance of catch \\
& \(\tau^2\) & variance of index \\
& \(\phi^2\) & variance of predicted recruitment \\
& \(\upsilon^2\) & variance of residuals \\
subscripts & & \\
& \(a\) & age \\
& \(y\) & year \\
& \(C\) & catch \\
& \(I\) & abundance index \\
& \(N\) & normal distribution \\
& \(s\) & survey \\
& \(SR\) & stock recruitment relationship \\
superscripts and accents & & \\
& \(\hat{}\) & observation \\
& \(\tilde{}\) & prediction \\
& \(c\) & catches \\
& \(s\) & abundance index \\
\end{longtable}

\hypertarget{growth}{%
\chapter{Modelling Individual Growth and Using Stochastic Slicing to Convert Length-based Data Into Age-based Data}\label{growth}}

The \texttt{a4a} stock assessment framework is based on age dynamics. Therefore, length information must be processed before running the stock assessment model. The methods in this section provide the analyst flexibility to use a large range of information sources, \emph{e.g.} literature or online databases, to collect information about the species growth model and uncertainty about the model parameters.

The framework allows the analyst to parametrize individual growth, set the assumptions about it and condition the stock assessment model on those decisions. It incentivize the uptake of estimation uncertainty, as well as exploring several parametrizations and/or growth models to deal with structural uncertainty.

Within the \texttt{a4a} framework this is handled using the \texttt{a4aGr} class and its methods. This class stores information about the growth model and it's parameters, including parameters' uncertainty and the distributions governing it. The class's main method is \texttt{l2a()} that converts length to ages based on a length based stock object and using the model defined in the \texttt{a4aGr} instance.

\hypertarget{a4agr---the-growth-class}{%
\section{a4aGr - The growth class}\label{a4agr---the-growth-class}}

The conversion of length data to age is performed through the use of a growth model. The implementation is done through the \texttt{a4aGr} class .

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{showClass}\NormalTok{(}\StringTok{"a4aGr"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Class "a4aGr" [package "FLa4a"]
## 
## Slots:
##                                                                             
## Name:      grMod  grInvMod    params      vcov     distr      name      desc
## Class:   formula   formula     FLPar     array character character character
##                 
## Name:      range
## Class:   numeric
## 
## Extends: "FLComp"
\end{verbatim}

To construct an \texttt{a4aGr} object, the growth model and parameters must be provided. Here we show an example using the von Bertalanffy growth model. To create the \texttt{a4aGr} object it's necessary to pass the model equation (\(length \sim time\)), the inverse model equation (\(time \sim length\)) and the parameters. Any growth model can be used as long as it's possible to write the model (and the inverse) as an R formula.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{vbObj }\OtherTok{\textless{}{-}} \FunctionTok{a4aGr}\NormalTok{(}
    \AttributeTok{grMod=}\SpecialCharTok{\textasciitilde{}}\NormalTok{linf}\SpecialCharTok{*}\NormalTok{(}\DecValTok{1}\SpecialCharTok{{-}}\FunctionTok{exp}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{k}\SpecialCharTok{*}\NormalTok{(t}\SpecialCharTok{{-}}\NormalTok{t0))),      }
    \AttributeTok{grInvMod=}\SpecialCharTok{\textasciitilde{}}\NormalTok{t0}\DecValTok{{-}1}\SpecialCharTok{/}\NormalTok{k}\SpecialCharTok{*}\FunctionTok{log}\NormalTok{(}\DecValTok{1}\SpecialCharTok{{-}}\NormalTok{len}\SpecialCharTok{/}\NormalTok{linf),      }
    \AttributeTok{params=}\FunctionTok{FLPar}\NormalTok{(}\AttributeTok{linf=}\FloatTok{58.5}\NormalTok{, }\AttributeTok{k=}\FloatTok{0.086}\NormalTok{, }\AttributeTok{t0=}\FloatTok{0.001}\NormalTok{, }\AttributeTok{units=}\FunctionTok{c}\NormalTok{(}\StringTok{"cm"}\NormalTok{,}\StringTok{"year{-}1"}\NormalTok{,}\StringTok{"year"}\NormalTok{))     }
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Check the model and its inverse:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lc}\OtherTok{=}\DecValTok{20}
\FunctionTok{predict}\NormalTok{(vbObj, }\AttributeTok{len=}\NormalTok{lc)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    iter
##           1
##   1 4.86575
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{predict}\NormalTok{(vbObj, }\AttributeTok{t=}\FunctionTok{predict}\NormalTok{(vbObj, }\AttributeTok{len=}\NormalTok{lc))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    iter
##      1
##   1 20
\end{verbatim}

The predict method allows the transformation between lengths and ages, and vice-versa, using the growth model.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{predict}\NormalTok{(vbObj, }\AttributeTok{len=}\DecValTok{5}\SpecialCharTok{:}\DecValTok{10}\FloatTok{+0.5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    iter
##            1
##   1 1.149080
##   2 1.370570
##   3 1.596362
##   4 1.826625
##   5 2.061540
##   6 2.301299
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{predict}\NormalTok{(vbObj, }\AttributeTok{t=}\DecValTok{5}\SpecialCharTok{:}\DecValTok{10}\FloatTok{+0.5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    iter
##            1
##   1 22.04376
##   2 25.04796
##   3 27.80460
##   4 30.33408
##   5 32.65511
##   6 34.78488
\end{verbatim}

\hypertarget{adding-uncertainty-to-growth-parameters-with-a-multivariate-normal-distribution}{%
\section{Adding uncertainty to growth parameters with a multivariate normal distribution}\label{adding-uncertainty-to-growth-parameters-with-a-multivariate-normal-distribution}}

Uncertainty in the growth model is introduced through the inclusion of parameter uncertainty. This is done by making use of the parameter variance-covariance matrix (the \texttt{vcov} slot of the \texttt{a4aGr} class) and setting a distribution for the parameters. The variance-covariance matrix could come from the parameter uncertainty from fitting the growth model parameters, or a meta analysis of correlation between parameters.

Here we set the variance-covariance matrix by scaling a correlation matrix, using a cv of 0.2. Based on

\[\rho_{x,y}=\frac{\Sigma_{x,y}}{\sigma_x \sigma_y}\]

and

\[CV_x=\frac{\sigma_x}{\mu_x}\]

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Make an empty cor matrix}
\NormalTok{cm }\OtherTok{\textless{}{-}} \FunctionTok{diag}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{))}
\CommentTok{\# k and linf are negatively correlated while t0 is independent}
\NormalTok{cm[}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{] }\OtherTok{\textless{}{-}}\NormalTok{ cm[}\DecValTok{2}\NormalTok{,}\DecValTok{1}\NormalTok{] }\OtherTok{\textless{}{-}} \SpecialCharTok{{-}}\FloatTok{0.5}
\CommentTok{\# scale cor to var using CV=0.2}
\NormalTok{cv }\OtherTok{\textless{}{-}} \FloatTok{0.2}
\NormalTok{p }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\AttributeTok{linf=}\DecValTok{60}\NormalTok{, }\AttributeTok{k=}\FloatTok{0.09}\NormalTok{, }\AttributeTok{t0=}\SpecialCharTok{{-}}\FloatTok{0.01}\NormalTok{)}
\NormalTok{vc }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\DecValTok{1}\NormalTok{, }\AttributeTok{ncol=}\DecValTok{3}\NormalTok{, }\AttributeTok{nrow=}\DecValTok{3}\NormalTok{)}
\NormalTok{l }\OtherTok{\textless{}{-}}\NormalTok{ vc}
\NormalTok{l[}\DecValTok{1}\NormalTok{,] }\OtherTok{\textless{}{-}}\NormalTok{ l[,}\DecValTok{1}\NormalTok{] }\OtherTok{\textless{}{-}}\NormalTok{ p[}\DecValTok{1}\NormalTok{]}\SpecialCharTok{*}\NormalTok{cv}
\NormalTok{k }\OtherTok{\textless{}{-}}\NormalTok{ vc}
\NormalTok{k[,}\DecValTok{2}\NormalTok{] }\OtherTok{\textless{}{-}}\NormalTok{ k[}\DecValTok{2}\NormalTok{,] }\OtherTok{\textless{}{-}}\NormalTok{ p[}\DecValTok{2}\NormalTok{]}\SpecialCharTok{*}\NormalTok{cv}
\NormalTok{t }\OtherTok{\textless{}{-}}\NormalTok{ vc}
\NormalTok{t[}\DecValTok{3}\NormalTok{,] }\OtherTok{\textless{}{-}}\NormalTok{ t[,}\DecValTok{3}\NormalTok{] }\OtherTok{\textless{}{-}}\NormalTok{ p[}\DecValTok{3}\NormalTok{]}\SpecialCharTok{*}\NormalTok{cv}
\NormalTok{mm }\OtherTok{\textless{}{-}}\NormalTok{ t}\SpecialCharTok{*}\NormalTok{k}\SpecialCharTok{*}\NormalTok{l}
\FunctionTok{diag}\NormalTok{(mm) }\OtherTok{\textless{}{-}} \FunctionTok{diag}\NormalTok{(mm)}\SpecialCharTok{\^{}}\DecValTok{2}
\NormalTok{mm }\OtherTok{\textless{}{-}}\NormalTok{ mm}\SpecialCharTok{*}\NormalTok{cm}
\CommentTok{\# check that we have the intended correlation}
\FunctionTok{all.equal}\NormalTok{(cm, }\FunctionTok{cov2cor}\NormalTok{(mm))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] TRUE
\end{verbatim}

Create the \texttt{a4aGr} object as before but now we also include the \texttt{vcov} argument for the variance-covariance matrix.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{vbObj }\OtherTok{\textless{}{-}} \FunctionTok{a4aGr}\NormalTok{(}
  \AttributeTok{grMod=}\SpecialCharTok{\textasciitilde{}}\NormalTok{linf}\SpecialCharTok{*}\NormalTok{(}\DecValTok{1}\SpecialCharTok{{-}}\FunctionTok{exp}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{k}\SpecialCharTok{*}\NormalTok{(t}\SpecialCharTok{{-}}\NormalTok{t0))),}
  \AttributeTok{grInvMod=}\SpecialCharTok{\textasciitilde{}}\NormalTok{t0}\DecValTok{{-}1}\SpecialCharTok{/}\NormalTok{k}\SpecialCharTok{*}\FunctionTok{log}\NormalTok{(}\DecValTok{1}\SpecialCharTok{{-}}\NormalTok{len}\SpecialCharTok{/}\NormalTok{linf),}
  \AttributeTok{params=}\FunctionTok{FLPar}\NormalTok{(}
    \AttributeTok{linf=}\NormalTok{p[}\StringTok{"linf"}\NormalTok{], }\AttributeTok{k=}\NormalTok{p[}\StringTok{"k"}\NormalTok{], }\AttributeTok{t0=}\NormalTok{p[}\StringTok{"t0"}\NormalTok{],}
    \AttributeTok{units=}\FunctionTok{c}\NormalTok{(}\StringTok{"cm"}\NormalTok{,}\StringTok{"year{-}1"}\NormalTok{,}\StringTok{"year"}\NormalTok{)),}
    \AttributeTok{vcov=}\NormalTok{mm}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

First we show a simple example where we assume that the parameters are represented using a multivariate normal distribution. Note that the object we have just created has a single iteration of each parameter.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{vbObj}\SpecialCharTok{@}\NormalTok{params}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## An object of class "FLPar"
## params
##  linf     k    t0 
## 60.00  0.09 -0.01 
## units:  cm year-1 year
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{dim}\NormalTok{(vbObj}\SpecialCharTok{@}\NormalTok{params)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 3 1
\end{verbatim}

We simulate 250 iterations from the \texttt{a4aGr} object by calling \texttt{mvrnorm()} using the variance-covariance matrix we created earlier. The object will now have 250 iterations of each parameter, randomly sampled from the multivariate normal distribution.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{vbNorm }\OtherTok{\textless{}{-}} \FunctionTok{mvrnorm}\NormalTok{(}\DecValTok{250}\NormalTok{,vbObj)}
\NormalTok{vbNorm}\SpecialCharTok{@}\NormalTok{params}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## An object of class "FLPar"
## iters:  250 
## 
## params
##                linf                   k                  t0 
## 59.392849(11.23446)  0.089573( 0.01918) -0.010171( 0.00191) 
## units:  cm year-1 year
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{dim}\NormalTok{(vbNorm}\SpecialCharTok{@}\NormalTok{params)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1]   3 250
\end{verbatim}

We can now convert from length to ages data based on the 250 parameter iterations, which will produce 250 sets of age data. For example, the next code will convert a single length vector using each of the 250 parameter iterations.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lvec }\OtherTok{\textless{}{-}} \DecValTok{5}\SpecialCharTok{:}\DecValTok{10}\FloatTok{+0.5}
\NormalTok{ages }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(vbNorm, }\AttributeTok{len=}\NormalTok{lvec)}
\FunctionTok{dim}\NormalTok{(ages)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1]   6 250
\end{verbatim}

The marginal distributions of the parameters can be seen in Figure \ref{fig:plotnormparams}.

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/plotnormparams-1.png}
\caption{\label{fig:plotnormparams}The marginal distributions of each of the parameters from using a multivariate normal distribution.}
\end{figure}

Pairwise plots show the covariance between each pair of parameters and the shape of their correlation (Figure \ref{fig:plotnormscatter}).

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/plotnormscatter-1.png}
\caption{\label{fig:plotnormscatter}Scatter plot of the 10000 samples parameter from the multivariate normal distribution.}
\end{figure}

Using the new generated age vectors one can depict the growth curves for the 250 iterations, which displays individual growth uncertainty (Figure \ref{fig:plotmvgrowth}).

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/plotmvgrowth-1.png}
\caption{\label{fig:plotmvgrowth}Growth curves using parameters simulated from a multivariate normal distribution.}
\end{figure}

\hypertarget{adding-uncertainty-to-growth-parameters-with-a-multivariate-triangle-distribution}{%
\section{Adding uncertainty to growth parameters with a multivariate triangle distribution}\label{adding-uncertainty-to-growth-parameters-with-a-multivariate-triangle-distribution}}

\label{sec:growth_triangle_cop}

One alternative to using a normal distribution is to use a \href{http://en.wikipedia.org/wiki/Triangle_distribution}{triangle distribution}. We use the package \texttt{triangle} (\protect\hyperlink{ref-R-triangle}{Carnell 2022}) where this distribution is parametrized using the minimum, maximum and median values. This can be very attractive if the analyst needs to scrape information from the web or literature, and use a meta-analysis to build the parameters' distribution. The triangle distribution has the advantage of setting hard tail limits, avoiding to generate extreme values. Here we show an example of setting a triangle distribution with values taken from Fishbase (\protect\hyperlink{ref-fishbase}{Froese and Pauly 2000}).

The following shows a method to extract data from fishbase. However, due to potential changes in the way one gets data from fishbase from within R, we've downloaded the data beforehand and load it for this example.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# The web address for the growth parameters for redfish (Sebastes norvegicus)}
\NormalTok{addr }\OtherTok{\textless{}{-}} \StringTok{"https://fishbase.se/PopDyn/PopGrowthList.php?ID=501"}
\CommentTok{\# Scrape the data}
\NormalTok{tab }\OtherTok{\textless{}{-}} \FunctionTok{try}\NormalTok{(}\FunctionTok{readHTMLTable}\NormalTok{(addr))}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Interrogate the data table and get vectors of the values}
\NormalTok{linf }\OtherTok{\textless{}{-}} \FunctionTok{as.numeric}\NormalTok{(}\FunctionTok{as.character}\NormalTok{(tab}\SpecialCharTok{$}\NormalTok{dataTable[,}\DecValTok{2}\NormalTok{]))}
\NormalTok{k }\OtherTok{\textless{}{-}} \FunctionTok{as.numeric}\NormalTok{(}\FunctionTok{as.character}\NormalTok{(tab}\SpecialCharTok{$}\NormalTok{dataTable[,}\DecValTok{4}\NormalTok{]))}
\NormalTok{t0 }\OtherTok{\textless{}{-}} \FunctionTok{as.numeric}\NormalTok{(}\FunctionTok{as.character}\NormalTok{(tab}\SpecialCharTok{$}\NormalTok{dataTable[,}\DecValTok{5}\NormalTok{]))}
\CommentTok{\# Set the min (a), max (b) and median (c) values for the parameter as a list of lists}
\CommentTok{\# Note that t0 has no \textquotesingle{}c\textquotesingle{} (median) value. This makes the distribution symmetrical}
\NormalTok{triPars }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{(}
  \AttributeTok{linf=}\FunctionTok{list}\NormalTok{(}\AttributeTok{a=}\FunctionTok{min}\NormalTok{(linf), }\AttributeTok{b=}\FunctionTok{max}\NormalTok{(linf), }\AttributeTok{c=}\FunctionTok{median}\NormalTok{(linf)),}
  \AttributeTok{k=}\FunctionTok{list}\NormalTok{(}\AttributeTok{a=}\FunctionTok{min}\NormalTok{(k), }\AttributeTok{b=}\FunctionTok{max}\NormalTok{(k), }\AttributeTok{c=}\FunctionTok{median}\NormalTok{(k)),}
  \AttributeTok{t0=}\FunctionTok{list}\NormalTok{(}\AttributeTok{a=}\FunctionTok{median}\NormalTok{(t0, }\AttributeTok{na.rm=}\NormalTok{T)}\SpecialCharTok{{-}}\FunctionTok{IQR}\NormalTok{(t0, }\AttributeTok{na.rm=}\NormalTok{T)}\SpecialCharTok{/}\DecValTok{2}\NormalTok{, }\AttributeTok{b=}\FunctionTok{median}\NormalTok{(t0, }\AttributeTok{na.rm=}\NormalTok{T)}\SpecialCharTok{+}\FunctionTok{IQR}\NormalTok{(t0, }\AttributeTok{na.rm=}\NormalTok{T)}\SpecialCharTok{/}\DecValTok{2}\NormalTok{))}

\CommentTok{\# Draw 250 samples using mvrtriangle}
\NormalTok{vbTri }\OtherTok{\textless{}{-}} \FunctionTok{mvrtriangle}\NormalTok{(}\DecValTok{250}\NormalTok{, vbObj, }\AttributeTok{paramMargins=}\NormalTok{triPars)}
\end{Highlighting}
\end{Shaded}

Note that in this case we're not building a new object with all the parameters' information. We're using the argument \texttt{paramMargins} to pass the parameters' information to the method.

The marginals will reflect the uncertainty on the parameter values that were scraped from Froese and Pauly (\protect\hyperlink{ref-fishbase}{2000}) but, as we don't really believe the parameters are multivariate normal, here we adopted a distribution based on a \emph{t} copula with triangle marginals. The marginal distributions can be seen in Figure \ref{fig:plottriparams} and the shape of the correlation can be seen in Figure \ref{fig:plottriscatter}.

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/plottriparams-1.png}
\caption{\label{fig:plottriparams}The marginal distributions of each of the parameters from using a multivariate triangle distribution.}
\end{figure}

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/plottriscatter-1.png}
\caption{\label{fig:plottriscatter}Scatter plot of the 10000 samples parameter from the multivariate triangle distribution.}
\end{figure}

We can still use \texttt{predict()} to see the growth model uncertainty (Figure \ref{fig:plottrigrowth}). Comparing with Figure \ref{fig:plotmvgrowth} one can see that using triangle distribution generates a lot less outliers, or values outside the central range of the growth curve.

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/plottrigrowth-1.png}
\caption{\label{fig:plottrigrowth}Growth curves using parameters simulated from a multivariate triangle distribution.}
\end{figure}

Remember that the above examples use a variance-covariance matrix that we essentially made up. An alternative would be to scrape the entire growth parameters dataset from Fishbase and compute the shape of the variance-covariance matrix yourself.

\hypertarget{adding-uncertainty-to-growth-parameters-with-statistical-copulas}{%
\section{Adding uncertainty to growth parameters with statistical copulas}\label{adding-uncertainty-to-growth-parameters-with-statistical-copulas}}

A more general approach to adding parameter uncertainty is to make use of statistical copulas (\protect\hyperlink{ref-sklar1959}{Sklar 1959}). Genest, Okhrin, and Bodnar (\protect\hyperlink{ref-copulahistory}{2024}) describes statistical ``copula'' as a multivariate cumulative distribution function with uniform margins on the unit interval. Sklar (\protect\hyperlink{ref-sklar1959}{1959}) highlighted the fact that any multivariate distribution can be expressed as a function of its margins and a copula. The idea is very attractive, one can simulate any multivariate distribution by setting a multivariate function in the unit interval which describes how the margins relate to each other, and scale up the univariate uniform margin with any continuos univariate distribution.

In our case this is possible with the \texttt{mvrcop()} function, borrowed from the package \texttt{copula} (\protect\hyperlink{ref-R-copula}{Jun Yan 2007}). The example below keeps the same parameters and changes only the copula type and family but a lot more can be done. Check the package \texttt{copula} for more information.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{vbCop }\OtherTok{\textless{}{-}} \FunctionTok{mvrcop}\NormalTok{(}\DecValTok{250}\NormalTok{, vbObj,}
  \AttributeTok{copula=}\StringTok{"archmCopula"}\NormalTok{,}
  \AttributeTok{family=}\StringTok{"clayton"}\NormalTok{,}
  \AttributeTok{param=}\DecValTok{2}\NormalTok{,}
  \AttributeTok{margins=}\StringTok{"triangle"}\NormalTok{,}
  \AttributeTok{paramMargins=}\NormalTok{triPars)}
\end{Highlighting}
\end{Shaded}

The shape of the correlation as well as the resulting growth curves are shown in Figures \ref{fig:plotcoptriscatter} and \ref{fig:plotcoptrigrowth}.

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/plotcoptriscatter-1.png}
\caption{\label{fig:plotcoptriscatter}Scatter plot of the 250 samples parameter from the using an archmCopula copula with triangle margins.}
\end{figure}

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/plotcoptrigrowth-1.png}
\caption{\label{fig:plotcoptrigrowth}Growth curves using parameters simulated from an archmCopula copula with triangle margins.}
\end{figure}

\hypertarget{converting-from-length-to-age-based-data---the-l2a-method}{%
\section{\texorpdfstring{Converting from length to age based data - the \texttt{l2a()} method}{Converting from length to age based data - the l2a() method}}\label{converting-from-length-to-age-based-data---the-l2a-method}}

After introducing uncertainty in the growth model through the parameters it's time to transform the length-based dataset into an age-based dataset. The method that deals with this process is \texttt{l2a()}. The implementation of this method for the \texttt{FLQuant} class is the main workhorse. There are two other implementations, for the \texttt{FLStock} and \texttt{FLIndex} classes, which are mainly wrappers that call the \texttt{FLQuant} method several times.

When converting from length-based data to age-based data you need to be aware of how the aggregation of length classes is performed. For example, individuals in length classes 1-2, 2-3, and 3-4 cm may all be considered as being of age 1 (obviously depending on the growth model). How should the values in those length classes be combined?

If the values are abundances then the values should be summed. Summing other types of values, such as mean weight, does not make sense. Instead these values are averaged over the length classes (possibly weighted by the abundance). This is controlled using the \texttt{stat} argument which can be either \texttt{mean} or \texttt{sum} (the default). Fishing mortality is not computed to avoid making wrong assumptions about the meaning of F at length.

We demonstrate the method by converting a catch-at-length \texttt{FLQuant} to a catch-at-age \texttt{FLQuant}. First we make an \texttt{a4aGr} object with a multivariate triangle distribution using parameters extracted from an AI agent. We use 10 iterations as an example, and call \texttt{l2a()} by passing in the length-based \texttt{FLQuant} and the \texttt{a4aGr} object.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{triPars }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{(}
  \AttributeTok{linf=}\FunctionTok{list}\NormalTok{(}\AttributeTok{a=}\DecValTok{55}\NormalTok{, }\AttributeTok{b=}\DecValTok{60}\NormalTok{),}
  \AttributeTok{k=}\FunctionTok{list}\NormalTok{(}\AttributeTok{a=}\FloatTok{0.05}\NormalTok{, }\AttributeTok{b=}\FloatTok{0.06}\NormalTok{),}
  \AttributeTok{t0=}\FunctionTok{list}\NormalTok{(}\AttributeTok{a=}\SpecialCharTok{{-}}\DecValTok{3}\NormalTok{, }\AttributeTok{b=}\SpecialCharTok{{-}}\DecValTok{2}\NormalTok{))}

\CommentTok{\# Draw 10 samples using mvrtriangle}
\NormalTok{vbTriSmall }\OtherTok{\textless{}{-}} \FunctionTok{mvrtriangle}\NormalTok{(}\DecValTok{10}\NormalTok{, vbObj, }\AttributeTok{paramMargins=}\NormalTok{triPars)}
\CommentTok{\# slice catch numbers at lengths to ages by summing catches}
\NormalTok{cth.n }\OtherTok{\textless{}{-}} \FunctionTok{l2a}\NormalTok{(}\FunctionTok{catch.n}\NormalTok{(rfLen.stk), vbTriSmall)}
\CommentTok{\# note there\textquotesingle{}s a lot of 0 catches so we\textquotesingle{}ll set the plus group at 21}
\NormalTok{cth.n }\OtherTok{\textless{}{-}} \FunctionTok{setPlusGroup}\NormalTok{(cth.n, }\DecValTok{21}\NormalTok{)}
\CommentTok{\# there\textquotesingle{}s also negative ages. The simulated data included individuals in lengths that won\textquotesingle{}t show in the catches, like 1 cm. We\textquotesingle{}ll trim those ages}
\NormalTok{cth.n }\OtherTok{\textless{}{-}}\NormalTok{ cth.n[}\FunctionTok{ac}\NormalTok{(}\DecValTok{0}\SpecialCharTok{:}\DecValTok{21}\NormalTok{)]}

\CommentTok{\# slice catch weights at lengths to ages by averaging catches}
\NormalTok{cth.wt }\OtherTok{\textless{}{-}} \FunctionTok{l2a}\NormalTok{(}\FunctionTok{catch.wt}\NormalTok{(rfLen.stk), vbTriSmall, }\AttributeTok{stat=}\StringTok{"mean"}\NormalTok{)}
\CommentTok{\# same process to deal with negative ages}
\NormalTok{cth.wt }\OtherTok{\textless{}{-}}\NormalTok{ cth.wt[}\FunctionTok{ac}\NormalTok{(}\DecValTok{0}\SpecialCharTok{:}\DecValTok{21}\NormalTok{)]}
\end{Highlighting}
\end{Shaded}

In the previous example, the \texttt{FLQuant} object that was sliced (\texttt{catch.n(rfLen.stk)}) had only one iteration. This iteration was sliced by each of the iterations in the growth model. It is possible for the \texttt{FLQuant} object to have the same number of iterations as the growth model, in which case each iteration of the \texttt{FLQuant} and the growth model are used together. It is also possible for the growth model to have only one iteration while the \texttt{FLQuant} object has many iterations. The same growth model is then used for each of the \texttt{FLQuant} iterations. As with all \texttt{FLR} objects, the general rule is \emph{one or n} iterations.

As well as converting one \texttt{FLQuant} at a time, we can convert entire \texttt{FLStock} and \texttt{FLIndex} objects. In these cases the individual \texttt{FLQuant} slots of those classes are converted from length-based to age-based. As mentioned above, the aggregation method depends on the type of values the slots contain. The abundance slots (\texttt{*.n}, such as \texttt{stock.n}) are summed. The \texttt{*.wt}, \texttt{m}, \texttt{mat}, \texttt{harvest.spwn} and \texttt{m.spwn} slots of an \texttt{FLStock} object are averaged. The \texttt{catch.wt} and \texttt{sel.pattern} slots of an \texttt{FLIndex} object are averaged, while the \texttt{index}, \texttt{index.var} and \texttt{catch.n} slots are summed.

The method for \texttt{FLStock} classes takes an additional argument for the plusgroup.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{aStk }\OtherTok{\textless{}{-}} \FunctionTok{l2a}\NormalTok{(rfLen.stk, vbTriSmall, }\AttributeTok{plusgroup=}\DecValTok{21}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "maxfbar has been changed to accomodate new plusgroup"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{aIdx }\OtherTok{\textless{}{-}} \FunctionTok{l2a}\NormalTok{(rfTrawl.idx, vbTriSmall)}
\end{Highlighting}
\end{Shaded}

When converting with \texttt{l2a()} all lengths above Linf are converted to the maximum age, as there is no information in the growth model about how to deal with individuals larger than Linf.

\hypertarget{modelling-natural-mortality}{%
\chapter{Modelling Natural Mortality}\label{modelling-natural-mortality}}

Natural mortality (\(M\)) is a critical parameter in stock assessment models, representing all sources of mortality not related to fishing or harvest (\(F\)). Combined, these two sources constitute the total mortality (\(Z\)) that individuals experience, with \(Z = F + M\).

However, natural mortality is notoriously difficult to observe and estimate. Only a few methods, such as mark-recapture studies, provide direct estimates of \(M\), and these methods are not applicable to all species and are often costly. As an alternative, life-history theory is commonly used to derive values for \(M\) that are consistent with individual growth and reproduction.

There is an extensive body of literature on natural mortality. Works by Pauly (\protect\hyperlink{ref-pauly1980}{1980}), Gislason et al. (\protect\hyperlink{ref-gislason2010}{2010}), Charnov (\protect\hyperlink{ref-charnov1993}{1993}), Mark N. Maunder et al. (\protect\hyperlink{ref-maunder2023mrev}{2023}) and Quinn and Deriso (\protect\hyperlink{ref-quinn1999}{1999}), as well as a dedicated special issue in Fisheries Research (\protect\hyperlink{ref-MCAPAM2023}{Hamel et al. 2023}), offer valuable insights and serve as excellent starting points. Given the parameter's importance and the difficulty of obtaining direct observations, natural mortality is widely regarded as one of the most significant sources of uncertainty in stock assessments.

Within the \texttt{a4a} framework, natural mortality is treated as an external parameter in the stock assessment model. Our aim is to develop a system that enables analysts to explore alternative models for \(M\) and compare the resulting assessment outcomes. This approach provides a more comprehensive information base to support informed decision-making throughout the stock assessment process.

Within the \texttt{a4a} framework, the general method for adding natural mortality in the stock assessment model is to:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Create an object of class \texttt{a4aM} which holds the natural mortality model and parameters.
\item
  Add uncertainty to the parameters in the \texttt{a4aM} object.
\item
  Apply the \texttt{m()} method to the \texttt{a4aM} object to create an age or length based \texttt{FLQuant} object of the required dimensions.
\end{enumerate}

The resulting \texttt{FLQuant} object can then be directly inserted into a \texttt{FLStock} object to be used in the assessment.

In this section we go through each of the steps in detail using a variety of different models.

\hypertarget{a4am---the-m-class}{%
\section{\texorpdfstring{\texttt{a4aM} - The M class}{a4aM - The M class}}\label{a4am---the-m-class}}

Natural mortality is implemented in a class named \texttt{a4aM}. This class is made up of three objects of the class \texttt{FLModelSim}. Each object is a model that represents one effect: an age or length effect, a scaling (level) effect and a time trend, named \texttt{shape}, \texttt{level} and \texttt{trend}, respectively. The impact of the models is multiplicative, i.e.~the overall natural mortality is given by \texttt{shape} x \texttt{level} x \texttt{trend}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{showClass}\NormalTok{(}\StringTok{"a4aM"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Class "a4aM" [package "FLa4a"]
## 
## Slots:
##                                                                         
## Name:       shape      level      trend       name       desc      range
## Class: FLModelSim FLModelSim FLModelSim  character  character    numeric
## 
## Extends: "FLComp"
\end{verbatim}

The \texttt{a4aM} constructor requires that the models and parameters are provided. The default method will build each of these models as a constant value of 1.

As a simple example, the usual ``0.2'' guess-estimate could be set up by setting the \texttt{level} model to have a single parameter with a fixed value, while the other two models, \texttt{shape} and \texttt{trend}, have a default value of 1 (meaning that they have no effect).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mod02 }\OtherTok{\textless{}{-}} \FunctionTok{FLModelSim}\NormalTok{(}\AttributeTok{model=}\SpecialCharTok{\textasciitilde{}}\NormalTok{a, }\AttributeTok{params=}\FunctionTok{FLPar}\NormalTok{(}\AttributeTok{a=}\FloatTok{0.2}\NormalTok{))}
\NormalTok{m1 }\OtherTok{\textless{}{-}} \FunctionTok{a4aM}\NormalTok{(}\AttributeTok{level=}\NormalTok{mod02)}
\NormalTok{m1}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## a4aM object:
##   shape: ~1
##   level: ~a
##   trend: ~1
\end{verbatim}

More interesting natural mortality shapes can be set up using biological knowledge. The following example uses an exponential decay over ages, implying that the resulting \texttt{FLQuant} generated by the \texttt{m()} method will be age based. We also use Jensen's second estimator (\protect\hyperlink{ref-Kenchington2014}{Kenchington 2014}) as a scaling \texttt{level} model, which is based on the von Bertalanffy \(K\) parameter, \(M=1.5K\).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{shape2 }\OtherTok{\textless{}{-}} \FunctionTok{FLModelSim}\NormalTok{(}\AttributeTok{model=}\SpecialCharTok{\textasciitilde{}}\FunctionTok{exp}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{age}\FloatTok{{-}0.5}\NormalTok{))}
\NormalTok{level2 }\OtherTok{\textless{}{-}} \FunctionTok{FLModelSim}\NormalTok{(}\AttributeTok{model=}\SpecialCharTok{\textasciitilde{}}\FloatTok{1.5}\SpecialCharTok{*}\NormalTok{k, }\AttributeTok{params=}\FunctionTok{FLPar}\NormalTok{(}\AttributeTok{k=}\FloatTok{0.4}\NormalTok{))}
\NormalTok{m2 }\OtherTok{\textless{}{-}} \FunctionTok{a4aM}\NormalTok{(}\AttributeTok{shape=}\NormalTok{shape2, }\AttributeTok{level=}\NormalTok{level2)}
\NormalTok{m2}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## a4aM object:
##   shape: ~exp(-age - 0.5)
##   level: ~1.5 * k
##   trend: ~1
\end{verbatim}

Note that the \texttt{shape} model has \texttt{age} as a parameter of the model but is not set using the \texttt{params} argument.

The \texttt{shape} model does not have to be age-based. For example, here we set up a \texttt{shape} model using Gislason's second estimator (\protect\hyperlink{ref-Kenchington2014}{Kenchington 2014}): \(M_l=K(\frac{L_{\inf}}{l})^{1.5}\). We use the default \texttt{level} and \texttt{trend} models.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{shape\_len }\OtherTok{\textless{}{-}} \FunctionTok{FLModelSim}\NormalTok{(}\AttributeTok{model=}\SpecialCharTok{\textasciitilde{}}\NormalTok{K}\SpecialCharTok{*}\NormalTok{(linf}\SpecialCharTok{/}\NormalTok{len)}\SpecialCharTok{\^{}}\FloatTok{1.5}\NormalTok{, }\AttributeTok{params=}\FunctionTok{FLPar}\NormalTok{(}\AttributeTok{linf=}\DecValTok{60}\NormalTok{, }\AttributeTok{K=}\FloatTok{0.4}\NormalTok{))}
\NormalTok{m\_len }\OtherTok{\textless{}{-}} \FunctionTok{a4aM}\NormalTok{(}\AttributeTok{shape=}\NormalTok{shape\_len)}
\end{Highlighting}
\end{Shaded}

Another option is to model how an external factor may impact natural mortality. This can be added through the \texttt{trend} model. Suppose natural mortality can be modelled with a dependency on the NAO index, due to some mechanism that results in having lower mortality when NAO is negative and higher when it's positive. In this example, the impact is represented by the NAO value on the quarter before spawning, which occurs in the second quarter.

We use this to make a complex natural mortality model with an age based shape model, a level model based on \(K\) and a trend model driven by NAO, where mortality increases by 50\% if NAO is positive on the first quarter.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Get NAO}
\NormalTok{nao }\OtherTok{\textless{}{-}} \FunctionTok{read.table}\NormalTok{(}\StringTok{"https://www.cpc.ncep.noaa.gov/products/precip/CWlink/pna/norm.nao.monthly.b5001.current.ascii.table"}\NormalTok{, }\AttributeTok{skip=}\DecValTok{1}\NormalTok{, }\AttributeTok{fill=}\ConstantTok{TRUE}\NormalTok{, }\AttributeTok{na.strings=}\StringTok{"{-}99.90"}\NormalTok{)}
\NormalTok{dnms }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{(}\AttributeTok{quant=}\StringTok{"nao"}\NormalTok{, }\AttributeTok{year=}\DecValTok{1950}\SpecialCharTok{:}\DecValTok{2024}\NormalTok{, }\AttributeTok{unit=}\StringTok{"unique"}\NormalTok{, }\AttributeTok{season=}\DecValTok{1}\SpecialCharTok{:}\DecValTok{12}\NormalTok{, }\AttributeTok{area=}\StringTok{"unique"}\NormalTok{)}
\CommentTok{\# Build an FLQuant from the NAO data}
\NormalTok{nao.flq }\OtherTok{\textless{}{-}} \FunctionTok{FLQuant}\NormalTok{(}\FunctionTok{unlist}\NormalTok{(nao[,}\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{]), }\AttributeTok{dimnames=}\NormalTok{dnms, }\AttributeTok{units=}\StringTok{"nao"}\NormalTok{)}
\CommentTok{\# Build covar by calculating mean over the first 3 months}
\NormalTok{nao }\OtherTok{\textless{}{-}} \FunctionTok{seasonMeans}\NormalTok{(}\FunctionTok{trim}\NormalTok{(nao.flq, }\AttributeTok{year=}\FunctionTok{dimnames}\NormalTok{(}\FunctionTok{stock.n}\NormalTok{(ple4))}\SpecialCharTok{$}\NormalTok{year))}
\CommentTok{\# Turn into Boolean}
\NormalTok{nao }\OtherTok{\textless{}{-}}\NormalTok{ (nao}\SpecialCharTok{\textgreater{}}\DecValTok{0}\NormalTok{)}
\CommentTok{\# Constructor}
\NormalTok{trend3 }\OtherTok{\textless{}{-}} \FunctionTok{FLModelSim}\NormalTok{(}\AttributeTok{model=}\SpecialCharTok{\textasciitilde{}}\DecValTok{1}\SpecialCharTok{+}\NormalTok{b}\SpecialCharTok{*}\NormalTok{nao, }\AttributeTok{params=}\FunctionTok{FLPar}\NormalTok{(}\AttributeTok{b=}\FloatTok{0.5}\NormalTok{))}
\NormalTok{shape3 }\OtherTok{\textless{}{-}} \FunctionTok{FLModelSim}\NormalTok{(}\AttributeTok{model=}\SpecialCharTok{\textasciitilde{}}\FunctionTok{exp}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{age}\FloatTok{{-}0.5}\NormalTok{))}
\NormalTok{level3 }\OtherTok{\textless{}{-}} \FunctionTok{FLModelSim}\NormalTok{(}\AttributeTok{model=}\SpecialCharTok{\textasciitilde{}}\FloatTok{1.5}\SpecialCharTok{*}\NormalTok{k, }\AttributeTok{params=}\FunctionTok{FLPar}\NormalTok{(}\AttributeTok{k=}\FloatTok{0.4}\NormalTok{))}
\NormalTok{m3 }\OtherTok{\textless{}{-}} \FunctionTok{a4aM}\NormalTok{(}\AttributeTok{shape=}\NormalTok{shape3, }\AttributeTok{level=}\NormalTok{level3, }\AttributeTok{trend=}\NormalTok{trend3)}
\NormalTok{m3}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## a4aM object:
##   shape: ~exp(-age - 0.5)
##   level: ~1.5 * k
##   trend: ~1 + b * nao
\end{verbatim}

\hypertarget{adding-uncertainty-to-natural-mortality-parameters-with-a-multivariate-normal-distribution}{%
\section{Adding uncertainty to natural mortality parameters with a multivariate normal distribution}\label{adding-uncertainty-to-natural-mortality-parameters-with-a-multivariate-normal-distribution}}

Uncertainty on natural mortality is added through uncertainty on the parameters.

In this section we'll' show how to add multivariate normal uncertainty. We make use of the class \texttt{FLModelSim} method \texttt{mvrnorm()}, which is a wrapper for the method \texttt{mvrnorm()} distributed by the package \texttt{MASS} (\protect\hyperlink{ref-mass}{Venables and Ripley 2002}).

We'll create an \texttt{a4aM} object with an exponential shape, a \texttt{level} model based on \(k\) and temperature, Jensen's third estimator (\protect\hyperlink{ref-Kenchington2014}{Kenchington 2014}), and a \texttt{trend} model driven by the NAO (as above). Afterwards a variance-covariance matrix for the \texttt{level} and \texttt{trend} models will be included. Finally, create an object with 100 iterations using the \texttt{mvrnorm()} method.

Create the object:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{shape4 }\OtherTok{\textless{}{-}} \FunctionTok{FLModelSim}\NormalTok{(}\AttributeTok{model=}\SpecialCharTok{\textasciitilde{}}\FunctionTok{exp}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{age}\FloatTok{{-}0.5}\NormalTok{))}
\NormalTok{level4 }\OtherTok{\textless{}{-}} \FunctionTok{FLModelSim}\NormalTok{(}\AttributeTok{model=}\SpecialCharTok{\textasciitilde{}}\NormalTok{k}\SpecialCharTok{\^{}}\FloatTok{0.66}\SpecialCharTok{*}\NormalTok{t}\SpecialCharTok{\^{}}\FloatTok{0.57}\NormalTok{,}
    \AttributeTok{params=}\FunctionTok{FLPar}\NormalTok{(}\AttributeTok{k=}\FloatTok{0.4}\NormalTok{, }\AttributeTok{t=}\DecValTok{10}\NormalTok{),}
    \AttributeTok{vcov=}\FunctionTok{array}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\FloatTok{0.002}\NormalTok{, }\FloatTok{0.01}\NormalTok{,}\FloatTok{0.01}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{dim=}\FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{)))}
\NormalTok{trend4 }\OtherTok{\textless{}{-}} \FunctionTok{FLModelSim}\NormalTok{(}\AttributeTok{model=}\SpecialCharTok{\textasciitilde{}}\DecValTok{1}\SpecialCharTok{+}\NormalTok{b}\SpecialCharTok{*}\NormalTok{nao,}
    \AttributeTok{params=}\FunctionTok{FLPar}\NormalTok{(}\AttributeTok{b=}\FloatTok{0.5}\NormalTok{),}
    \AttributeTok{vcov=}\FunctionTok{matrix}\NormalTok{(}\FloatTok{0.02}\NormalTok{))}
\NormalTok{m4 }\OtherTok{\textless{}{-}} \FunctionTok{a4aM}\NormalTok{(}\AttributeTok{shape=}\NormalTok{shape4, }\AttributeTok{level=}\NormalTok{level4, }\AttributeTok{trend=}\NormalTok{trend4)}
\CommentTok{\# Call mvrnorm()}
\NormalTok{m4 }\OtherTok{\textless{}{-}} \FunctionTok{mvrnorm}\NormalTok{(}\DecValTok{100}\NormalTok{, m4)}
\NormalTok{m4}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## a4aM object:
##   shape: ~exp(-age - 0.5)
##   level: ~k^0.66 * t^0.57
##   trend: ~1 + b * nao
\end{verbatim}

Inspect the level model (for example):

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{level}\NormalTok{(m4)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## An object of class "FLModelSim"
## Slot "model":
## ~k^0.66 * t^0.57
## 
## Slot "params":
## An object of class "FLPar"
## iters:  100 
## 
## params
##               k               t 
## 0.39928(0.0549) 9.71613(0.8864) 
## units:  NA 
## 
## Slot "vcov":
##       [,1] [,2]
## [1,] 0.002 0.01
## [2,] 0.010 1.00
## 
## Slot "distr":
## [1] "norm"
\end{verbatim}

Note the variance in the parameters:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{params}\NormalTok{(}\FunctionTok{trend}\NormalTok{(m4))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## An object of class "FLPar"
## iters:  100 
## 
## params
##              b 
## 0.49366(0.167) 
## units:  NA
\end{verbatim}

Note the shape model has no parameters and no uncertainty:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{params}\NormalTok{(}\FunctionTok{shape}\NormalTok{(m4))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## An object of class "FLPar"
## params
##    
## NA 
## units:  NA
\end{verbatim}

In this particular case, the \texttt{shape} model will not be randomized because it doesn't have a variance-covariance matrix. Also note that because there is only one parameter in the \texttt{trend} model, the randomization will use a univariate normal distribution. The same model could be achieved by using \texttt{mnrnorm()} on each model component:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{m4 }\OtherTok{\textless{}{-}} \FunctionTok{a4aM}\NormalTok{(}\AttributeTok{shape=}\NormalTok{shape4,}
    \AttributeTok{level=}\FunctionTok{mvrnorm}\NormalTok{(}\DecValTok{100}\NormalTok{, level4),}
    \AttributeTok{trend=}\FunctionTok{mvrnorm}\NormalTok{(}\DecValTok{100}\NormalTok{, trend4))}
\end{Highlighting}
\end{Shaded}

an exact match would require to control the random seed so that the draws would be exactly the same.

\hypertarget{adding-uncertainty-to-natural-mortality-parameters-with-statistical-copulas}{%
\section{Adding uncertainty to natural mortality parameters with statistical copulas}\label{adding-uncertainty-to-natural-mortality-parameters-with-statistical-copulas}}

We can also use copulas to add parameter uncertainty to the natural mortality model, similar to the way we use them for the growth model in Section \ref{growth}. As stated above these processes make use of the methods implemented for the \texttt{FLModelSim} class.

In the following example we'll use again Gislason's second estimator, \(M_l=K(\frac{L_{\inf}}{l})^{1.5}\) and a triangle copula to model parameter uncertainty. The method \texttt{mvrtriangle()} is used to create 1000 iterations.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{linf }\OtherTok{\textless{}{-}} \DecValTok{60}
\NormalTok{k }\OtherTok{\textless{}{-}} \FloatTok{0.4}
\CommentTok{\# vcov matrix (make up some values)}
\NormalTok{mm }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\ConstantTok{NA}\NormalTok{, }\AttributeTok{ncol=}\DecValTok{2}\NormalTok{, }\AttributeTok{nrow=}\DecValTok{2}\NormalTok{)}
\CommentTok{\# 10\% cv}
\FunctionTok{diag}\NormalTok{(mm) }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{((linf}\SpecialCharTok{*}\FloatTok{0.1}\NormalTok{)}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{, (k}\SpecialCharTok{*}\FloatTok{0.1}\NormalTok{)}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)}
\CommentTok{\# 0.2 correlation}
\NormalTok{mm[}\FunctionTok{upper.tri}\NormalTok{(mm)] }\OtherTok{\textless{}{-}}\NormalTok{ mm[}\FunctionTok{lower.tri}\NormalTok{(mm)] }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\FloatTok{0.05}\NormalTok{)}
\CommentTok{\# a good way to check is using cov2cor}
\FunctionTok{cov2cor}\NormalTok{(mm)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##           [,1]      [,2]
## [1,] 1.0000000 0.2083333
## [2,] 0.2083333 1.0000000
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# create object}
\NormalTok{mgis2 }\OtherTok{\textless{}{-}} \FunctionTok{FLModelSim}\NormalTok{(}\AttributeTok{model=}\SpecialCharTok{\textasciitilde{}}\NormalTok{k}\SpecialCharTok{*}\NormalTok{(linf}\SpecialCharTok{/}\NormalTok{len)}\SpecialCharTok{\^{}}\FloatTok{1.5}\NormalTok{, }\AttributeTok{params=}\FunctionTok{FLPar}\NormalTok{(}\AttributeTok{linf=}\NormalTok{linf, }\AttributeTok{k=}\NormalTok{k), }\AttributeTok{vcov=}\NormalTok{mm)}
\CommentTok{\# set the lower, upper and centre of the parameters}
\NormalTok{pars }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{(}\FunctionTok{list}\NormalTok{(}\AttributeTok{a=}\DecValTok{55}\NormalTok{,}\AttributeTok{b=}\DecValTok{65}\NormalTok{), }\FunctionTok{list}\NormalTok{(}\AttributeTok{a=}\FloatTok{0.3}\NormalTok{, }\AttributeTok{b=}\FloatTok{0.6}\NormalTok{, }\AttributeTok{c=}\FloatTok{0.35}\NormalTok{))}
\NormalTok{mgis2 }\OtherTok{\textless{}{-}} \FunctionTok{mvrtriangle}\NormalTok{(}\DecValTok{1000}\NormalTok{, mgis2, }\AttributeTok{paramMargins=}\NormalTok{pars)}
\NormalTok{mgis2}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## An object of class "FLModelSim"
## Slot "model":
## ~k * (linf/len)^1.5
## 
## Slot "params":
## An object of class "FLPar"
## iters:  1000 
## 
## params
##           linf              k 
## 59.968(2.2896)  0.404(0.0706) 
## units:  NA 
## 
## Slot "vcov":
##       [,1]   [,2]
## [1,] 36.00 0.0500
## [2,]  0.05 0.0016
## 
## Slot "distr":
## [1] "un <deprecated slot> triangle"
\end{verbatim}

The resulting parameter estimates and marginal distributions can be seen in Figures \ref{fig:plottrigism} and \ref{fig:plottrigismhist}. By default the method uses an elliptical copula of t family (see \texttt{?ellipCopula} for more information).

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/plottrigism-1.png}
\caption{\label{fig:plottrigism}Pairwise depiction of Gislason's second natural mortality model estimates using a `t' family elliptic copula and triangle distribution margins.}
\end{figure}

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/plottrigismhist-1.png}
\caption{\label{fig:plottrigismhist}Marginal distributions of the parameters for Gislason's second natural mortality model using triangle distributions.}
\end{figure}

We now have a new model that can be used for the \texttt{shape} model. You can use the constructor or the set method to add the new model. Note that we have a quite complex method now for M. A length based \texttt{shape} model from Gislason's work, Jensen's third model based on temperature \texttt{level} and a time \texttt{trend} depending on NAO. All of the component models have uncertainty in their parameters.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{m5 }\OtherTok{\textless{}{-}} \FunctionTok{a4aM}\NormalTok{(}\AttributeTok{shape=}\NormalTok{mgis2, }\AttributeTok{level=}\NormalTok{level4, }\AttributeTok{trend=}\NormalTok{trend4)}
\CommentTok{\# or}
\NormalTok{m5 }\OtherTok{\textless{}{-}}\NormalTok{ m4}
\FunctionTok{shape}\NormalTok{(m5) }\OtherTok{\textless{}{-}}\NormalTok{ mgis2}
\end{Highlighting}
\end{Shaded}

\hypertarget{computing-natural-mortality-time-series---the-m-method}{%
\section{\texorpdfstring{Computing natural mortality time series - the \texttt{m()} method}{Computing natural mortality time series - the m() method}}\label{computing-natural-mortality-time-series---the-m-method}}

Now that we have set up the natural mortality \texttt{a4aM} model and added parameter uncertainty to each component, we are ready to generate the \texttt{FLQuant} of natural mortality with \texttt{m()}. The \texttt{m()} method is the workhorse method for computing natural mortality. The method returns a \texttt{FLQuant} that can be inserted in an \texttt{FLStock} to be used in the assessment method.

The size of the \texttt{FLQuant} object is determined by the \texttt{min}, \texttt{max}, \texttt{minyear} and \texttt{maxyear} elements of the \texttt{range} slot of the \texttt{a4aM} object. By default the values of these elements are set to 0, which generates a \texttt{FLQuant} with length 1 in the \texttt{quant} and \texttt{year} dimension. The \texttt{range} slot can be set by hand, or by using the \texttt{rngquant()} and \texttt{rngyear()} methods.

The name of the first dimension of the output \texttt{FLQuant} (e.g.~`age' or `len') is determined by the parameters of the \texttt{shape} model. If it is not clear what the name should be then the name is set to `quant'.

Here we demonstrate \texttt{m()} using the simple \texttt{a4aM} object we created above that has constant natural mortality.

Start with the simplest model:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{m1}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## a4aM object:
##   shape: ~1
##   level: ~a
##   trend: ~1
\end{verbatim}

Check the range:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{range}\NormalTok{(m1)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##       min       max plusgroup   minyear   maxyear   minmbar   maxmbar 
##         0         0         0         0         0         0         0
\end{verbatim}

The \(M\) \texttt{FLQuant} won't have ages or years:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{m}\NormalTok{(m1)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## An object of class "FLQuant"
## , , unit = unique, season = all, area = unique
## 
##      year
## quant 0  
##     0 0.2
## 
## units:  NA
\end{verbatim}

To have a more useful matrix of values that cover the ages and years in the \texttt{FLStock} object, the analyst needs to set the quant and year ranges.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# set the quant range}
\FunctionTok{range}\NormalTok{(m1, }\FunctionTok{c}\NormalTok{(}\StringTok{"min"}\NormalTok{,}\StringTok{"max"}\NormalTok{)) }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{7}\NormalTok{)}
\CommentTok{\# set the year range}
\FunctionTok{range}\NormalTok{(m1, }\FunctionTok{c}\NormalTok{(}\StringTok{"minyear"}\NormalTok{,}\StringTok{"maxyear"}\NormalTok{)) }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{2000}\NormalTok{, }\DecValTok{2010}\NormalTok{)}
\FunctionTok{range}\NormalTok{(m1)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##       min       max plusgroup   minyear   maxyear   minmbar   maxmbar 
##         0         7         0      2000      2010         0         0
\end{verbatim}

Create the object with the M estimates by age and year, note the name of the first dimension is `quant'.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{m}\NormalTok{(m1)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## An object of class "FLQuant"
## , , unit = unique, season = all, area = unique
## 
##      year
## quant 2000 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010
##     0 0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2 
##     1 0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2 
##     2 0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2 
##     3 0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2 
##     4 0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2 
##     5 0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2 
##     6 0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2 
##     7 0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2  0.2 
## 
## units:  NA
\end{verbatim}

The next example has an age-based shape (model ``m2'' from above). As the \texttt{shape} model has `age' as a variable which is not included in the \texttt{FLPar} slot it is used as the name of the first dimension of the resulting \texttt{FLQuant}.

An important feature of the \texttt{m()} method is the use of the \texttt{level} model. The outcome of the \texttt{level} model will be applied to a range of ages or lengths, set by the \texttt{mbar} information in the range slot. In this example the level model is \(1.5*K\) and since \(K=0.4\), the level predicted by the model will be \(0.6\). The \texttt{m()} model will use the information in the range, \texttt{minmbar} and \texttt{maxmbar} to compute the mean level. This mean level will match the value given by the \texttt{level} model. The \texttt{mbar} range can be changed with the \texttt{rngmbar()} method. We illustrate this by making an \texttt{FLQuant} with age varying natural mortality.

Check the model and set the ranges:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{m2}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## a4aM object:
##   shape: ~exp(-age - 0.5)
##   level: ~1.5 * k
##   trend: ~1
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# set the quant range}
\FunctionTok{range}\NormalTok{(m2, }\FunctionTok{c}\NormalTok{(}\StringTok{"min"}\NormalTok{,}\StringTok{"max"}\NormalTok{)) }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{7}\NormalTok{)}
\CommentTok{\# set the year range}
\FunctionTok{range}\NormalTok{(m2, }\FunctionTok{c}\NormalTok{(}\StringTok{"minyear"}\NormalTok{,}\StringTok{"maxyear"}\NormalTok{)) }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{2000}\NormalTok{, }\DecValTok{2003}\NormalTok{)}
\FunctionTok{range}\NormalTok{(m2)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##       min       max plusgroup   minyear   maxyear   minmbar   maxmbar 
##         0         7         0      2000      2003         0         0
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{m}\NormalTok{(m2)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## An object of class "FLQuant"
## , , unit = unique, season = all, area = unique
## 
##    year
## age 2000     2001     2002     2003    
##   0 0.600000 0.600000 0.600000 0.600000
##   1 0.220728 0.220728 0.220728 0.220728
##   2 0.081201 0.081201 0.081201 0.081201
##   3 0.029872 0.029872 0.029872 0.029872
##   4 0.010989 0.010989 0.010989 0.010989
##   5 0.004043 0.004043 0.004043 0.004043
##   6 0.001487 0.001487 0.001487 0.001487
##   7 0.000547 0.000547 0.000547 0.000547
## 
## units:  NA
\end{verbatim}

Note that the level value is:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{predict}\NormalTok{(}\FunctionTok{level}\NormalTok{(m2))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    iter
##       1
##   1 0.6
\end{verbatim}

Which is the same as:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{m}\NormalTok{(m2)[}\StringTok{"0"}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## An object of class "FLQuant"
## , , unit = unique, season = all, area = unique
## 
##    year
## age 2000 2001 2002 2003
##   0 0.6  0.6  0.6  0.6 
## 
## units:  NA
\end{verbatim}

This is because the \texttt{mbar} range is currently set to ``0'' and ``0'' (see above) and the mean natural mortality value over this range is given by the level model.

We can change the \texttt{mbar} range:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{range}\NormalTok{(m2, }\FunctionTok{c}\NormalTok{(}\StringTok{"minmbar"}\NormalTok{,}\StringTok{"maxmbar"}\NormalTok{)) }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{5}\NormalTok{)}
\FunctionTok{range}\NormalTok{(m2)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##       min       max plusgroup   minyear   maxyear   minmbar   maxmbar 
##         0         7         0      2000      2003         0         5
\end{verbatim}

Which rescales the the natural mortality at age:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{m}\NormalTok{(m2)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## An object of class "FLQuant"
## , , unit = unique, season = all, area = unique
## 
##    year
## age 2000    2001    2002    2003   
##   0 2.28129 2.28129 2.28129 2.28129
##   1 0.83924 0.83924 0.83924 0.83924
##   2 0.30874 0.30874 0.30874 0.30874
##   3 0.11358 0.11358 0.11358 0.11358
##   4 0.04178 0.04178 0.04178 0.04178
##   5 0.01537 0.01537 0.01537 0.01537
##   6 0.00565 0.00565 0.00565 0.00565
##   7 0.00208 0.00208 0.00208 0.00208
## 
## units:  NA
\end{verbatim}

Check that the mortality over the mean range is the same as the level model:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{quantMeans}\NormalTok{(}\FunctionTok{m}\NormalTok{(m2)[}\FunctionTok{ac}\NormalTok{(}\DecValTok{0}\SpecialCharTok{:}\DecValTok{5}\NormalTok{)])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## An object of class "FLQuant"
## , , unit = unique, season = all, area = unique
## 
##      year
## age   2000 2001 2002 2003
##   all 0.6  0.6  0.6  0.6 
## 
## units:  NA
\end{verbatim}

The next example uses a time trend for the \texttt{trend} model. We use the \texttt{m3} model we made earlier. The \texttt{trend} model for this model has a covariate, `nao'. This needs to be passed to the \texttt{m()} method. The year range of the `nao' covariate should match that of the \texttt{range} slot.

Simple, pass in a single nao value (only one year):

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{m}\NormalTok{(m3, }\AttributeTok{nao=}\DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## An object of class "FLQuant"
## , , unit = unique, season = all, area = unique
## 
##    year
## age 0  
##   0 0.9
## 
## units:  NA
\end{verbatim}

Set ages:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{range}\NormalTok{(m3, }\FunctionTok{c}\NormalTok{(}\StringTok{"min"}\NormalTok{,}\StringTok{"max"}\NormalTok{)) }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{7}\NormalTok{)}
\FunctionTok{m}\NormalTok{(m3, }\AttributeTok{nao=}\DecValTok{0}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## An object of class "FLQuant"
## , , unit = unique, season = all, area = unique
## 
##    year
## age 0       
##   0 0.600000
##   1 0.220728
##   2 0.081201
##   3 0.029872
##   4 0.010989
##   5 0.004043
##   6 0.001487
##   7 0.000547
## 
## units:  NA
\end{verbatim}

With ages and years - passing in the NAO data as numeric (1,0,1,0)

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{range}\NormalTok{(m3, }\FunctionTok{c}\NormalTok{(}\StringTok{"minyear"}\NormalTok{,}\StringTok{"maxyear"}\NormalTok{)) }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{2000}\NormalTok{, }\DecValTok{2003}\NormalTok{)}
\FunctionTok{m}\NormalTok{(m3, }\AttributeTok{nao=}\FunctionTok{as.numeric}\NormalTok{(nao[,}\FunctionTok{as.character}\NormalTok{(}\DecValTok{2000}\SpecialCharTok{:}\DecValTok{2003}\NormalTok{)]))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## An object of class "FLQuant"
## , , unit = unique, season = all, area = unique
## 
##    year
## age 2000     2001     2002     2003    
##   0 0.600000 0.900000 0.600000 0.900000
##   1 0.220728 0.331091 0.220728 0.331091
##   2 0.081201 0.121802 0.081201 0.121802
##   3 0.029872 0.044808 0.029872 0.044808
##   4 0.010989 0.016484 0.010989 0.016484
##   5 0.004043 0.006064 0.004043 0.006064
##   6 0.001487 0.002231 0.001487 0.002231
##   7 0.000547 0.000821 0.000547 0.000821
## 
## units:  NA
\end{verbatim}

The final example show how \texttt{m()} can be used to make an \texttt{FLQuant} with uncertainty (see Figure \ref{fig:uncertainm}). We use the \texttt{m4} object from earlier with uncertainty on the \texttt{level} and \texttt{trend} parameters.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{range}\NormalTok{(m4, }\FunctionTok{c}\NormalTok{(}\StringTok{"min"}\NormalTok{,}\StringTok{"max"}\NormalTok{)) }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{7}\NormalTok{)}
\FunctionTok{range}\NormalTok{(m4, }\FunctionTok{c}\NormalTok{(}\StringTok{"minyear"}\NormalTok{,}\StringTok{"maxyear"}\NormalTok{)) }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{2000}\NormalTok{, }\DecValTok{2003}\NormalTok{)}
\NormalTok{flq }\OtherTok{\textless{}{-}} \FunctionTok{m}\NormalTok{(m4, }\AttributeTok{nao=}\FunctionTok{c}\NormalTok{(nao[,}\FunctionTok{ac}\NormalTok{(}\DecValTok{2000}\SpecialCharTok{:}\DecValTok{2003}\NormalTok{)]))}
\NormalTok{flq}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## An object of class "FLQuant"
## iters:  100 
## 
## , , unit = unique, season = all, area = unique
## 
##    year
## age 2000              2001              2002              2003             
##   0 2.02791(0.188200) 3.07211(0.389155) 2.02791(0.188200) 3.07211(0.389155)
##   1 0.74603(0.069235) 1.13017(0.143162) 0.74603(0.069235) 1.13017(0.143162)
##   2 0.27445(0.025470) 0.41577(0.052666) 0.27445(0.025470) 0.41577(0.052666)
##   3 0.10096(0.009370) 0.15295(0.019375) 0.10096(0.009370) 0.15295(0.019375)
##   4 0.03714(0.003447) 0.05627(0.007128) 0.03714(0.003447) 0.05627(0.007128)
##   5 0.01366(0.001268) 0.02070(0.002622) 0.01366(0.001268) 0.02070(0.002622)
##   6 0.00503(0.000467) 0.00762(0.000965) 0.00503(0.000467) 0.00762(0.000965)
##   7 0.00185(0.000172) 0.00280(0.000355) 0.00185(0.000172) 0.00280(0.000355)
## 
## units:  NA
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{dim}\NormalTok{(flq)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1]   8   4   1   1   1 100
\end{verbatim}

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/uncertainm-1.png}
\caption{\label{fig:uncertainm}Natural mortality with age and year trend.}
\end{figure}

Notably, the last example created a M model that varies with time, based on an environmental variable, and adds estimation uncertainty, showing the huge flexibility this method can deal with.

\hypertarget{stock-assessment-framework}{%
\chapter{Stock assessment framework}\label{stock-assessment-framework}}

\hypertarget{maths-description}{%
\section{\texorpdfstring{Maths description \label{sec:math}}{Maths description }}\label{maths-description}}

The stock assessment model is based on two types of observations: catches, \(\hat{C}\), and abundance indices, \(\hat{I}\). The model predicts catches at age \(C_{ay}\) and indices of abundance \(I_{ays}\) for each age \(a\), year \(y\) and survey \(s\) in the input dataset. To predict catches and survey indices, the model uses the standard population dynamics model

\begin{equation}
N_{a+1,y+1} = N_{ay} \exp \left( - F_{ay} - M_{ay} \right)
\end{equation}

where \(N_{ay}\) is the number of individuals at age \(a\) in year \(y\), \(F_{ay}\) is the fishing mortality at age \(a\) in year \(y\), and \(M_{ay}\) is the natural mortality at age \(a\) in year \(y\). Any fish that survived beyond the oldest age \(A\) in the model are accumulated in the oldest age group and are assumed to be fished at a common rate \(F_{A,y}\).

\begin{align}
N_{A,y+1} = &N_{A-1,y} \exp \left( - F_{A-1,y} - M_{A-1,y} \right) \\
            &+ N_{A,y} \exp \left( - F_{A,y} - M_{A,y} \right)
\end{align}

The numbers \(N_{a,y}\) are initiated in the first year, \(y=1\) and at the youngest age, \(a=1\), and the matrix of numbers at age are filled in according to the population dynamics model stated above (see Figure \ref{fig:popdyn}).

\begin{figure}

{\centering \includegraphics[width=0.4\linewidth]{figure/sca_matrix} 

}

\caption{Statistical catch at age population dynamics model}\label{fig:popdyn}
\end{figure}

Defining \(R_y = N_{1,y}\), the numbers at age can be written (ignoring the plus group) as:

\begin{equation}
	N_{a,y} = \left\{ 
	\begin{matrix} 
		R_{y-a+1} \exp \left( - \sum^a_{i=1} \left( F_{a-i,y-i} + M_{a-i,y-i} \right) \right) & y \geq a \\
		N_{a-y+1,1} \exp \left( - \sum^{a-y}_{i=1} \left( F_{a-i,y-i} + M_{a-i,y-i} \right) \right) & y < a 
	\end{matrix} 
	\right.
\end{equation}

Catches in numbers by age and year are defined in terms of the three quantities: natural mortality, fishing mortality and recruitment; using a modified form of the well known Baranov catch equation:

\begin{equation}
C_{ay} = \frac{F_{ay}}{F_{ay}+M_{ay}}\left(1 - e^{-(F_{ay}+M_{ay})}\right) R_{y}e^{-\sum (F_{ay} + M_{ay})}
\end{equation}

Survey indices by age and year are defined in terms of the same three quantities with the addition of survey catchability:

\begin{equation}
I_{ays} = Q_{ays} R_{y}e^{-\sum (F_{ay} + M_{ay})}
\end{equation}

It is assumed that the observed catches are normally distributed about the model predictions on the log scale with observation variance \(\sigma^2_{ay}\). that is:

\begin{equation}
\log \hat{C}_{ay} \sim \text{Normal} \Big( \log C_{ay}, \sigma^2_{ay}\Big)
\end{equation}

\begin{equation}
\log \hat{I}_{ays} \sim \text{Normal} \Big( \log I_{ays}, \tau^2_{ays} \Big)
\end{equation}

The log-likelihood can now be defined as the sum of the log-likelihood of the observed catches:

\begin{equation}
\ell_C = \sum_{ay} w^{(c)}_{ay}\ \ell_N \Big( \log C_{ay}, \sigma^2_{ay} ;\ \log \hat{C}_{ay} \Big)
\end{equation}

and the log-likelihood of the observed survey indices as:

\begin{equation}
\ell_I = \sum_s \sum_{ay} w^{(s)}_{ays}\ \ell_N \Big( \log I_{ays}, \tau_{ays}^2 ;\ \log \hat{I}_{ays} \Big)
\end{equation}

giving the total log-likelihood

\begin{equation}
\ell = \ell_C + \ell_I
\end{equation}

which is defined in terms of the strictly positive quantities, \(M_{ay}\), \(F_{ay}\), \(Q_{ays}\) and \(R_{y}\), and the observation variances \(\sigma_{ay}\) and \(\tau_{ays}\). As such, the log-likelihood is over-parameterised as there are many more parameters than observations. In order to reduce the number of parameters, \(M_{ay}\) is assumed known (as is common).

The remaining parameters are written in terms of a linear combination of covariates \(x_{ayk}\), e.g.

\begin{equation}
\log F_{ay} = \sum_k \beta_k x_{ayk}
\end{equation}

where \(k\) is the number of parameters to be estimated and is sufficiently small. Using this technique the quantities \(\log F\), \(\log Q\), \(\log \sigma\) and \(\log \tau\) can be described by a reduced number of parameters.

The a4a statistical catch-at-age model can additionally allow for a functional relationship that links predicted recruitment \(\tilde{R}\) based on spawning stock biomass and modelled recruitment \(R\), to be imposed as a fixed variance random effect.

Options for the relationship are the hard coded models Ricker, Beverton Holt, smooth hockey-stick or geometric mean. This is implemented by including a third component in the log-likelihood:

\begin{equation}
\ell_{SR} = \sum_y \ell_N \Big( \log \tilde{R}_y(a, b), \phi_y^2 ;\ \log R_y \Big)
\end{equation}

giving the total log-likelihood

\begin{equation}
\ell = \ell_C + \ell_I + \ell_{SR}
\end{equation}

Using the (time varying) Ricker model as an example, predicted recruitment is

\begin{equation}
\tilde{R}_y(a_y,b_y) = a_y S_{y-1} e^{-b_y S_{y-1}}
\end{equation}

where \(S\) is spawning stock biomass derived from the model parameters \(F\) and \(R\), and the fixed quantities \(M\) and mean weights by year and age. It is assumed that \(R\) is log-normally distributed, or equivalently, normally distributed on the log-scale about the (log) recruitment predicted by the SR model \(\tilde{R}\), with known variance \(\phi^2\), i.e.

\begin{equation}
\log R_y \sim \text{Normal} \Big( \log \tilde{R}_y, \phi_y^2 \Big)
\end{equation}

which leads to the definition of \(\ell_{SR}\) given above. In all cases \(a\) and \(b\) are strictly positive, and with the quantities \(F\), \(R\), etc. linear models are used to parameterise \(\log a\) and/or \(\log b\), where relevant.

By default, recruitment \(R\) as apposed to the recruitment predicted from a stock recruitment model \(\tilde{R}\), is specified as a linear model with a parameter for each year, i.e.

\begin{equation}
\log R_y = \gamma_y
\end{equation}

This is to allow modelled recruitment \(R_y\) to be shrunk towards the stock recruitment model. However, if it is considered appropriate that recruitment can be determined exactly by a relationship with covariates, it is possible, to instead define \(\log R\) in terms of a linear model in the same way as \(\log F\), \(\log Q\), \(\log \sigma\) and \(\log \tau\). \%But this is pretty much the same as taking a geometric mean, with a model on log a, and making the variance very small.

\hypertarget{model-structure}{%
\section{\texorpdfstring{Model structure \label{sec:submod}}{Model structure }}\label{model-structure}}

The \texttt{a4a} stock assessment framework allows the user to set up a large number of different models. The mechanics which provide this flexibility are designed around the concept of submodels. The user has to define the model structure using \texttt{R} formulas, including \texttt{mgcv} (\protect\hyperlink{ref-R-mgcv}{S. N. Wood 2011}) gam formulas, for each unknown variable that must be estimated. By using \texttt{R} formulas the stock assessment framework gives lot's of flexibility to explore models and combinations of submodels.

There are 5 submodels in operation:

\begin{itemize}
\tightlist
\item
  a model for F-at-age (\(F_{ay}\))
\item
  a (list) of model(s) for abundance indices catchability-at-age (\(Q_{ays}\)),
\item
  a model for recruitment (\(R_y\))
\item
  a list of models for the observation variance of catch-at-age and abundance indices (\(\{\sigma^2_{ay}, \tau^2_{ays}\}\))
\item
  a model for the initial age structure (\(N_{a,y=1}\))
\end{itemize}

When setting the structure of each submodel the user is in fact building the predictive model and its parameters. The optimization process, done through \texttt{ADMB}, estimates the parameters and their variance-covariance matrix, allowing further analysis to be carried out, like simulation, prediction, diagnostics, etc. All the statistical machinery will be at the user's reach.

The framework's workhorse is the method \texttt{sca}, which is called over \texttt{FLStock} and \texttt{FLIndex} or \texttt{FLIndices} objects. The following code shows an example of a call to \texttt{sca()}.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# fit a model with a single index}
\NormalTok{fit }\OtherTok{\textless{}{-}} \FunctionTok{sca}\NormalTok{(ple4, ple4.index,}
    \AttributeTok{fmodel =} \SpecialCharTok{\textasciitilde{}} \FunctionTok{s}\NormalTok{(age, }\AttributeTok{k =} \DecValTok{5}\NormalTok{),}
    \AttributeTok{qmodel =} \FunctionTok{list}\NormalTok{(}\SpecialCharTok{\textasciitilde{}} \FunctionTok{s}\NormalTok{(age, }\AttributeTok{k =} \DecValTok{4}\NormalTok{)),}
    \AttributeTok{srmodel =} \SpecialCharTok{\textasciitilde{}} \DecValTok{1}\NormalTok{,}
    \AttributeTok{n1model =} \SpecialCharTok{\textasciitilde{}} \FunctionTok{s}\NormalTok{(age, }\AttributeTok{k =} \DecValTok{5}\NormalTok{),}
    \AttributeTok{vmodel =} \FunctionTok{list}\NormalTok{( }\SpecialCharTok{\textasciitilde{}} \DecValTok{1}\NormalTok{, }\SpecialCharTok{\textasciitilde{}} \DecValTok{1}\NormalTok{))}
\CommentTok{\# check output}
\NormalTok{fit}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## a4a model fit for: PLE 
## 
## Call:
## .local(stock = stock, indices = indices, fmodel = ..1, qmodel = ..2, 
##     srmodel = ..3, n1model = ..4, vmodel = ..5)
## 
## Time used:
##  Pre-processing     Running a4a Post-processing           Total 
##       0.3013997       0.2656412       0.1012204       0.6682613 
## 
## Submodels:
##   fmodel: ~s(age, k = 5)
##  srmodel: ~1
##  n1model: ~s(age, k = 5)
##   qmodel:
##     IND: ~s(age, k = 4)
##   vmodel:
##     catch: ~1
##     IND:   ~1
\end{verbatim}

The \texttt{sca()} method arguments are shown in Table \ref{tab:scaargs}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.2105}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.2105}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.5789}}@{}}
\caption{\label{tab:scaargs} \texttt{sca()} arguments}\tabularnewline
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Argument
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Default
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Description
\end{minipage} \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Argument
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Default
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Description
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\texttt{stock} & \texttt{missing} & \texttt{FLStock} object containing catch and stock information \\
\texttt{indices} & \texttt{missing} & \texttt{FLIndices} object containing survey indices \\
\texttt{fmodel} & \texttt{missing} & a formula object depicting the model for log fishing mortality at age \\
\texttt{qmodel} & \texttt{missing} & a list of formula objects depicting the models for log survey catchability at age \\
\texttt{srmodel} & \texttt{missing} & a formula object depicting the model for log recruitment \\
\texttt{n1model} & \texttt{missing} & a formula object depicting the model for the population in the first year of the time series \\
\texttt{vmodel} & \texttt{missing} & a list of formula objects depicting the model for the variance of fishing mortality and the indices \\
\texttt{covar} & \texttt{missing} & a list with covariates to be used by the submodels. The formula must have an element with the same name as the list element \\
\texttt{wkdir} & \texttt{missing} & used to set a working directory for the admb optimiser; if \texttt{wkdir} is set, all admb files are saved to this folder, otherwise they are deleted \\
\texttt{verbose} & \texttt{FALSE} & if \texttt{TRUE}, admb fitting information is printed to the screen \\
\texttt{fit} & \texttt{assessment} & character with type of fit: \texttt{assessment} (ML estimation, returns covariance matrix), \texttt{MP} (ML estimation, doesn't compute covariance matrix) or \texttt{MCMC} (MCMC estimation) \\
\texttt{center} & \texttt{TRUE} & logical defining if the data should be centered before fitting \\
\texttt{mcmc} & \texttt{missing} & a \texttt{SCAMCMC} object with the arguments to run MCMC fits (\texttt{fit=MCMC}) \\
\end{longtable}

\hypertarget{submodel-building-blocks-and-fundamental-r-formulas}{%
\section{\texorpdfstring{Submodel building blocks and fundamental \texttt{R} formulas}{Submodel building blocks and fundamental R formulas}}\label{submodel-building-blocks-and-fundamental-r-formulas}}

The elements available to build submodels formulas are `age' and `year', which can be used to build models with different structures.

In R's modelling language, a constant model is coded as \texttt{\textasciitilde{}1}, while a slope over time would simply be \texttt{\textasciitilde{}year}, a smoother over time \texttt{\textasciitilde{}s(year,\ k=10)}, a model with a coefficient for each year would be \texttt{\textasciitilde{}factor(year)}. Transformations of the variables are as usual, e.g.~\texttt{sqrt(year)}, etc; while combinations of all the above can be done although non-convergence will limit the possibilities.

Using the \(F\) submodel as example the following specifies the models described in the previous paragraph, see Figure \ref{fig:fundforms}.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# models}
\NormalTok{m1 }\OtherTok{\textless{}{-}} \ErrorTok{\textasciitilde{}}\DecValTok{1}
\NormalTok{m2 }\OtherTok{\textless{}{-}} \ErrorTok{\textasciitilde{}}\NormalTok{ year}
\NormalTok{m3 }\OtherTok{\textless{}{-}} \ErrorTok{\textasciitilde{}} \FunctionTok{s}\NormalTok{(year, }\AttributeTok{k=}\DecValTok{10}\NormalTok{)}
\NormalTok{m4 }\OtherTok{\textless{}{-}} \ErrorTok{\textasciitilde{}} \FunctionTok{factor}\NormalTok{(year)}
\NormalTok{m5 }\OtherTok{\textless{}{-}} \ErrorTok{\textasciitilde{}} \FunctionTok{sqrt}\NormalTok{(year)}

\CommentTok{\# fits}
\NormalTok{fit1 }\OtherTok{\textless{}{-}} \FunctionTok{sca}\NormalTok{(ple4, ple4.indices, }\AttributeTok{fmodel=}\NormalTok{m1, }\AttributeTok{fit=}\StringTok{"MP"}\NormalTok{)}
\NormalTok{fit2 }\OtherTok{\textless{}{-}} \FunctionTok{sca}\NormalTok{(ple4, ple4.indices, }\AttributeTok{fmodel=}\NormalTok{m2, }\AttributeTok{fit=}\StringTok{"MP"}\NormalTok{)}
\NormalTok{fit3 }\OtherTok{\textless{}{-}} \FunctionTok{sca}\NormalTok{(ple4, ple4.indices, }\AttributeTok{fmodel=}\NormalTok{m3, }\AttributeTok{fit=}\StringTok{"MP"}\NormalTok{)}
\NormalTok{fit4 }\OtherTok{\textless{}{-}} \FunctionTok{sca}\NormalTok{(ple4, ple4.indices, }\AttributeTok{fmodel=}\NormalTok{m4, }\AttributeTok{fit=}\StringTok{"MP"}\NormalTok{)}
\NormalTok{fit5 }\OtherTok{\textless{}{-}} \FunctionTok{sca}\NormalTok{(ple4, ple4.indices, }\AttributeTok{fmodel=}\NormalTok{m5, }\AttributeTok{fit=}\StringTok{"MP"}\NormalTok{)}

\CommentTok{\# plot}
\NormalTok{lst }\OtherTok{\textless{}{-}} \FunctionTok{FLStocks}\NormalTok{(}\AttributeTok{constant=}\NormalTok{ple4}\SpecialCharTok{+}\NormalTok{fit1,}
  \AttributeTok{linear=}\NormalTok{ple4}\SpecialCharTok{+}\NormalTok{fit2,}
  \AttributeTok{smooth=}\NormalTok{ple4}\SpecialCharTok{+}\NormalTok{fit3,}
  \AttributeTok{factor=}\NormalTok{ple4}\SpecialCharTok{+}\NormalTok{fit4,}
  \AttributeTok{sqrt=}\NormalTok{ple4}\SpecialCharTok{+}\NormalTok{fit5)}
\NormalTok{lst }\OtherTok{\textless{}{-}} \FunctionTok{lapply}\NormalTok{(lst, fbar)}
\NormalTok{lgnd }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{(}\AttributeTok{points=}\ConstantTok{FALSE}\NormalTok{, }\AttributeTok{lines=}\ConstantTok{TRUE}\NormalTok{, }\AttributeTok{space=}\StringTok{\textquotesingle{}right\textquotesingle{}}\NormalTok{)}
\FunctionTok{xyplot}\NormalTok{(data}\SpecialCharTok{\textasciitilde{}}\NormalTok{year, }\AttributeTok{groups=}\NormalTok{qname, lst, }\AttributeTok{auto.key=}\NormalTok{lgnd, }\AttributeTok{type=}\StringTok{\textquotesingle{}l\textquotesingle{}}\NormalTok{, }\AttributeTok{ylab=}\StringTok{\textquotesingle{}fishing mortality\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/fundforms-1.png}
\caption{\label{fig:fundforms}Example of fundamental R formulas used to model the year effect}
\end{figure}

The models above and their combinations can be used to model both \texttt{age} and \texttt{year}. The corresponding fits for age are show in the code below and Figure \ref{fig:fundformsage}.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# models}
\NormalTok{m1 }\OtherTok{\textless{}{-}} \ErrorTok{\textasciitilde{}}\DecValTok{1}
\NormalTok{m2 }\OtherTok{\textless{}{-}} \ErrorTok{\textasciitilde{}}\NormalTok{ age}
\NormalTok{m3 }\OtherTok{\textless{}{-}} \ErrorTok{\textasciitilde{}} \FunctionTok{s}\NormalTok{(age, }\AttributeTok{k=}\DecValTok{3}\NormalTok{)}
\NormalTok{m4 }\OtherTok{\textless{}{-}} \ErrorTok{\textasciitilde{}} \FunctionTok{factor}\NormalTok{(age)}
\NormalTok{m5 }\OtherTok{\textless{}{-}} \ErrorTok{\textasciitilde{}} \FunctionTok{sqrt}\NormalTok{(age)}

\CommentTok{\# fits}
\NormalTok{fit1 }\OtherTok{\textless{}{-}} \FunctionTok{sca}\NormalTok{(ple4, ple4.indices, }\AttributeTok{fmodel=}\NormalTok{m1, }\AttributeTok{fit=}\StringTok{"MP"}\NormalTok{)}
\NormalTok{fit2 }\OtherTok{\textless{}{-}} \FunctionTok{sca}\NormalTok{(ple4, ple4.indices, }\AttributeTok{fmodel=}\NormalTok{m2, }\AttributeTok{fit=}\StringTok{"MP"}\NormalTok{)}
\NormalTok{fit3 }\OtherTok{\textless{}{-}} \FunctionTok{sca}\NormalTok{(ple4, ple4.indices, }\AttributeTok{fmodel=}\NormalTok{m3, }\AttributeTok{fit=}\StringTok{"MP"}\NormalTok{)}
\NormalTok{fit4 }\OtherTok{\textless{}{-}} \FunctionTok{sca}\NormalTok{(ple4, ple4.indices, }\AttributeTok{fmodel=}\NormalTok{m4, }\AttributeTok{fit=}\StringTok{"MP"}\NormalTok{)}
\NormalTok{fit5 }\OtherTok{\textless{}{-}} \FunctionTok{sca}\NormalTok{(ple4, ple4.indices, }\AttributeTok{fmodel=}\NormalTok{m5, }\AttributeTok{fit=}\StringTok{"MP"}\NormalTok{)}

\CommentTok{\# plot}
\NormalTok{lst }\OtherTok{\textless{}{-}} \FunctionTok{FLStocks}\NormalTok{(}\AttributeTok{constant=}\NormalTok{ple4}\SpecialCharTok{+}\NormalTok{fit1,}
  \AttributeTok{linear=}\NormalTok{ple4}\SpecialCharTok{+}\NormalTok{fit2,}
  \AttributeTok{smooth=}\NormalTok{ple4}\SpecialCharTok{+}\NormalTok{fit3,}
  \AttributeTok{factor=}\NormalTok{ple4}\SpecialCharTok{+}\NormalTok{fit4,}
  \AttributeTok{sqrt=}\NormalTok{ple4}\SpecialCharTok{+}\NormalTok{fit5)}
\NormalTok{lst }\OtherTok{\textless{}{-}} \FunctionTok{lapply}\NormalTok{(lst, }\ControlFlowTok{function}\NormalTok{(x) }\FunctionTok{harvest}\NormalTok{(x)[,}\StringTok{\textquotesingle{}2000\textquotesingle{}}\NormalTok{])}
\FunctionTok{xyplot}\NormalTok{(data}\SpecialCharTok{\textasciitilde{}}\NormalTok{age, }\AttributeTok{groups=}\NormalTok{qname, lst, }\AttributeTok{auto.key=}\NormalTok{lgnd, }\AttributeTok{type=}\StringTok{\textquotesingle{}l\textquotesingle{}}\NormalTok{, }\AttributeTok{ylab=}\StringTok{\textquotesingle{}fishing mortality in 2000\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/fundformsage-1.png}
\caption{\label{fig:fundformsage}Example of fundamental R formulas used to model the age effect}
\end{figure}

\hypertarget{the-major-effects-available-for-modelling}{%
\section{The major effects available for modelling}\label{the-major-effects-available-for-modelling}}

Although the building blocks for formulas are \texttt{age} and \texttt{year}, in fact there are three effects that can be modelled for each submodel: \texttt{age}, \texttt{year} and \texttt{cohort}. As examples note the following models for fishing mortality.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# the age effect}
\NormalTok{ageeffect }\OtherTok{\textless{}{-}} \ErrorTok{\textasciitilde{}} \FunctionTok{factor}\NormalTok{(age)}

\CommentTok{\# the year effect}
\NormalTok{yeareffect }\OtherTok{\textless{}{-}} \ErrorTok{\textasciitilde{}} \FunctionTok{factor}\NormalTok{(year)}

\CommentTok{\# the cohort}
\NormalTok{cohorteffect }\OtherTok{\textless{}{-}} \ErrorTok{\textasciitilde{}} \FunctionTok{factor}\NormalTok{(year}\SpecialCharTok{{-}}\NormalTok{age)}

\CommentTok{\# the fits}
\NormalTok{fit1 }\OtherTok{\textless{}{-}} \FunctionTok{sca}\NormalTok{(ple4, ple4.indices, }\AttributeTok{fmodel=}\NormalTok{yeareffect)}
\NormalTok{fit2 }\OtherTok{\textless{}{-}} \FunctionTok{sca}\NormalTok{(ple4, ple4.indices, }\AttributeTok{fmodel=}\NormalTok{ageeffect)}
\NormalTok{fit3 }\OtherTok{\textless{}{-}} \FunctionTok{sca}\NormalTok{(ple4, ple4.indices, }\AttributeTok{fmodel=}\NormalTok{cohorteffect)}
\end{Highlighting}
\end{Shaded}

and the graphical representation of the three models in Figures \ref{fig:majeffy} to \ref{fig:majeffc}.

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/majeffy-1.png}
\caption{\label{fig:majeffy}Major effects: the year effect (\textasciitilde{} factor(year))}
\end{figure}

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/majeffa-1.png}
\caption{\label{fig:majeffa}Major effects: the age effect (\textasciitilde{} factor(age))}
\end{figure}

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/majeffc-1.png}
\caption{\label{fig:majeffc}Major effects: the cohort effect (\textasciitilde{} factor(year-age))}
\end{figure}

\hypertarget{classes-description}{%
\section{\texorpdfstring{Classes Description \label{sec:classes}}{Classes Description }}\label{classes-description}}

The data structure used to store and report the fitting process follows an object-oriented paradigm (e.g.~the S4 system in R) and is hierarchically organized. The \texttt{type} argument in the \texttt{sca} method defines the fitting method - either maximum likelihood or MCMC - and specifies whether the variance-covariance matrix of the parameters is calculated and returned in the case of maximum likelihood. The resulting object belongs to a specific class, depending on the selected option. Figure \ref{fig:iomod} illustrates the input/output model of the statistical stock assessment method based on catch-at-age data.

\begin{figure}

{\centering \includegraphics[width=1.2\linewidth]{figure/scamethod} 

}

\caption{The fit process input/output model}\label{fig:iomod}
\end{figure}

Table \ref{tab:scatype} provides details about the type of fit approach and computation of variance covariance information.

\begin{longtable}[]{@{}llll@{}}
\caption{\label{tab:scatype} Fit Types and Associated Classes}\tabularnewline
\toprule\noalign{}
Type of Fit & Fit Method & Variance-Covariance Matrix & Output Object Class \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
Type of Fit & Fit Method & Variance-Covariance Matrix & Output Object Class \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\texttt{MP} & Maximum Likelihood & No & \texttt{a4aFit} \\
\texttt{assessment} & Maximum Likelihood & Yes & \texttt{a4aFitSA} \\
\texttt{MCMC} & MCMC & No & \texttt{a4aFitMCMC} \\
\end{longtable}

Type \texttt{MP}, for ``Management Procedure,'' returns an \texttt{a4aFit} class object designed for use in MSEs (Management Strategy Evaluations) with full feedback models (\protect\hyperlink{ref-puntmse}{Punt et al. 2016}). Inverting the jacobian to compute the variance-covariance matrix is computationally intensive in maximum likelihood models, and as MSE analyses often involve thousands of iterations, using \texttt{fit="MP"} significantly speeds up the process. This option is advantageous for scenarios requiring multiple model fits. However, the lack of immediate feedback on model convergence is a drawback, as convergence is assessed by inverting the Jacobian. A failed inversion indicates non-convergence.

Type \texttt{assessment}, the default, reports both the parameters and their variance-covariance, and as such requires the inversion of the hessian matrix. The method takes longer to run but returns a much richer dataset which allows the computation confidence intervals, simulate, etc. When the hessian matrix can't be inverted this method flags potential non-convergence and returns an empty object.

Type \texttt{MCMC} uses the Markov Chain Monte-Carlo approach, in which case it doesn't compute likelihoods or variance-covariance matrices. It returns the full draws of the chain, which allows the computation of credible intervals, simulation kind of studies and so on.

Table \ref{tab:a4afitclass} describes the composition of the \texttt{a4aFit} class.

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.2500}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.2500}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.2500}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.2500}}@{}}
\caption{\label{tab:a4afitclass} \texttt{a4aFit} Class Description}\tabularnewline
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Class
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Slot
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Slot's Class
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Description
\end{minipage} \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Class
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Slot
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Slot's Class
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Description
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\texttt{a4aFit} & \texttt{call} & \texttt{call} & Code used to run the analysis \\
& \texttt{catch.n} & \texttt{FLQuant} & Catch numbers at age and year \\
& \texttt{clock} & \texttt{numeric} & Time to run the analysis \\
& \texttt{desc} & \texttt{character} & Description of the stock and/or analysis \\
& \texttt{fitSumm} & \texttt{array} & Summary statistics of the fit (e.g., number of data points) \\
& \texttt{harvest} & \texttt{FLQuant} & Fishing mortality at age and year \\
& \texttt{index} & \texttt{FLQuants} & Indices of abundance (age/biomass, by year) \\
& \texttt{name} & \texttt{character} & Stock name \\
& \texttt{range} & \texttt{numeric} & Age and year range of the data \\
& \texttt{stock.n} & \texttt{FLQuant} & Population in numbers (age and year) \\
\end{longtable}

The \texttt{a4aFitSA} and \texttt{a4aFitMCMC} classes extend \texttt{a4aFit}, retaining all its slots while adding a \texttt{pars} slot of class \texttt{SCAPars}. Table \ref{tab:a4afitSAclass} outlines these classes.

\begin{longtable}[]{@{}llll@{}}
\caption{\label{tab:a4afitSAclass} \texttt{a4aFitSA} and \texttt{a4aFitMCMC} Class Description}\tabularnewline
\toprule\noalign{}
Class & Slot & Slot's Class & Description \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
Class & Slot & Slot's Class & Description \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\texttt{a4aFitSA} & All \texttt{a4aFit} & & Inherited from \texttt{a4aFit} \\
& \texttt{pars} & \texttt{SCAPars} & Parameter information \\
\texttt{a4aFitMCMC} & All \texttt{a4aFit} & & Inherited from \texttt{a4aFit} \\
& \texttt{pars} & \texttt{SCAPars} & Parameter information \\
\end{longtable}

The \texttt{SCAPars} class stores details about submodel parameters, such as formulas and distributions, and includes three slots: \texttt{stkmodel} for stock model parameters, \texttt{qmodel} for catchability parameters, and \texttt{vmodel} for variance parameters. Table \ref{tab:SCAParsclass} describes the \texttt{SCAPars} class.

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.2500}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.2500}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.2500}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.2500}}@{}}
\caption{\label{tab:SCAParsclass} \texttt{SCAPars} Class Description}\tabularnewline
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Class
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Slot
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Slot's Class
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Description
\end{minipage} \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Class
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Slot
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Slot's Class
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Description
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\texttt{SCAPars} & \texttt{stkmodel} & \texttt{a4aStkParams} & Details of fishing mortality, stock recruitment, and initial stock numbers \\
& \texttt{qmodel} & \texttt{submodel} & Details of catchability parameters \\
& \texttt{vmodel} & \texttt{submodel} & Details of variance parameters \\
\end{longtable}

The \texttt{stkmodel} slot encompasses parameters for fishing mortality, stock recruitment, and initial stock numbers. Due to potential correlations among these parameters, their variance-covariance matrix is reported collectively. Table \ref{tab:a4aStkParamsclass} describes the slots of the \texttt{a4aStkParams} class.

\begin{longtable}[]{@{}llll@{}}
\caption{\label{tab:a4aStkParamsclass} \texttt{a4aStkParams} Class Description}\tabularnewline
\toprule\noalign{}
Class & Slot & Slot's Class & Description \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
Class & Slot & Slot's Class & Description \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\texttt{a4aStkParams} & \texttt{centering} & \texttt{FLPar} & Centering parameters \\
& \texttt{coefficients} & \texttt{FLPar} & Model coefficients \\
& \texttt{desc} & \texttt{character} & Description \\
& \texttt{distr} & \texttt{character} & Distributions \\
& \texttt{fMod} & \texttt{formula} & Fishing mortality model \\
& \texttt{link} & \texttt{function} & Link function \\
& \texttt{linkinv} & \texttt{function} & Inverse link function \\
& \texttt{m} & \texttt{FLQuant} & Mortality parameters \\
& \texttt{mat} & \texttt{FLQuant} & Maturity parameters \\
& \texttt{n1Mod} & \texttt{formula} & Initial stock numbers model \\
& \texttt{name} & \texttt{character} & Stock name \\
& \texttt{range} & \texttt{numeric} & Age and year range \\
& \texttt{srMod} & \texttt{formula} & Stock-recruitment model \\
& \texttt{units} & \texttt{character} & Units of measurement \\
& \texttt{vcov} & \texttt{array} & Variance-covariance matrix \\
& \texttt{wt} & \texttt{FLQuant} & Weights \\
\end{longtable}

The \texttt{qmodel} and \texttt{vmodel} slots share the \texttt{submodel} class, which describes single submodels. Table \ref{tab:submodelclass} provides details.

\begin{longtable}[]{@{}llll@{}}
\caption{\label{tab:submodelclass} \texttt{submodel} Class Description}\tabularnewline
\toprule\noalign{}
Class & Slot & Slot's Class & Description \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
Class & Slot & Slot's Class & Description \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\texttt{submodel} & \texttt{centering} & \texttt{FLPar} & Centering parameters \\
& \texttt{coefficients} & \texttt{FLPar} & Model coefficients \\
& \texttt{desc} & \texttt{character} & Description \\
& \texttt{distr} & \texttt{character} & Distributions \\
& \texttt{formula} & \texttt{formula} & Submodel formula \\
& \texttt{link} & \texttt{function} & Link function \\
& \texttt{linkinv} & \texttt{function} & Inverse link function \\
& \texttt{name} & \texttt{character} & Stock name \\
& \texttt{range} & \texttt{numeric} & Age and year range \\
& \texttt{vcov} & \texttt{array} & Variance-covariance matrix \\
\end{longtable}

\hypertarget{introduction-to-splines}{%
\chapter{Introduction to Splines}\label{introduction-to-splines}}

Splines are a specific case of smoothers. A \textbf{smoother} is a method or algorithm designed to estimate a smooth function that fits data, capturing underlying trends without overfitting noise. Splines are a powerful tool for modeling complex, non-linear relationships between variables in a flexible and interpretable way. A common way to use splines is to break a function into smooth, continuous polynomial segments, each called a \emph{piece} or \emph{basis function}, joined at specific points called \emph{knots}. This piecewise approach allows us to capture the non-linearity in the data without overfitting.

\emph{Basis functions} consist the main building block of splines.The key concept of ``basis functions'' is that they transform the input variable (or vector) \(\mathbf{x}\) into a set of new variables, which are then used as inputs in the model. This allows the model to remain linear in these transformed variables, even though it can capture complex, non-linear relationships in the original variable.

Splines build their functionality through the core concepts of linear models. Linear models assume that the relationship between data can be described by a straight line, in the case of only one predictor \(\mathbf{x}\).
We denote linear model as:

\[\mathbf{y} = \beta_0 + \beta_1\mathbf{x} + \mathbf{\epsilon}\]

Where \(\mathbf{y}\) are the observations, the parameters \(\beta_0\) and \(\beta_1\) uniquely determine a straight line and \(\mathbf{\epsilon}\) is the observation error. Simple in its construction and representation, linear models can be limited when trying to capture the complexity of a real-world data set. The simplest form of a linear model is the mean or average of a data set:

\[\mathbf{y} = \beta_0 + \epsilon\]

In the following graph of non linear data (\(\mathbf{y}\)), we fit a simple mean value of \(\beta_0\) and a straight line model \(\beta_0 + \beta_1\mathbf{x}\):

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/meanandlinear-1.png}
\caption{\label{fig:meanandlinear}Generated data with two linear fits, left a simple mean and right a straight line}
\end{figure}

In this case our parameters are a \(\beta_0 =\) 3.09 for the mean (left) model, while for the straight line model, \(\beta_0 =\) 0.85 and \(\beta_1 =\) 0.46. In Figure \ref{fig:meanandlinear} we see how by adding to the constant model \(\beta_0\) a multiple (\(\beta_1\)) of the variable \(\mathbf{x}\), the model becomes a little more complex but it can now follow the general upward trend compared to the first line, although it fails to follow the peaks and the lows of the data set.

One of the mechanisms that splines use is to split the set of values of the predictor, in our case \(\mathbf{x}\), in smaller compartments and fit in those compartments a specified model. The points where the splitting occurs are called \emph{knots}. In Figure \ref{fig:knots} we take a stepwise approach following the logic behind the use of piecewise polynomials in smoothing splines. First, we split our range of \(\mathbf{x}\) values in 4 subsets, by defining our knots, then we take the average of \(\mathbf{y}\) data for each of these compartments and in the final step we add a bit of complexity by fitting a straight line model in each of these subsets of our original dataset. \ref{fig:knots} demonstrates a naive approach to try and follow better the trends of the data, where in each step we manage to capture a bit more.

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/knots-1.png}
\caption{\label{fig:knots}Effect of breaking the data in sections, by knots, and fitting the mean or a linear model to each section.}
\end{figure}

\hypertarget{generalize-to-polynomials}{%
\section{Generalize to polynomials}\label{generalize-to-polynomials}}

We explored the concept of splitting the \(\mathbf{x}\) variable space into compartments and developing a solution by locally fitting linear models that better capture the global trajectory of the data. Smooth functions rely on two fundamental mechanisms. The first, as mentioned earlier, involves how the domain of the function is divided for estimation. The second, which we will focus on here, involves using slightly more complex functions than linear ones, such as polynomials.

By combining polynomial pieces and ensuring smoothness at their junctions, i.e.~knots, we can create flexible models that adapt to the data. In regression, splines are a powerful tool for fitting complex shapes by introducing non-linear trends while maintaining control over the smoothness of the overall function. This approach allows us to balance flexibility and precision in modeling.

The polynomials are build by transforming the predictor variable or the sets of variables into higher order polynomials (usually 2nd or 3rd grade polynomials). These polynomials need to have matching values at the knots.

Let \(S\) our spline function, that is defined in an interval \([a,b]\). We seek to construct \(S\) by combining \(k\) polynomials \(P\), where \(k\) is the number of knots. Let also \(t_{i}, i = 1, ..., k\) the positions of the knots in the interval \([a,b]\).

\(S\) is going to be defined as:

\[
S(x) = \sum_{i = 1}^{k}\beta_iP_{i}(x)
\]

where \(\beta_i\) parameters to be estimated

The above definition is a simplified version of how splines work and can help as an intuitive approach. In reality splines need to satisfy some extra conditions like continuity, i.e.~\(P_{i-1}(t_{i}) = P_{i}(t_{i})\) on the points of junction, and of the first and second derivative. Depending on the basis functions the conditions may differ.

In Figure \ref{fig:naivespline} we demonstrate the fitting of B splines. In this each of the polynomials i.e basis functions, \(P_i(x)\) is a simple function which is constructed based on the position of knots.

The spline would be then as follows:

\[\mathbf{y} = \beta_1P_1(\mathbf{x}) + \beta_2P_2(\mathbf{x}) + \beta_3P_3(\mathbf{x}) + \beta_4P_4(\mathbf{x})+\beta_5P_5(\mathbf{x}) \]

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/naivespline-1.png}
\caption{\label{fig:naivespline}A B-spline with 5 knots consists of 5 cubic polynomials}
\end{figure}

The B-spline fit above is constrained at the boundaries, by putting two of the five knots there, resulting in a linear behavior at the ends of the data range. This approach is helpful for data that has an approximately linear trend at the boundaries but exhibits non-linearity in the center.

The knots in this regression spline are placed by quantiles through the variable space, so in the case where the data are evenly spread across the variable space the knots will be placed evenly.

For the spline fitted above, there are \(k\) polynomials plus an intercept (not shown) based on the knots (dashed lines). See Figure \ref{fig:splinebasis} for a depiction of the basis functions.

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/splinebasis-1.png}
\caption{\label{fig:splinebasis}basis functions for a B-spline with 5 knots}
\end{figure}

The polynomials transform the initial variable \(\mathbf{x}\) and create a \emph{model} matrix \(\mathbf{X}\) with \(k\) columns and \(n\) rows, where \(n\) is the number of data points. This new transformation is being then used to fit the model and estimate the \(\beta_{0}, ... ,\beta_{k}\) coefficients, \(\beta_0\) is required for the intercept. The fitted model results from \(\mathbf{X} \mathbf{\beta}\) (Figure \ref{fig:splinebasisandmodel}).

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/splinebasisandmodel-1.png}
\caption{\label{fig:splinebasisandmodel}basis functions for a B-spline with 5 knots}
\end{figure}

\hypertarget{thin-plate-spline}{%
\section{Thin plate spline}\label{thin-plate-spline}}

Thin plate splines are particularly useful for smoothing in multiple dimensions. However, they also work well with univariate data, as they offer flexibility and control over smoothness they are the default choice of the \texttt{mgcv} package. Thin plate splines work differently from the splines we have shown so far. They are not composed of a sequence of local polynomials but from basis functions that are smooth across the entire range of the data, and capture increasing amounts of flexibility (Figure \ref{fig:tps}).

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Fit a thin plate spline with gam()}
\NormalTok{tps\_model }\OtherTok{\textless{}{-}} \FunctionTok{gam}\NormalTok{(y }\SpecialCharTok{\textasciitilde{}} \FunctionTok{s}\NormalTok{(x, }\AttributeTok{k =} \DecValTok{5}\NormalTok{, }\AttributeTok{bs =} \StringTok{"tp"}\NormalTok{), }\AttributeTok{data =}\NormalTok{ data)}

\CommentTok{\# Predict}
\NormalTok{data}\SpecialCharTok{$}\NormalTok{tps\_fit }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(tps\_model)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/tps-1.png}
\caption{\label{fig:tps}Thin plate splines fit with k = 5}
\end{figure}

Thin plate splines are ideal when you need a smooth fit without predefined knots. The notion of knots in thin plate splines does not have the same interpretation as for B-splines and other piecewise functions, and in fact it is likely not useful to think of knots when using thin plate spines. Instead it is better to think of the number of basis functions used to represent the smooth term (Figure \ref{fig:tpsbasis}).

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/tpsbasis-1.png}
\caption{\label{fig:tpsbasis}basis functions for thin plate splines}
\end{figure}

As in the example before, the fitted model results from \(X\beta\) (Figure \ref{fig:tpsbasisandmodel}).

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/tpsbasisandmodel-1.png}
\caption{\label{fig:tpsbasisandmodel}Basis functions for thin plate splines and the fitted model}
\end{figure}

Figure \ref{fig:spliesandtps} shows both models fitted to the dataset, both fits use the same number of knots.

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/spliesandtps-1.png}
\caption{\label{fig:spliesandtps}Thin plate splines and cubic regression splines fit}
\end{figure}

\hypertarget{the-mgcv-package-inside-a4a}{%
\section{\texorpdfstring{The \texttt{mgcv} package inside \texttt{a4a}}{The mgcv package inside a4a}}\label{the-mgcv-package-inside-a4a}}

The \texttt{mgcv} package provides various user input options to define the smoother functions used to construct the submodels.

Under the \texttt{a4a} framework, the \texttt{mgcv} package is used to construct the model matrices of the submodels, which are then passed to \texttt{ADMB} where the model fitting takes place.

The default option for the basis functions of the splines is \texttt{bs\ =\ tp} (thin plate splines) and is considered the optimal option. The user can define other smoothing basis functions using the \texttt{bs} argument. The user can refer to the \texttt{smooth.terms} of the \texttt{mgcv} package for a full description. There are many equivalent basis functions for the splines, and some of them have little or no effect in the context of \texttt{a4a}, since they differ only in the penalty term, which is not used in \texttt{a4a}.

Examples for different smoothing terms:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fmod00 }\OtherTok{\textless{}{-}} \ErrorTok{\textasciitilde{}}\FunctionTok{s}\NormalTok{(age)}\SpecialCharTok{+}\FunctionTok{s}\NormalTok{(year, }\AttributeTok{bs =} \StringTok{\textquotesingle{}tp\textquotesingle{}}\NormalTok{, }\AttributeTok{k =} \DecValTok{10}\NormalTok{) }\CommentTok{\# thin plate splines}
\NormalTok{fmod01 }\OtherTok{\textless{}{-}} \ErrorTok{\textasciitilde{}}\FunctionTok{s}\NormalTok{(age)}\SpecialCharTok{+}\FunctionTok{s}\NormalTok{(year, }\AttributeTok{bs =} \StringTok{\textquotesingle{}cr\textquotesingle{}}\NormalTok{, }\AttributeTok{k =} \DecValTok{10}\NormalTok{) }\CommentTok{\# regression cubic splines}
\NormalTok{fmod02 }\OtherTok{\textless{}{-}} \ErrorTok{\textasciitilde{}}\FunctionTok{s}\NormalTok{(age)}\SpecialCharTok{+}\FunctionTok{s}\NormalTok{(year, }\AttributeTok{bs =} \StringTok{\textquotesingle{}bs\textquotesingle{}}\NormalTok{, }\AttributeTok{k =} \DecValTok{10}\NormalTok{) }\CommentTok{\# b{-}splines}
\NormalTok{fmod03 }\OtherTok{\textless{}{-}} \ErrorTok{\textasciitilde{}}\FunctionTok{s}\NormalTok{(age)}\SpecialCharTok{+}\FunctionTok{s}\NormalTok{(year, }\AttributeTok{bs =} \StringTok{\textquotesingle{}ps\textquotesingle{}}\NormalTok{, }\AttributeTok{k =} \DecValTok{10}\NormalTok{) }\CommentTok{\# p{-}splines}
\NormalTok{fmod04 }\OtherTok{\textless{}{-}} \ErrorTok{\textasciitilde{}}\FunctionTok{s}\NormalTok{(age)}\SpecialCharTok{+}\FunctionTok{s}\NormalTok{(year, }\AttributeTok{bs =} \StringTok{\textquotesingle{}ad\textquotesingle{}}\NormalTok{, }\AttributeTok{k =} \DecValTok{10}\NormalTok{) }\CommentTok{\# Adaptive smoothers}

\NormalTok{fit00 }\OtherTok{\textless{}{-}} \FunctionTok{sca}\NormalTok{(stk, idx, }\AttributeTok{fmodel =}\NormalTok{ fmod00)}
\NormalTok{fit01 }\OtherTok{\textless{}{-}} \FunctionTok{sca}\NormalTok{(stk, idx, }\AttributeTok{fmodel =}\NormalTok{ fmod01)}
\NormalTok{fit02 }\OtherTok{\textless{}{-}} \FunctionTok{sca}\NormalTok{(stk, idx, }\AttributeTok{fmodel =}\NormalTok{ fmod02)}
\NormalTok{fit03 }\OtherTok{\textless{}{-}} \FunctionTok{sca}\NormalTok{(stk, idx, }\AttributeTok{fmodel =}\NormalTok{ fmod03)}
\NormalTok{fit04 }\OtherTok{\textless{}{-}} \FunctionTok{sca}\NormalTok{(stk, idx, }\AttributeTok{fmodel =}\NormalTok{ fmod04)}
\end{Highlighting}
\end{Shaded}

In this example we are using the thin plate regression splines, cubic splines, b-splines, p-splines and adaptive smoothers. Figure \ref{fig:a4asplines} shows the different fits together, where it's clear the differences are very small.

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/a4asplines-1.png}
\caption{\label{fig:a4asplines}Multiple fits of thin plate splines, cubic splines, b-splines, p-splines and adaptive smoothers}
\end{figure}

Functionality of \texttt{mgcv} package provides also the option to work with interactions. Although \texttt{s(age,\ year)} can be defined, it uses a common bivariate spline for the two variables which are very different in scale. It is preferable if interactions are assumed to use a tensor \texttt{te(age,\ year)}. Tensors are mathematical products that help model the individual smoothness of each variable while also capturing their joint interaction. The independent variables in the case of tensors are modeled with different numbers of basis functions allowing different amount of smoothness in each dimension.

Following the example above, let now \(\mathbf{x}\) and \(\mathbf{z}\) two independent variables with \(S_x\) and \(S_z\) their spline functions, having \(k\) and \(m\) number of basis functions, respectively. Given the nature of the basis functions, their tensor (interactions and main effects), \(te(\mathbf{x},\mathbf{z})\) can be defined as the sum of all possible multiplications of the elements of \(S_x\) and \(S_z\).

Again is up to the user to define the basis functions for the tensor smoothers. In the case of tensors the default basis is \texttt{cr}. Figure \ref{fig:te} shows the differences when using different basis for the tensor product.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fmod03 }\OtherTok{\textless{}{-}} \ErrorTok{\textasciitilde{}}\FunctionTok{te}\NormalTok{(age, year, }\AttributeTok{k =} \FunctionTok{c}\NormalTok{(}\DecValTok{3}\NormalTok{,}\DecValTok{10}\NormalTok{))}
\NormalTok{fmod04 }\OtherTok{\textless{}{-}} \ErrorTok{\textasciitilde{}}\FunctionTok{te}\NormalTok{(age, year, }\AttributeTok{k =} \FunctionTok{c}\NormalTok{(}\DecValTok{3}\NormalTok{,}\DecValTok{10}\NormalTok{), }\AttributeTok{bs =} \StringTok{\textquotesingle{}tp\textquotesingle{}}\NormalTok{)}
\NormalTok{fmod05 }\OtherTok{\textless{}{-}} \ErrorTok{\textasciitilde{}}\FunctionTok{te}\NormalTok{(age, year, }\AttributeTok{bs =} \StringTok{\textquotesingle{}bs\textquotesingle{}}\NormalTok{)}

\NormalTok{fit03 }\OtherTok{\textless{}{-}} \FunctionTok{sca}\NormalTok{(stk, idx, }\AttributeTok{fmodel =}\NormalTok{ fmod03)}
\NormalTok{fit04 }\OtherTok{\textless{}{-}} \FunctionTok{sca}\NormalTok{(stk, idx, }\AttributeTok{fmodel =}\NormalTok{ fmod04)}
\NormalTok{fit05 }\OtherTok{\textless{}{-}} \FunctionTok{sca}\NormalTok{(stk, idx, }\AttributeTok{fmodel =}\NormalTok{ fmod05)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/te-1.png}
\caption{\label{fig:te}Multiple basis for a tensor and their effects in the fit}
\end{figure}

\hypertarget{on-the-number-of-knots-k}{%
\section{\texorpdfstring{On the number of knots \(k\)}{On the number of knots k}}\label{on-the-number-of-knots-k}}

\(k\) is the dimension of the basis used to represent the smooth term \(s\). The default depends on the number of variables that the smooth is a function of. In practice k-1 (or k) sets the upper limit on the degrees of freedom associated with an s smooth (1 degree of freedom is usually lost to the intercept of the smooth). For the smooths the upper limit of the degrees of freedom is given by the product of the k values provided for each marginal smooth less one, for the constraint. The choice of the k is not critical and in general it must be large enough to allow to have enough degrees of freedom capturing the underlying process and small enough to prevent overfitting (Figure \ref{fig:ks}). A strong pattern in the residuals can be a sign of low \(k\).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fmod00 }\OtherTok{\textless{}{-}} \ErrorTok{\textasciitilde{}}\FunctionTok{s}\NormalTok{(age)}\SpecialCharTok{+}\FunctionTok{s}\NormalTok{(year, }\AttributeTok{k =} \DecValTok{5}\NormalTok{)}
\NormalTok{fmod01 }\OtherTok{\textless{}{-}} \ErrorTok{\textasciitilde{}}\FunctionTok{s}\NormalTok{(age)}\SpecialCharTok{+}\FunctionTok{s}\NormalTok{(year, }\AttributeTok{k =} \DecValTok{10}\NormalTok{) }\CommentTok{\# cubic splines [Why is this cubic]}
\NormalTok{fmod02 }\OtherTok{\textless{}{-}} \ErrorTok{\textasciitilde{}}\FunctionTok{s}\NormalTok{(age)}\SpecialCharTok{+}\FunctionTok{s}\NormalTok{(year, }\AttributeTok{k =} \DecValTok{20}\NormalTok{) }\CommentTok{\# b{-}splines [and this b?]}

\NormalTok{fit00 }\OtherTok{\textless{}{-}} \FunctionTok{sca}\NormalTok{(stk, idx, }\AttributeTok{fmodel =}\NormalTok{ fmod00)}
\NormalTok{fit01 }\OtherTok{\textless{}{-}} \FunctionTok{sca}\NormalTok{(stk, idx, }\AttributeTok{fmodel =}\NormalTok{ fmod01)}
\NormalTok{fit02 }\OtherTok{\textless{}{-}} \FunctionTok{sca}\NormalTok{(stk, idx, }\AttributeTok{fmodel =}\NormalTok{ fmod02)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/ks-1.png}
\caption{\label{fig:ks}Multiple ks and their effects in the fit}
\end{figure}

We can check the result of choosing different \(k\) values on BIC (Bayesian Information Criteria) and GCV (Generalized Cross Validation score) by running the stock assessment model with different k and looking at the values of those statistics (Figure \ref{fig:bic}).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fmodsk }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{()}
\ControlFlowTok{for}\NormalTok{(i }\ControlFlowTok{in} \DecValTok{10}\SpecialCharTok{:}\DecValTok{20}\NormalTok{) \{}
\NormalTok{  fmodsk[[}\FunctionTok{paste0}\NormalTok{(i)]] }\OtherTok{\textless{}{-}} \FunctionTok{as.formula}\NormalTok{(}\FunctionTok{paste0}\NormalTok{(}\StringTok{"\textasciitilde{}s(age)+s(year, k="}\NormalTok{,i,}\StringTok{")"}\NormalTok{))}
\NormalTok{\}}

\NormalTok{myFits }\OtherTok{\textless{}{-}} \FunctionTok{scas}\NormalTok{(}\FunctionTok{FLStocks}\NormalTok{(stk), }\FunctionTok{list}\NormalTok{(idx), }\AttributeTok{fmodel =}\NormalTok{ fmodsk)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/bic-1.png}
\caption{\label{fig:bic}BIC (Bayesian Information Criteria) and GCV (Generalized Cross Validation score) profiles based on changing the value of k.}
\end{figure}

\hypertarget{fitting}{%
\chapter{Fitting}\label{fitting}}

The \texttt{a4a} stock assessment framework is implemented in \texttt{R} through the method \texttt{sca()}. The method call requires as a minimum a \texttt{FLStock} object and a \texttt{FLIndices} or \texttt{FLindex} object, in which case the default submodels will be set by the method.

Having described building blocks, basic formulations and effects available to build a submodel's model, it's important to look into specific formulations and relate them to commonly known representations. Note that although a large number of formulations are available for each submodel, the user must carefully decide on the full stock assessment model being build and avoid over-parameterize. Over-parametrization may lead to non-convergence, but may also end up not being very useful for prediction/forecasting, which is one of the main objectives of stock assessment.

As mentioned before there are 5 submodels in operation:

\begin{itemize}
\tightlist
\item
  a model for F-at-age (\(F_{ay}\))
\item
  a (list) of model(s) for abundance indices catchability-at-age (\(Q_{ays}\)),
\item
  a model for recruitment (\(R_y\))
\item
  a list of models for the observation variance of catch-at-age and abundance indices (\(\{\sigma^2_{ay}, \tau^2_{ays}\}\))
\item
  a model for the initial age structure (\(N_{a,y=1}\))
\end{itemize}

Submodels that are not explicitly defined will be set by default using the relevant call to \texttt{defaultFmod()}, \texttt{defaultQmod}, \texttt{defaultSRmod()}, \texttt{defaultN1mod} or \texttt{defaultVmod()}. These methods will use the length of the time series and number of age groups to define the models.

To set specific submodels the user has to write the relevant \texttt{R} formula and include it in the call. The arguments for each submodel are self-explanatory: fishing mortality is \texttt{fmodel}, indices' catchability is \texttt{qmodel}, stock-recruitment is \texttt{srmodel}, observation variance is \texttt{vmodel} and for initial year's abundance is \texttt{n1model}. The following model comes closer to the official stock assessment of North Sea plaice, as such we'll name it \texttt{fit0} and keep it for future comparisons.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fmod0 }\OtherTok{\textless{}{-}} \ErrorTok{\textasciitilde{}}\FunctionTok{s}\NormalTok{(age, }\AttributeTok{k=}\DecValTok{6}\NormalTok{)}\SpecialCharTok{+}\FunctionTok{s}\NormalTok{(year, }\AttributeTok{k=}\DecValTok{10}\NormalTok{)}\SpecialCharTok{+}\FunctionTok{te}\NormalTok{(age, year, }\AttributeTok{k=}\FunctionTok{c}\NormalTok{(}\DecValTok{3}\NormalTok{,}\DecValTok{8}\NormalTok{))}
\NormalTok{qmod0 }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\FunctionTok{s}\NormalTok{(age, }\AttributeTok{k =} \DecValTok{4}\NormalTok{),}
       \SpecialCharTok{\textasciitilde{}}\FunctionTok{s}\NormalTok{(age, }\AttributeTok{k =} \DecValTok{3}\NormalTok{),}
       \SpecialCharTok{\textasciitilde{}}\FunctionTok{s}\NormalTok{(age, }\AttributeTok{k =} \DecValTok{3}\NormalTok{) }\SpecialCharTok{+}\NormalTok{ year,}
       \SpecialCharTok{\textasciitilde{}}\FunctionTok{s}\NormalTok{(age, }\AttributeTok{k =} \DecValTok{3}\NormalTok{),}
       \SpecialCharTok{\textasciitilde{}}\FunctionTok{s}\NormalTok{(age, }\AttributeTok{k =} \DecValTok{4}\NormalTok{),}
       \SpecialCharTok{\textasciitilde{}}\FunctionTok{s}\NormalTok{(age, }\AttributeTok{k =} \DecValTok{6}\NormalTok{))}
\NormalTok{srmod0 }\OtherTok{\textless{}{-}} \ErrorTok{\textasciitilde{}} \FunctionTok{s}\NormalTok{(year, }\AttributeTok{k=}\DecValTok{20}\NormalTok{)}
\NormalTok{vmod0 }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\FunctionTok{s}\NormalTok{(age, }\AttributeTok{k=}\DecValTok{4}\NormalTok{), }\SpecialCharTok{\textasciitilde{}}\DecValTok{1}\NormalTok{,  }\SpecialCharTok{\textasciitilde{}}\DecValTok{1}\NormalTok{, }\SpecialCharTok{\textasciitilde{}}\DecValTok{1}\NormalTok{, }\SpecialCharTok{\textasciitilde{}}\DecValTok{1}\NormalTok{, }\SpecialCharTok{\textasciitilde{}}\DecValTok{1}\NormalTok{, }\SpecialCharTok{\textasciitilde{}}\DecValTok{1}\NormalTok{, }\SpecialCharTok{\textasciitilde{}}\DecValTok{1}\NormalTok{)}
\NormalTok{n1mod0 }\OtherTok{\textless{}{-}} \ErrorTok{\textasciitilde{}} \FunctionTok{s}\NormalTok{(age, }\AttributeTok{k=}\DecValTok{3}\NormalTok{)}
\NormalTok{fit0 }\OtherTok{\textless{}{-}} \FunctionTok{sca}\NormalTok{(ple4, ple4.indices,}
       \AttributeTok{fmodel=}\NormalTok{fmod0,}
       \AttributeTok{qmodel=}\NormalTok{qmod0,}
       \AttributeTok{srmodel=}\NormalTok{srmod0,}
       \AttributeTok{n1model=}\NormalTok{n1mod0,}
       \AttributeTok{vmodel=}\NormalTok{vmod0)}
\NormalTok{stk0 }\OtherTok{\textless{}{-}}\NormalTok{ ple4 }\SpecialCharTok{+}\NormalTok{ fit0}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/plt02-1.png}
\caption{\label{fig:plt02}Stock summary - close to official assessment}
\end{figure}

The \texttt{show} method for \texttt{a4aFit} objects display the models used for the fit. Calling the fitted object, the submodels' formulas are printed in the console:

\begin{verbatim}
## a4a model fit for: PLE 
## 
## Call:
## .local(stock = stock, indices = indices, fmodel = ..1, qmodel = ..2, 
##     srmodel = ..3, n1model = ..4, vmodel = ..5)
## 
## Time used:
##  Pre-processing     Running a4a Post-processing           Total 
##      0.73477387      3.52265382      0.07718682      4.33461452 
## 
## Submodels:
##   fmodel: ~s(age, k = 6) + s(year, k = 10) + te(age, year, k = c(3, 8))
##  srmodel: ~s(year, k = 20)
##  n1model: ~s(age, k = 3)
##   qmodel:
##     BTS-Isis-early:                  ~s(age, k = 4)
##     BTS-Combined (ISIS and TRIDENS): ~s(age, k = 3)
##     SNS:                             ~s(age, k = 3) + year
##     BTS-Combined (all):              ~s(age, k = 3)
##     IBTS_Q3:                         ~s(age, k = 4)
##     IBTS_Q1:                         ~s(age, k = 6)
##   vmodel:
##     catch:                           ~s(age, k = 4)
##     BTS-Isis-early:                  ~1
##     BTS-Combined (ISIS and TRIDENS): ~1
##     SNS:                             ~1
##     BTS-Combined (all):              ~1
##     IBTS_Q3:                         ~1
##     IBTS_Q1:                         ~1
\end{verbatim}

There are a set of methods for \texttt{a4a} fit objects which help manipulating \texttt{sca()} results, namely \texttt{+}, that updates the stock object with the fitted fishing mortalities, population abundance and catch in numbers at age. This method can be applied to \texttt{FLStocks} and \texttt{a4aFits} objects as well.

The following subsections describe common formulations used to define submodels. Although the formulas are tailored to specific submodels --- \emph{e.g.}, a separable model for \(F\) --- they can, in principle, be applied to any submodel. The \texttt{sca} method is agnostic to the model setup and will attempt to fit the model regardless of its specification. However, from a statistical standpoint, convergence may fail if the model is not well specified. From a fisheries modeling perspective, limitations arise in how the model is interpreted. For example, if a scientific survey is modeled with a year effect, the user is implicitly assuming that the survey's selectivity has changed over time. Consequently, the model may attribute part of the observed trend in the survey data to changes in selectivity rather than to changes in abundance.

\hypertarget{fishing-mortality-submodel-f_ay}{%
\section{\texorpdfstring{Fishing mortality submodel (\(F_{ay}\))}{Fishing mortality submodel (F\_\{ay\})}}\label{fishing-mortality-submodel-f_ay}}

\hypertarget{separable-model}{%
\subsection{Separable model}\label{separable-model}}

One of the most useful models for fishing mortality is one in which `age' and `year' effects are independent, that is, where the shape of the selection pattern does not change over time, but the overall level of fishing mortality do. Commonly called a `separable model'.

A full separable model in \texttt{a4a} is written using the \texttt{factor} function which converts age and year effects into categorical values, forcing a different coefficient to be estimated for each level of both effects. This model has \(age \times year\) number of parameters.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fmod1 }\OtherTok{\textless{}{-}} \ErrorTok{\textasciitilde{}} \FunctionTok{factor}\NormalTok{(age) }\SpecialCharTok{+} \FunctionTok{factor}\NormalTok{(year)}
\NormalTok{fit1 }\OtherTok{\textless{}{-}} \FunctionTok{sca}\NormalTok{(ple4, ple4.indices, }\AttributeTok{fmodel=}\NormalTok{fmod1, }\AttributeTok{fit=}\StringTok{"MP"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

One can reduce the number of parameters and add dependency along both effects, although still keeping independence of each other, by using smoothers rather than \texttt{factor}. We're using the North Sea Plaice data, and since it has 10 ages we will use a simple rule of thumb that the spline should have fewer than \(\frac{10}{2} = 5\) degrees of freedom, and so we opt for 4 degrees of freedom. We will also do the same for year and model the change in \(F\) through time as a smoother with 20 degrees of freedom.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fmod2 }\OtherTok{\textless{}{-}} \ErrorTok{\textasciitilde{}} \FunctionTok{s}\NormalTok{(age, }\AttributeTok{k=}\DecValTok{4}\NormalTok{) }\SpecialCharTok{+} \FunctionTok{s}\NormalTok{(year, }\AttributeTok{k=}\DecValTok{20}\NormalTok{)}
\NormalTok{fit2 }\OtherTok{\textless{}{-}} \FunctionTok{sca}\NormalTok{(ple4, ple4.indices, }\AttributeTok{fmodel=}\NormalTok{fmod2, }\AttributeTok{fit=}\StringTok{"MP"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

An interesting extension of the separable model is the `double separable' where a third factor or smoother is added for the cohort effect.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fmod3 }\OtherTok{\textless{}{-}} \ErrorTok{\textasciitilde{}} \FunctionTok{s}\NormalTok{(age, }\AttributeTok{k=}\DecValTok{4}\NormalTok{) }\SpecialCharTok{+} \FunctionTok{s}\NormalTok{(year, }\AttributeTok{k=}\DecValTok{20}\NormalTok{) }\SpecialCharTok{+} \FunctionTok{s}\NormalTok{(}\FunctionTok{as.numeric}\NormalTok{(year}\SpecialCharTok{{-}}\NormalTok{age), }\AttributeTok{k=}\DecValTok{10}\NormalTok{)}
\NormalTok{fit3 }\OtherTok{\textless{}{-}} \FunctionTok{sca}\NormalTok{(ple4, ple4.indices, }\AttributeTok{fmodel=}\NormalTok{fmod3, }\AttributeTok{fit=}\StringTok{"MP"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Figures \ref{fig:sep00} and \ref{fig:sep01} depicts the three models selectivities for each year. Each separable model has a single selectivity that changes it's overall scale in each year, while the double separable introduces some variability over time by modeling the cohort factor.

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/sep00-1.png}
\caption{\label{fig:sep00}Selection pattern of separable models. Each line represents the selection pattern in a specific year. Independent age and year effects (factor), internally dependent age and year (smooth), double separable (double).}
\end{figure}

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/sep01-1.png}
\caption{\label{fig:sep01}Fishing mortality of separable models. Independent age and year effects (factor), internally dependent age and year (smooth), double separable (double).}
\end{figure}

\hypertarget{model-with-age-year-interaction}{%
\subsection{Model with age-year interaction}\label{model-with-age-year-interaction}}

A non-separable model, where we consider age and year to interact can be modeled by a smooth interaction term with a tensor product of cubic splines, the \texttt{te} method (Figure \ref{fig:te1}), again borrowed from \texttt{mgcv} (S. N. Wood (\protect\hyperlink{ref-R-mgcv}{2011})).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fmod }\OtherTok{\textless{}{-}} \ErrorTok{\textasciitilde{}} \FunctionTok{te}\NormalTok{(age, year, }\AttributeTok{k =} \FunctionTok{c}\NormalTok{(}\DecValTok{4}\NormalTok{,}\DecValTok{20}\NormalTok{))}
\NormalTok{fit }\OtherTok{\textless{}{-}} \FunctionTok{sca}\NormalTok{(ple4, ple4.indices, }\AttributeTok{fmodel=}\NormalTok{fmod)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/te1-1.png}
\caption{\label{fig:te1}Fishing mortality smoothed non-separable model}
\end{figure}

In this example fishing mortalities are linked across age and time. What if we want to free up a specific age class because in the residuals we see a consistent pattern. This can happen, for example, if the spatial distribution of juveniles is disconnected to the distribution of adults. The fishery focuses on the adult fish, and therefore the \(F\) on young fish is a function of the distribution of the juveniles and could deserve a specific model. This can be achieved by adding a component for the year effect on age 1 (Figure \ref{fig:age1}). We'll use \texttt{s}'s argument \texttt{by} to define the ages that the model will apply to. The \texttt{as.numeric} method over \texttt{age==1}, will result in a matrix that will be \(1\) for ages 1 and \(0\) for the other ages, effectively removing those ages from the \texttt{s} model. Furthermore, by not removing age 1 from the \texttt{te} component we're in effect adding the two estimates for age 1.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fmod }\OtherTok{\textless{}{-}} \ErrorTok{\textasciitilde{}} \FunctionTok{te}\NormalTok{(age, year, }\AttributeTok{k =} \FunctionTok{c}\NormalTok{(}\DecValTok{4}\NormalTok{,}\DecValTok{20}\NormalTok{)) }\SpecialCharTok{+} \FunctionTok{s}\NormalTok{(year, }\AttributeTok{k =} \DecValTok{5}\NormalTok{, }\AttributeTok{by =} \FunctionTok{as.numeric}\NormalTok{(age}\SpecialCharTok{==}\DecValTok{1}\NormalTok{))}
\NormalTok{fit2 }\OtherTok{\textless{}{-}} \FunctionTok{sca}\NormalTok{(ple4, ple4.indices, }\AttributeTok{fmodel=}\NormalTok{fmod)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/age1-1.png}
\caption{\label{fig:age1}Fishing mortality age-year interaction model with extra age 1 smoother.}
\end{figure}

\hypertarget{constant-selectivity-for-contiguous-ages-or-years}{%
\subsection{Constant selectivity for contiguous ages or years}\label{constant-selectivity-for-contiguous-ages-or-years}}

To set these models we'll use the method \texttt{replace()} to define which ages or years will be modelled together. The following example shows \texttt{replace()} in operation. The dependent variables used in the model will be changed and attributed the same age or year, as such during the fit observations of those ages or years with will be seen as replicates. One can think of it as sharing the same mean value, which will be estimated by the model.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{age }\OtherTok{\textless{}{-}} \DecValTok{1}\SpecialCharTok{:}\DecValTok{10}
\CommentTok{\# last age same as previous}
\FunctionTok{replace}\NormalTok{(age, age}\SpecialCharTok{\textgreater{}}\DecValTok{9}\NormalTok{, }\DecValTok{9}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] 1 2 3 4 5 6 7 8 9 9
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# all ages after age 6}
\FunctionTok{replace}\NormalTok{(age, age}\SpecialCharTok{\textgreater{}}\DecValTok{6}\NormalTok{, }\DecValTok{6}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] 1 2 3 4 5 6 6 6 6 6
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{year }\OtherTok{\textless{}{-}} \DecValTok{1950}\SpecialCharTok{:}\DecValTok{2010}
\FunctionTok{replace}\NormalTok{(year, year}\SpecialCharTok{\textgreater{}}\DecValTok{2005}\NormalTok{, }\DecValTok{2005}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] 1950 1951 1952 1953 1954 1955 1956 1957 1958 1959 1960 1961 1962 1963 1964
## [16] 1965 1966 1967 1968 1969 1970 1971 1972 1973 1974 1975 1976 1977 1978 1979
## [31] 1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990 1991 1992 1993 1994
## [46] 1995 1996 1997 1998 1999 2000 2001 2002 2003 2004 2005 2005 2005 2005 2005
## [61] 2005
\end{verbatim}

In the \(F\) submodel one can use this method to fix the estimation of \(F\) in the plus group to be the same as in the last non-aggregated age.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fmod }\OtherTok{\textless{}{-}} \ErrorTok{\textasciitilde{}} \FunctionTok{s}\NormalTok{(}\FunctionTok{replace}\NormalTok{(age, age}\SpecialCharTok{\textgreater{}}\DecValTok{9}\NormalTok{, }\DecValTok{9}\NormalTok{), }\AttributeTok{k=}\DecValTok{4}\NormalTok{) }\SpecialCharTok{+} \FunctionTok{s}\NormalTok{(year, }\AttributeTok{k=}\DecValTok{20}\NormalTok{)}
\NormalTok{fit }\OtherTok{\textless{}{-}} \FunctionTok{sca}\NormalTok{(ple4, ple4.indices, fmod)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/ctsselage-1.png}
\caption{\label{fig:ctsselage}F-at-age fixed above age 9}
\end{figure}

Or estimate the average \(F\) in the most recent years, instead of averaging after the assessment to compute the \emph{statu quo} selection pattern.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fmod }\OtherTok{\textless{}{-}} \ErrorTok{\textasciitilde{}} \FunctionTok{s}\NormalTok{(age, }\AttributeTok{k=}\DecValTok{4}\NormalTok{) }\SpecialCharTok{+} \FunctionTok{s}\NormalTok{(}\FunctionTok{replace}\NormalTok{(year, year}\SpecialCharTok{\textgreater{}}\DecValTok{2013}\NormalTok{, }\DecValTok{2013}\NormalTok{), }\AttributeTok{k=}\DecValTok{20}\NormalTok{)}
\NormalTok{fit }\OtherTok{\textless{}{-}} \FunctionTok{sca}\NormalTok{(ple4, ple4.indices, fmod)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/ctsselyear-1.png}
\caption{\label{fig:ctsselyear}F-at-age fixed for the most recent 5 years}
\end{figure}

\hypertarget{time-blocks-selectivity}{%
\subsection{Time blocks selectivity}\label{time-blocks-selectivity}}

To define blocks of data \texttt{sca()} uses the method \texttt{breakpts()}, which creates a factor from a vector with levels defined by the second argument.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{year }\OtherTok{\textless{}{-}} \DecValTok{1950}\SpecialCharTok{:}\DecValTok{2010}
\CommentTok{\# two levels separated in 2000}
\FunctionTok{breakpts}\NormalTok{(year, }\DecValTok{2000}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] (1949,2000] (1949,2000] (1949,2000] (1949,2000] (1949,2000] (1949,2000]
##  [7] (1949,2000] (1949,2000] (1949,2000] (1949,2000] (1949,2000] (1949,2000]
## [13] (1949,2000] (1949,2000] (1949,2000] (1949,2000] (1949,2000] (1949,2000]
## [19] (1949,2000] (1949,2000] (1949,2000] (1949,2000] (1949,2000] (1949,2000]
## [25] (1949,2000] (1949,2000] (1949,2000] (1949,2000] (1949,2000] (1949,2000]
## [31] (1949,2000] (1949,2000] (1949,2000] (1949,2000] (1949,2000] (1949,2000]
## [37] (1949,2000] (1949,2000] (1949,2000] (1949,2000] (1949,2000] (1949,2000]
## [43] (1949,2000] (1949,2000] (1949,2000] (1949,2000] (1949,2000] (1949,2000]
## [49] (1949,2000] (1949,2000] (1949,2000] (2000,2010] (2000,2010] (2000,2010]
## [55] (2000,2010] (2000,2010] (2000,2010] (2000,2010] (2000,2010] (2000,2010]
## [61] (2000,2010]
## Levels: (1949,2000] (2000,2010]
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# five periods with equal interval}
\FunctionTok{breakpts}\NormalTok{(year, }\FunctionTok{seq}\NormalTok{(}\DecValTok{1949}\NormalTok{, }\DecValTok{2010}\NormalTok{, }\AttributeTok{length=}\DecValTok{6}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] (1949,1961.2]   (1949,1961.2]   (1949,1961.2]   (1949,1961.2]  
##  [5] (1949,1961.2]   (1949,1961.2]   (1949,1961.2]   (1949,1961.2]  
##  [9] (1949,1961.2]   (1949,1961.2]   (1949,1961.2]   (1949,1961.2]  
## [13] (1961.2,1973.4] (1961.2,1973.4] (1961.2,1973.4] (1961.2,1973.4]
## [17] (1961.2,1973.4] (1961.2,1973.4] (1961.2,1973.4] (1961.2,1973.4]
## [21] (1961.2,1973.4] (1961.2,1973.4] (1961.2,1973.4] (1961.2,1973.4]
## [25] (1973.4,1985.6] (1973.4,1985.6] (1973.4,1985.6] (1973.4,1985.6]
## [29] (1973.4,1985.6] (1973.4,1985.6] (1973.4,1985.6] (1973.4,1985.6]
## [33] (1973.4,1985.6] (1973.4,1985.6] (1973.4,1985.6] (1973.4,1985.6]
## [37] (1985.6,1997.8] (1985.6,1997.8] (1985.6,1997.8] (1985.6,1997.8]
## [41] (1985.6,1997.8] (1985.6,1997.8] (1985.6,1997.8] (1985.6,1997.8]
## [45] (1985.6,1997.8] (1985.6,1997.8] (1985.6,1997.8] (1985.6,1997.8]
## [49] (1997.8,2010]   (1997.8,2010]   (1997.8,2010]   (1997.8,2010]  
## [53] (1997.8,2010]   (1997.8,2010]   (1997.8,2010]   (1997.8,2010]  
## [57] (1997.8,2010]   (1997.8,2010]   (1997.8,2010]   (1997.8,2010]  
## [61] (1997.8,2010]  
## 5 Levels: (1949,1961.2] (1961.2,1973.4] (1973.4,1985.6] ... (1997.8,2010]
\end{verbatim}

Note \texttt{seq()} computes `left-open' intervals, which means that to include 1950 the sequence must start one year earlier.

These methods can be used to create discrete time series, for which a different selection pattern is allowed in each block. This is called an interaction in statistical modelling parlance, and typically a \texttt{*} denotes an interaction term, for smoothers an interaction is achieved using the \texttt{by} argument. When this argument is a \texttt{factor} a replicate of the smooth is produced for each factor level.

In the next case we'll use the \texttt{breakpts()} to split the time series at 1990, although keeping the same shape in both periods, a thin plate spline with 3 knots (Figure \ref{fig:brk}).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fmod }\OtherTok{\textless{}{-}} \ErrorTok{\textasciitilde{}}\FunctionTok{s}\NormalTok{(age, }\AttributeTok{k =} \DecValTok{3}\NormalTok{, }\AttributeTok{by =} \FunctionTok{breakpts}\NormalTok{(year, }\DecValTok{1990}\NormalTok{))}
\NormalTok{fit }\OtherTok{\textless{}{-}} \FunctionTok{sca}\NormalTok{(ple4, ple4.indices, fmod)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/brk-1.png}
\caption{\label{fig:brk}F-at-age in two periods using in both cases a thin plate spline with 3 knots}
\end{figure}

\hypertarget{time-changing-selectivity}{%
\subsection{Time changing selectivity}\label{time-changing-selectivity}}

In many cases, it may be desirable to allow the selection pattern to evolve over time, from year to year. Again there are several ways to do this, one way is to estimate a mean selection pattern, while also allowing \(F\) to vary over time for each age. This is like a separable smoother over year, with `age blocks' so, looking back at previous examples, we have:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fmodel }\OtherTok{\textless{}{-}} \ErrorTok{\textasciitilde{}} \FunctionTok{s}\NormalTok{(year, }\AttributeTok{k =} \DecValTok{15}\NormalTok{, }\AttributeTok{by =} \FunctionTok{factor}\NormalTok{(age)) }\SpecialCharTok{+} \FunctionTok{s}\NormalTok{(age, }\AttributeTok{k =} \DecValTok{4}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

This is a type of interaction between age and year, but the only connection (or correlation) across ages is via the smoother on age, however there are still 15 degrees of freedom for each age, so the model 10 x 15 + 4 = 154 degrees of freedom.

To include correlation across ages and years together the tensor product (\texttt{te()}) is used, this has the effect of restricting the flexibility of the model for \(F\). In the following, there is a smoother in 2 dimensions (age and year) where there is 5 degrees of freedom in the age direction, and 15 in the year dimension, resulting in a total of 5 x 15 = 65 degrees of freedom

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fmodel }\OtherTok{\textless{}{-}} \ErrorTok{\textasciitilde{}} \FunctionTok{te}\NormalTok{(age, year, }\AttributeTok{k =} \FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{15}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

Often the above formulations provide too much flexibility, and a more complicated specification, but simpler model is preferable:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fmodel }\OtherTok{\textless{}{-}} \ErrorTok{\textasciitilde{}} \FunctionTok{s}\NormalTok{(age, }\AttributeTok{k =} \DecValTok{4}\NormalTok{) }\SpecialCharTok{+} \FunctionTok{s}\NormalTok{(year, }\AttributeTok{k =} \DecValTok{15}\NormalTok{) }\SpecialCharTok{+} \FunctionTok{te}\NormalTok{(age, year, }\AttributeTok{k =} \FunctionTok{c}\NormalTok{(}\DecValTok{3}\NormalTok{, }\DecValTok{5}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

in the above model, the main effects for age and year still have similar flexibility to the full tensor model, however, the interaction (or the change in F at age over time) has been restricted, so that the full model now has 4 + 15 + 3 x 5 = 34 degrees of freedom.

\hypertarget{closed-form-selection-pattern}{%
\subsection{Closed form selection pattern}\label{closed-form-selection-pattern}}

One can use a closed form for the selection pattern. The only requirement is to be able to write it as a \texttt{R} formula, the example below uses a logistic form.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fmod }\OtherTok{\textless{}{-}} \ErrorTok{\textasciitilde{}} \FunctionTok{I}\NormalTok{(}\DecValTok{1}\SpecialCharTok{/}\NormalTok{(}\DecValTok{1}\SpecialCharTok{+}\FunctionTok{exp}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{age)))}
\NormalTok{fit }\OtherTok{\textless{}{-}} \FunctionTok{sca}\NormalTok{(ple4, ple4.indices, fmod)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/logistic-1.png}
\caption{\label{fig:logistic}F-at-age logistic}
\end{figure}

\hypertarget{abundance-indices-catchability-submodel-q_ays}{%
\section{\texorpdfstring{Abundance indices catchability submodel (\(Q_{ays}\))}{Abundance indices catchability submodel (Q\_\{ays\})}}\label{abundance-indices-catchability-submodel-q_ays}}

The catchability submodel is set up the same way as the \(F\) submodel. The only difference is that the submodel is set up as a list of formulas, where each formula relates with one abundance index. There's no limitation in the number of indices or type that can be used for a fit. It's the analyst that has to decide based on her/his expertise and knowledge of the stock and fleet dynamics.

In the following examples we'll use a single index instead of all available indices for plaice in ICES area 4, to simplify the code and examples.

\hypertarget{catchability-submodel-for-age-based-indices}{%
\subsection{Catchability submodel for age based indices}\label{catchability-submodel-for-age-based-indices}}

The first model shown is simply a dummy effect on age, which means that one coefficient will be estimated for each age. Note this kind of model considers each level of the factor to be independent from the others levels (Figure \ref{fig:dummyage}).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{qmod }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\FunctionTok{factor}\NormalTok{(age))}
\NormalTok{fit }\OtherTok{\textless{}{-}} \FunctionTok{sca}\NormalTok{(ple4, ple4.index, }\AttributeTok{qmodel=}\NormalTok{qmod)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/dummyage-1.png}
\caption{\label{fig:dummyage}Catchability age independent model}
\end{figure}

If one considers catchability at a specific age to be dependent on catchability on the other ages, similar to a selectivity modelling approach, one option is to use a smoother at age, and let the data `speak' regarding the shape (Figure \ref{fig:smoothage}).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{qmod }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{(}\SpecialCharTok{\textasciitilde{}} \FunctionTok{s}\NormalTok{(age, }\AttributeTok{k=}\DecValTok{4}\NormalTok{))}
\NormalTok{fit }\OtherTok{\textless{}{-}} \FunctionTok{sca}\NormalTok{(ple4, ple4.indices[}\DecValTok{1}\NormalTok{], }\AttributeTok{qmodel=}\NormalTok{qmod)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/smoothage-1.png}
\caption{\label{fig:smoothage}Catchability smoother age model}
\end{figure}

Finally, one may want to investigate a trend in catchability with time, very common in indices built from CPUE data. In the example given here we'll use a linear trend in time, set up by a simple linear model (Figure \ref{fig:qtrend}).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{qmod }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{( }\SpecialCharTok{\textasciitilde{}} \FunctionTok{s}\NormalTok{(age, }\AttributeTok{k=}\DecValTok{4}\NormalTok{) }\SpecialCharTok{+}\NormalTok{ year)}
\NormalTok{fit }\OtherTok{\textless{}{-}} \FunctionTok{sca}\NormalTok{(ple4, ple4.indices[}\DecValTok{1}\NormalTok{], }\AttributeTok{qmodel=}\NormalTok{qmod)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/qtrend-1.png}
\caption{\label{fig:qtrend}Catchability with a linear trend in year}
\end{figure}

\hypertarget{catchability-submodel-for-age-aggregated-biomass-indices}{%
\subsection{Catchability submodel for age aggregated biomass indices}\label{catchability-submodel-for-age-aggregated-biomass-indices}}

The previous section focused on age-disaggregated indices, which are most often reported as standardized number of individuals, \emph{e.g.} number of individuals caught per hour. Age-aggregated indices (such as CPUE, biomass, DEPM, etc.) may also be used to tune the population's biomass in terms of weight. These indices are linked either to the total biomass or to the weight of a specific group of age classes, defined by the age range set in the object.

In such cases, a different index class must be used: FLIndexBiomass. This class uses a vector named index with an age dimension labeled as `all'. The qmodel should be specified without age-specific factors, although it may still include a `year' component and relevant covariates, if needed.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# simulating a biomass index (note the name of the first dimension element) using}
\CommentTok{\# the ple4 biomass and an arbritary catchability of 0.001 plus a lognormal error.}
\NormalTok{dnms }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{(}\AttributeTok{age=}\StringTok{"all"}\NormalTok{, }\AttributeTok{year=}\FunctionTok{range}\NormalTok{(ple4)[}\StringTok{"minyear"}\NormalTok{]}\SpecialCharTok{:}\FunctionTok{range}\NormalTok{(ple4)[}\StringTok{"maxyear"}\NormalTok{])}
\NormalTok{bioidx }\OtherTok{\textless{}{-}} \FunctionTok{FLIndexBiomass}\NormalTok{(}\FunctionTok{FLQuant}\NormalTok{(}\ConstantTok{NA}\NormalTok{, }\AttributeTok{dimnames=}\NormalTok{dnms))}
\FunctionTok{index}\NormalTok{(bioidx) }\OtherTok{\textless{}{-}} \FunctionTok{stock}\NormalTok{(ple4)}\SpecialCharTok{*}\FloatTok{0.001}
\FunctionTok{index}\NormalTok{(bioidx) }\OtherTok{\textless{}{-}} \FunctionTok{index}\NormalTok{(bioidx)}\SpecialCharTok{*}\FunctionTok{exp}\NormalTok{(}\FunctionTok{rnorm}\NormalTok{(}\FunctionTok{index}\NormalTok{(bioidx), }\AttributeTok{sd=}\FloatTok{0.1}\NormalTok{))}
\FunctionTok{range}\NormalTok{(bioidx)[}\FunctionTok{c}\NormalTok{(}\StringTok{"startf"}\NormalTok{,}\StringTok{"endf"}\NormalTok{)] }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{)}
\CommentTok{\# note the name of the first dimension element}
\FunctionTok{index}\NormalTok{(bioidx)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## An object of class "FLQuant"
## , , unit = unique, season = all, area = unique
## 
##      year
## age   1957 1958 1959 1960 1961 1962 1963 1964 1965 1966 1967 1968 1969 1970
##   all  410  452  471  524  600  643  535  491  530  520  636  450  463  472
##      year
## age   1971 1972 1973 1974 1975 1976 1977 1978 1979 1980 1981 1982 1983 1984
##   all  445  422  386  451  508  515  600  532  469  436  570  511  506  590
##      year
## age   1985 1986 1987 1988 1989 1990 1991 1992 1993 1994 1995 1996 1997 1998
##   all  589  709  690  698  651  498  365  426  388  350  331  328  342  416
##      year
## age   1999 2000 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012
##   all  386  343  399  396  397  400  389  470  455  565  562  708  871  711
##      year
## age   2013 2014 2015 2016 2017
##   all  928 1069  982  918 1056
## 
## units:  t
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# fitting the model}
\NormalTok{fit }\OtherTok{\textless{}{-}} \FunctionTok{sca}\NormalTok{(ple4, }\FunctionTok{FLIndices}\NormalTok{(bioidx), }\AttributeTok{qmodel=}\FunctionTok{list}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\DecValTok{1}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

To estimate a constant selectivity over time one used the model \(\sim 1\), resulting in the following estimate:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{predict}\NormalTok{(fit)}\SpecialCharTok{$}\NormalTok{qmodel[[}\DecValTok{1}\NormalTok{]][}\DecValTok{1}\NormalTok{,drop}\OtherTok{=}\ConstantTok{TRUE}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.001006285
\end{verbatim}

The next code shows an example where the biomass index refers to age groups 2 to 4, \emph{e.g.} the CPUE of a fleet that targets these particular ages.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# creating the index}
\NormalTok{dnms }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{(}\AttributeTok{age=}\StringTok{"all"}\NormalTok{, }\AttributeTok{year=}\FunctionTok{range}\NormalTok{(ple4)[}\StringTok{"minyear"}\NormalTok{]}\SpecialCharTok{:}\FunctionTok{range}\NormalTok{(ple4)[}\StringTok{"maxyear"}\NormalTok{])}
\NormalTok{bioidx }\OtherTok{\textless{}{-}} \FunctionTok{FLIndexBiomass}\NormalTok{(}\FunctionTok{FLQuant}\NormalTok{(}\ConstantTok{NA}\NormalTok{, }\AttributeTok{dimnames=}\NormalTok{dnms))}
\CommentTok{\# but now use only ages 2:4}
\FunctionTok{index}\NormalTok{(bioidx) }\OtherTok{\textless{}{-}} \FunctionTok{tsb}\NormalTok{(ple4[}\FunctionTok{ac}\NormalTok{(}\DecValTok{2}\SpecialCharTok{:}\DecValTok{4}\NormalTok{)])}\SpecialCharTok{*}\FloatTok{0.001}
\FunctionTok{index}\NormalTok{(bioidx) }\OtherTok{\textless{}{-}} \FunctionTok{index}\NormalTok{(bioidx)}\SpecialCharTok{*}\FunctionTok{exp}\NormalTok{(}\FunctionTok{rnorm}\NormalTok{(}\FunctionTok{index}\NormalTok{(bioidx), }\AttributeTok{sd=}\FloatTok{0.1}\NormalTok{))}
\FunctionTok{range}\NormalTok{(bioidx)[}\FunctionTok{c}\NormalTok{(}\StringTok{"startf"}\NormalTok{,}\StringTok{"endf"}\NormalTok{)] }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{)}
\CommentTok{\# to pass this information to the model one needs to specify an age range}
\FunctionTok{range}\NormalTok{(bioidx)[}\FunctionTok{c}\NormalTok{(}\StringTok{"min"}\NormalTok{,}\StringTok{"max"}\NormalTok{)] }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{4}\NormalTok{)}
\CommentTok{\# fitting the model}
\NormalTok{fit }\OtherTok{\textless{}{-}} \FunctionTok{sca}\NormalTok{(ple4, }\FunctionTok{FLIndices}\NormalTok{(bioidx), }\AttributeTok{qmodel=}\FunctionTok{list}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\DecValTok{1}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

Once more the estimate value is not very far from the simulated one, 0.001.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{predict}\NormalTok{(fit)}\SpecialCharTok{$}\NormalTok{qmodel[[}\DecValTok{1}\NormalTok{]][}\DecValTok{1}\NormalTok{,drop}\OtherTok{=}\ConstantTok{TRUE}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.001001054
\end{verbatim}

\hypertarget{catchability-submodel-for-single-age-indices}{%
\subsection{Catchability submodel for single age indices}\label{catchability-submodel-for-single-age-indices}}

Similar to age aggregated indices one may have an index that relates only to one age, like a recruitment index. In this case the \texttt{FLIndex} object must have in the first dimension the age it refers to. The fit uses the index to tune the population abundance for the specific age. As for biomass indices, the qmodel should be set without age factors, although it can have a `year' component and covariates if needed.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{idx }\OtherTok{\textless{}{-}}\NormalTok{ ple4.index[}\DecValTok{1}\NormalTok{]}
\NormalTok{fit }\OtherTok{\textless{}{-}} \FunctionTok{sca}\NormalTok{(ple4, }\FunctionTok{FLIndices}\NormalTok{(}\AttributeTok{recidx=}\NormalTok{idx), }\AttributeTok{qmodel=}\FunctionTok{list}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\DecValTok{1}\NormalTok{))}
\CommentTok{\# the estimated catchability is}
\FunctionTok{predict}\NormalTok{(fit)}\SpecialCharTok{$}\NormalTok{qmodel[[}\DecValTok{1}\NormalTok{]][}\DecValTok{1}\NormalTok{,drop}\OtherTok{=}\ConstantTok{TRUE}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.04751391
\end{verbatim}

\hypertarget{stock-recruitment-submodel-r_y}{%
\section{\texorpdfstring{Stock-recruitment submodel (\(R_y\))}{Stock-recruitment submodel (R\_y)}}\label{stock-recruitment-submodel-r_y}}

The S/R submodel is a special case, in the sense that it can be set up with the same linear tools as the \(F\) and \(Q\) models, but it can also use some hard coded models. The example shows how to set up a simple dummy model with \texttt{factor()}, a smooth model with \texttt{s()}, a Ricker model (\texttt{ricker()}), a Beverton and Holt model (\texttt{bevholt()}), a hockey stick model (\texttt{hockey()}), and a geometric mean model (\texttt{geomean()}). See Figure \ref{fig:srmod} for results. As mentioned before, the `structural' models have a fixed variance, which must be set by defining the coefficient of variation.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{srmod }\OtherTok{\textless{}{-}} \ErrorTok{\textasciitilde{}} \FunctionTok{factor}\NormalTok{(year)}
\NormalTok{fit }\OtherTok{\textless{}{-}} \FunctionTok{sca}\NormalTok{(ple4, ple4.indices, }\AttributeTok{srmodel=}\NormalTok{srmod)}
\NormalTok{srmod }\OtherTok{\textless{}{-}} \ErrorTok{\textasciitilde{}} \FunctionTok{s}\NormalTok{(year, }\AttributeTok{k=}\DecValTok{15}\NormalTok{)}
\NormalTok{fit1 }\OtherTok{\textless{}{-}} \FunctionTok{sca}\NormalTok{(ple4, ple4.indices, }\AttributeTok{srmodel=}\NormalTok{srmod)}
\NormalTok{srmod }\OtherTok{\textless{}{-}} \ErrorTok{\textasciitilde{}} \FunctionTok{ricker}\NormalTok{(}\AttributeTok{CV=}\FloatTok{0.1}\NormalTok{)}
\NormalTok{fit2 }\OtherTok{\textless{}{-}} \FunctionTok{sca}\NormalTok{(ple4, ple4.indices, }\AttributeTok{srmodel=}\NormalTok{srmod)}
\NormalTok{srmod }\OtherTok{\textless{}{-}} \ErrorTok{\textasciitilde{}} \FunctionTok{bevholt}\NormalTok{(}\AttributeTok{CV=}\FloatTok{0.1}\NormalTok{)}
\NormalTok{fit3 }\OtherTok{\textless{}{-}} \FunctionTok{sca}\NormalTok{(ple4, ple4.indices, }\AttributeTok{srmodel=}\NormalTok{srmod)}
\NormalTok{srmod }\OtherTok{\textless{}{-}} \ErrorTok{\textasciitilde{}} \FunctionTok{hockey}\NormalTok{(}\AttributeTok{CV=}\FloatTok{0.1}\NormalTok{)}
\NormalTok{fit4 }\OtherTok{\textless{}{-}} \FunctionTok{sca}\NormalTok{(ple4, ple4.indices, }\AttributeTok{srmodel=}\NormalTok{srmod)}
\NormalTok{srmod }\OtherTok{\textless{}{-}} \ErrorTok{\textasciitilde{}} \FunctionTok{geomean}\NormalTok{(}\AttributeTok{CV=}\FloatTok{0.1}\NormalTok{)}
\NormalTok{fit5 }\OtherTok{\textless{}{-}} \FunctionTok{sca}\NormalTok{(ple4, ple4.indices, }\AttributeTok{srmodel=}\NormalTok{srmod)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/srmod-1.png}
\caption{\label{fig:srmod}Recruitment estimates since 1960 by each stock-recruitment model.}
\end{figure}

\hypertarget{observation-variance-submodel-sigma2_ay-tau2_ays}{%
\section{\texorpdfstring{Observation variance submodel (\(\{\sigma^2_{ay}, \tau^2_{ays}\}\))}{Observation variance submodel (\textbackslash\{\textbackslash sigma\^{}2\_\{ay\}, \textbackslash tau\^{}2\_\{ays\}\textbackslash\})}}\label{observation-variance-submodel-sigma2_ay-tau2_ays}}

The variance model allows the user to set up the shape of the observation variances \(\sigma^2_{ay}\) and \(\tau^2_{ays}\). This is an important subject for fisheries data used as input to stock assessment models.

The defaults assume a U-shape like model for catch-at-age and constant variance for abundance indices. The first relies on the fact that it's common to have more precision on the most represented ages and less precision on the less frequent ages which tend to be the younger and older individuals. These sizes are less caught by the fleets and as such do not appear as often at the auction markets samples. With regards to the abundance indices, one assumes a scientific survey to have a well designed sampling scheme and protocols which keep observation error at similar levels across ages.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# reference model with constant variance for the survey index}
\NormalTok{vmod }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\FunctionTok{s}\NormalTok{(age, }\AttributeTok{k=}\DecValTok{3}\NormalTok{), }\SpecialCharTok{\textasciitilde{}}\DecValTok{1}\NormalTok{)}
\NormalTok{fit1 }\OtherTok{\textless{}{-}} \FunctionTok{sca}\NormalTok{(ple4, ple4.index, }\AttributeTok{vmodel=}\NormalTok{vmod)}
\CommentTok{\# to compare {-} survey index variance modelled has a U{-}shape smoother}
\NormalTok{vmod }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\FunctionTok{s}\NormalTok{(age, }\AttributeTok{k=}\DecValTok{3}\NormalTok{), }\SpecialCharTok{\textasciitilde{}}\FunctionTok{s}\NormalTok{(age, }\AttributeTok{k=}\DecValTok{4}\NormalTok{))}
\NormalTok{fit2 }\OtherTok{\textless{}{-}} \FunctionTok{sca}\NormalTok{(ple4, ple4.index, }\AttributeTok{vmodel=}\NormalTok{vmod)}
\end{Highlighting}
\end{Shaded}

Variance estimated for the survey is constant at 0.476 while for catches using the U-shape model, fitted with a smoother, changes with ages (Figure \ref{fig:vmod}).

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/vmod-1.png}
\caption{\label{fig:vmod}Abundance index observation variance estimate}
\end{figure}

Observation variance options have an impact in the final estimates of population abundance, which can be seen in Figure \ref{fig:vmodimpact}.

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/vmodimpact-1.png}
\caption{\label{fig:vmodimpact}Population estimates using two different variance models for the survey}
\end{figure}

\hypertarget{initial-year-abundance-submodel-n_ay1}{%
\section{\texorpdfstring{Initial year abundance submodel (\(N_{a,y=1}\))}{Initial year abundance submodel (N\_\{a,y=1\})}}\label{initial-year-abundance-submodel-n_ay1}}

The submodel for the stock number at age in the first year of the time series is set with the usual tools. The model deals with the shape of the population abundance in a single year and as such the year effect shouldn't be included (Figure \ref{fig:ny1}).

This model has its influence limited to the initial lower triangle of the population matrix, which in assessments with long time series doesn't make much difference. Nevertheless, when modelling stocks with short time series in relation to the number of ages present, it becomes more important and should be given proper attention.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# model with smoother}
\NormalTok{n1mod }\OtherTok{\textless{}{-}} \ErrorTok{\textasciitilde{}}\FunctionTok{s}\NormalTok{(age, }\AttributeTok{k=}\DecValTok{4}\NormalTok{)}
\NormalTok{fit1 }\OtherTok{\textless{}{-}} \FunctionTok{sca}\NormalTok{(ple4, ple4.indices, }\AttributeTok{n1model=}\NormalTok{n1mod)}
\CommentTok{\# model with factor}
\NormalTok{n1mod }\OtherTok{\textless{}{-}} \ErrorTok{\textasciitilde{}}\FunctionTok{factor}\NormalTok{(age)}
\NormalTok{fit2 }\OtherTok{\textless{}{-}} \FunctionTok{sca}\NormalTok{(ple4, ple4.indices, }\AttributeTok{n1model=}\NormalTok{n1mod)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/ny1-1.png}
\caption{\label{fig:ny1}Nay=1 models}
\end{figure}

The impact in the overall perspective of the stock status is depicted in Figure \ref{fig:n1modimpact}. Most of the changes happen in the beginning of the time series, although due to the impact on the estimates of other submodels' parameters it can have an impact over the full time series.

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/n1modimpact-1.png}
\caption{\label{fig:n1modimpact}Population estimates using two different variance models}
\end{figure}

\hypertarget{more-models}{%
\section{More models}\label{more-models}}

More complicated models can be built with these tools. The limitation is going to be the potential overparametrization of the model and the failure to fit if the data isn't informative enough.

For example, Figure \ref{fig:ageind} shows a model where the age effect is modelled as a smoother throughout years independent from each other, with the exception of ages 9 and 10 which share their parameters.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fmod }\OtherTok{\textless{}{-}} \ErrorTok{\textasciitilde{}} \FunctionTok{factor}\NormalTok{(age) }\SpecialCharTok{+} \FunctionTok{s}\NormalTok{(year, }\AttributeTok{k=}\DecValTok{10}\NormalTok{, }\AttributeTok{by =} \FunctionTok{breakpts}\NormalTok{(age, }\FunctionTok{c}\NormalTok{(}\DecValTok{0}\SpecialCharTok{:}\DecValTok{8}\NormalTok{)))}
\NormalTok{fit }\OtherTok{\textless{}{-}} \FunctionTok{sca}\NormalTok{(ple4, ple4.indices, fmod)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/ageind-1.png}
\caption{\label{fig:ageind}F-at-age as thin plate spline with 3 knots for each age}
\end{figure}

A quite complex model that implements a cohort effect can be set through the following formula. Figure \ref{fig:coh} shows the resulting fishing mortality. Note that in this case we end up with a variable \(F\) pattern over time, but rather than using 4 * 10 = 40 parameters, it uses, 4 + 10 + 10 = 24.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fmodel }\OtherTok{\textless{}{-}} \ErrorTok{\textasciitilde{}} \FunctionTok{s}\NormalTok{(age, }\AttributeTok{k =} \DecValTok{4}\NormalTok{) }\SpecialCharTok{+} \FunctionTok{s}\NormalTok{(}\FunctionTok{pmax}\NormalTok{(year }\SpecialCharTok{{-}}\NormalTok{ age, }\DecValTok{1957}\NormalTok{), }\AttributeTok{k =} \DecValTok{10}\NormalTok{) }\SpecialCharTok{+} \FunctionTok{s}\NormalTok{(year, }\AttributeTok{k =} \DecValTok{10}\NormalTok{)}
\NormalTok{fit }\OtherTok{\textless{}{-}} \FunctionTok{sca}\NormalTok{(ple4, ple4.indices, }\AttributeTok{fmodel=}\NormalTok{fmodel)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/coh-1.png}
\caption{\label{fig:coh}F-at-age with a cohort effect.}
\end{figure}

The following model is applied to the vmodel and it introduces an time trend to reflect the increase in precision in more recent years with improvements in sampling design and increase in sampling effort.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{vmod }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{(}
       \SpecialCharTok{\textasciitilde{}} \FunctionTok{s}\NormalTok{(age, }\AttributeTok{k =} \DecValTok{3}\NormalTok{) }\SpecialCharTok{+}\NormalTok{ year,}
       \SpecialCharTok{\textasciitilde{}}\DecValTok{1}\NormalTok{, }\SpecialCharTok{\textasciitilde{}}\DecValTok{1}\NormalTok{, }\SpecialCharTok{\textasciitilde{}}\DecValTok{1}\NormalTok{, }\SpecialCharTok{\textasciitilde{}}\DecValTok{1}\NormalTok{, }\SpecialCharTok{\textasciitilde{}}\DecValTok{1}\NormalTok{, }\SpecialCharTok{\textasciitilde{}}\DecValTok{1}
\NormalTok{       )}
\NormalTok{fit }\OtherTok{\textless{}{-}} \FunctionTok{sca}\NormalTok{(ple4, ple4.indices, }\AttributeTok{vmodel=}\NormalTok{vmod)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/vm-1.png}
\caption{\label{fig:vm}Catch at age variance model with a year effect.}
\end{figure}

This model fits two smoothers to different sets of ages.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fmod }\OtherTok{\textless{}{-}} \ErrorTok{\textasciitilde{}}\FunctionTok{s}\NormalTok{(age, }\AttributeTok{k =} \DecValTok{3}\NormalTok{, }\AttributeTok{by =} \FunctionTok{breakpts}\NormalTok{(age, }\DecValTok{5}\NormalTok{)) }\SpecialCharTok{+} \FunctionTok{s}\NormalTok{(year, }\AttributeTok{k =} \DecValTok{10}\NormalTok{)}
\NormalTok{fit }\OtherTok{\textless{}{-}} \FunctionTok{sca}\NormalTok{(ple4, ple4.indices, }\AttributeTok{fmodel =}\NormalTok{ fmod)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/danai01-1.png}
\caption{\label{fig:danai01}Smoothers fitted to two sets of ages, 1 to 4 and 5 to 10.}
\end{figure}

\hypertarget{data-weigthing}{%
\section{Data weigthing}\label{data-weigthing}}

The \texttt{a4a} framework gives the opportunity to assign a weight or score to each observation, so that some data points influence the parameter estimates more (or less) than others, what's referred to as Weighted Likelihood Estimation (WLE) in the literature (\protect\hyperlink{ref-wang2004asymptotic}{Wang, Eeden, and Zidek 2004}; \protect\hyperlink{ref-fieldwle}{Field and Smith 1994}; \protect\hyperlink{ref-hu2002weighted}{Hu and Zidek 2002}).

The user will set the \(w_{ays}\) (see section \ref{sec:math}), which internally will be inverted and normalized to have a mean of 1. This is done by adding a variance matrix to the \texttt{catch.n} and \texttt{index.n} slots of the stock and index objects.

One pragmatic way to look at this scores is to think of them as coefficients of variation, the smaller values will reflect higher weight in the fitting process, and since CVs are unitless one can compare across data points.

Figure \ref{fig:likwgt} show the results of two fits, one without weighting the data points, in effect \(w_{ays}\) are all 1, and a fit with different weightings for catch-at-age (0.5) and index (0.1).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{stk }\OtherTok{\textless{}{-}}\NormalTok{ ple4}
\NormalTok{idx }\OtherTok{\textless{}{-}}\NormalTok{ ple4.indices[}\DecValTok{1}\NormalTok{]}
\CommentTok{\# run no weight}
\NormalTok{fit0 }\OtherTok{\textless{}{-}} \FunctionTok{sca}\NormalTok{(stk, idx, }\AttributeTok{fmodel=}\NormalTok{fmod0, }\AttributeTok{qmodel=}\NormalTok{qmod0, }\AttributeTok{srmodel=}\NormalTok{srmod0,}
       \AttributeTok{vmodel=}\NormalTok{vmod0, }\AttributeTok{n1model=}\NormalTok{n1mod0)}
\CommentTok{\# add cv to observed catches to be used to weight data points}
\NormalTok{varslt }\OtherTok{\textless{}{-}} \FunctionTok{catch.n}\NormalTok{(stk)}
\NormalTok{varslt[] }\OtherTok{\textless{}{-}} \FloatTok{0.5}
\FunctionTok{catch.n}\NormalTok{(stk) }\OtherTok{\textless{}{-}} \FunctionTok{FLQuantDistr}\NormalTok{(}\FunctionTok{catch.n}\NormalTok{(stk), varslt)}
\CommentTok{\# cv of observed indices to be used to weight data points}
\NormalTok{varslt }\OtherTok{\textless{}{-}} \FunctionTok{index}\NormalTok{(idx[[}\DecValTok{1}\NormalTok{]])}
\NormalTok{varslt[] }\OtherTok{\textless{}{-}} \FloatTok{0.1}
\FunctionTok{index.var}\NormalTok{(idx[[}\DecValTok{1}\NormalTok{]]) }\OtherTok{\textless{}{-}}\NormalTok{ varslt}
\CommentTok{\# run}
\NormalTok{fit1 }\OtherTok{\textless{}{-}} \FunctionTok{sca}\NormalTok{(stk, idx, }\AttributeTok{fmodel=}\NormalTok{fmod0, }\AttributeTok{qmodel=}\NormalTok{qmod0, }\AttributeTok{srmodel=}\NormalTok{srmod0,}
       \AttributeTok{vmodel=}\NormalTok{vmod0, }\AttributeTok{n1model=}\NormalTok{n1mod0)}
\NormalTok{flqs }\OtherTok{\textless{}{-}} \FunctionTok{FLQuants}\NormalTok{(}\AttributeTok{nowgt=}\FunctionTok{stock.n}\NormalTok{(fit0), }\AttributeTok{extwgt=}\FunctionTok{stock.n}\NormalTok{(fit1))}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/likwgt-1.png}
\caption{\label{fig:likwgt}Stock summary of distinct likelihood weightings}
\end{figure}

Note that by using a smaller CV for the index, one is increasing the contribution of the survey and penalizing catch at age, in relative terms.

\hypertarget{working-with-covariates}{%
\section{Working with covariates}\label{working-with-covariates}}

In linear model one can use covariates to explain part of the variance observed on the data that the `core' model does not explain. The same can be done in the \texttt{a4a} framework. The example below uses the North Atlantic Oscillation (NAO) index to model recruitment.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nao }\OtherTok{\textless{}{-}} \FunctionTok{read.table}\NormalTok{(}\StringTok{"https://www.cpc.ncep.noaa.gov/products/precip/CWlink/pna/norm.nao.monthly.b5001.current.ascii.table"}\NormalTok{, }\AttributeTok{skip=}\DecValTok{1}\NormalTok{, }\AttributeTok{fill=}\ConstantTok{TRUE}\NormalTok{, }\AttributeTok{na.strings=}\StringTok{"{-}99.90"}\NormalTok{)}
\NormalTok{dnms }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{(}\AttributeTok{quant=}\StringTok{"nao"}\NormalTok{, }\AttributeTok{year=}\DecValTok{1950}\SpecialCharTok{:}\DecValTok{2024}\NormalTok{, }\AttributeTok{unit=}\StringTok{"unique"}\NormalTok{, }\AttributeTok{season=}\DecValTok{1}\SpecialCharTok{:}\DecValTok{12}\NormalTok{, }\AttributeTok{area=}\StringTok{"unique"}\NormalTok{)}
\NormalTok{nao }\OtherTok{\textless{}{-}} \FunctionTok{FLQuant}\NormalTok{(}\FunctionTok{unlist}\NormalTok{(nao[,}\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{]), }\AttributeTok{dimnames=}\NormalTok{dnms, }\AttributeTok{units=}\StringTok{"nao"}\NormalTok{)}
\NormalTok{nao }\OtherTok{\textless{}{-}} \FunctionTok{seasonMeans}\NormalTok{(}\FunctionTok{trim}\NormalTok{(nao, }\AttributeTok{year=}\FunctionTok{dimnames}\NormalTok{(}\FunctionTok{stock.n}\NormalTok{(ple4))}\SpecialCharTok{$}\NormalTok{year))}
\end{Highlighting}
\end{Shaded}

First by simply assuming that the NAO index drives recruitment (Figure \ref{fig:naor}).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{srmod }\OtherTok{\textless{}{-}} \ErrorTok{\textasciitilde{}} \FunctionTok{s}\NormalTok{(nao, }\AttributeTok{k=}\DecValTok{10}\NormalTok{)}
\NormalTok{fit2 }\OtherTok{\textless{}{-}} \FunctionTok{sca}\NormalTok{(ple4, ple4.indices[}\DecValTok{1}\NormalTok{], }\AttributeTok{qmodel=}\FunctionTok{list}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\FunctionTok{s}\NormalTok{(age, }\AttributeTok{k=}\DecValTok{4}\NormalTok{)), }\AttributeTok{srmodel=}\NormalTok{srmod,}
       \AttributeTok{covar=}\FunctionTok{FLQuants}\NormalTok{(}\AttributeTok{nao=}\NormalTok{nao))}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/naor-1.png}
\caption{\label{fig:naor}Recruitment model with covariates. Using the NAO index as a recruitment index.}
\end{figure}

In a second model we're using the NAO index not to model recruitment directly but to model one of the parameters of the S/R function (Figure \ref{fig:naor2}).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{srmod }\OtherTok{\textless{}{-}} \ErrorTok{\textasciitilde{}} \FunctionTok{ricker}\NormalTok{(}\AttributeTok{a=}\SpecialCharTok{\textasciitilde{}}\NormalTok{nao, }\AttributeTok{CV=}\FloatTok{0.25}\NormalTok{)}
\NormalTok{fit3 }\OtherTok{\textless{}{-}} \FunctionTok{sca}\NormalTok{(ple4, ple4.indices[}\DecValTok{1}\NormalTok{], }\AttributeTok{qmodel=}\FunctionTok{list}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\FunctionTok{s}\NormalTok{(age, }\AttributeTok{k=}\DecValTok{4}\NormalTok{)), }\AttributeTok{srmodel=}\NormalTok{srmod,}
       \AttributeTok{covar=}\FunctionTok{FLQuants}\NormalTok{(}\AttributeTok{nao=}\NormalTok{nao))}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/naor2-1.png}
\caption{\label{fig:naor2}Recruitment model with covariates. Using the NAO index as a covariate for the stock-recruitment model parameters.}
\end{figure}

Note that covariates can be added to any submodel using the linear model capabilities of \texttt{R}.

\hypertarget{assessing-admb-files}{%
\section{\texorpdfstring{Assessing \texttt{ADMB} files}{Assessing ADMB files}}\label{assessing-admb-files}}

The framework gives access to all files produced to run the \texttt{ADMB} fitting routine through the argument \texttt{wkdir}. When set up, all the \texttt{ADMB} files will be left in the directory. Note that the \texttt{ADMB} tpl file is distributed with the \texttt{FLa4a}. One can get it from your \texttt{R} library, under the folder \texttt{{[}myRlib{]}/FLa4a/admb/}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit1 }\OtherTok{\textless{}{-}} \FunctionTok{sca}\NormalTok{(ple4, ple4.indices, }\AttributeTok{wkdir=}\StringTok{"fit1run"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{missing-observations-in-the-catch-matrix-or-index}{%
\section{Missing observations in the catch matrix or index}\label{missing-observations-in-the-catch-matrix-or-index}}

Missing observations are encoded as \texttt{NA}, and usually occur if there was no sampling for a year, or, since we model observations on the log scale, if the observation was zero. The \texttt{a4a} framework can deal with missing observations in the catches and indices.

The example below shows how to set up a model with missing observations in the catch matrix, to demonstrate the effect of missing observations, using the default model settings.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit }\OtherTok{\textless{}{-}} \FunctionTok{sca}\NormalTok{(ple4, ple4.indices)}
\NormalTok{ple4\_missing }\OtherTok{\textless{}{-}}\NormalTok{ ple4}
\FunctionTok{catch.n}\NormalTok{(ple4\_missing)[}\FunctionTok{ac}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\DecValTok{2}\NormalTok{), }\StringTok{"2013"}\NormalTok{] }\OtherTok{\textless{}{-}} \ConstantTok{NA}
\NormalTok{fit\_missing }\OtherTok{\textless{}{-}} \FunctionTok{sca}\NormalTok{(ple4\_missing, ple4.indices)}
\end{Highlighting}
\end{Shaded}

In effect, the information on \(F\) and \(Q\) for the missing observations is inferred from the structural assumptions of the model. If a separable \(F\) model is used, the value of \(F\) at a given age is derived from its relationship with \(F\) at other ages in the same year, as well as from the temporal relationship of \(F\) across years for ages with available data. The same principle applies to any other submodel.

The impact of missing observations is illustrated in Figure \ref{fig:obsmissing}, which shows box plots of the predicted catch at age, incorporating estimation error. When observations are missing, the resulting estimates for those ages are both different and more uncertain. Additionally, the estimates for nearby years are affected, although the influence of the missing data diminishes with time---estimates from years further away converge toward those obtained using the full dataset.

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/obsmissing-1.png}
\caption{\label{fig:obsmissing}Stock estimates with missing observations.}
\end{figure}

This is a simple example, but the same principle applies to more complex models. However, if there are many missing observations, the model cannot be too flexible; otherwise, it won't be able to reliably estimate the missing data.

In any case, one can always add more structure to the model to help address missing information. A common approach is to include a stock-recruitment relationship, which links the spawning stock biomass to recruitment. The example above would definitely benefit from this approach, as the missing information pertains to the first age group. See Figure \ref{fig:obsmissing2}, estimates are much more similar, although estimates from the fit to the missing data dataset show more uncertainty, as expected.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# bevholt s/r CV was tweaked to give best results for the example}
\NormalTok{fit2 }\OtherTok{\textless{}{-}} \FunctionTok{sca}\NormalTok{(ple4, ple4.indices, }\AttributeTok{srmodel=}\SpecialCharTok{\textasciitilde{}}\FunctionTok{bevholt}\NormalTok{(}\AttributeTok{CV=}\FloatTok{0.16}\NormalTok{))}
\NormalTok{fit\_missing2 }\OtherTok{\textless{}{-}} \FunctionTok{sca}\NormalTok{(ple4\_missing, ple4.indices, }\AttributeTok{srmodel=}\SpecialCharTok{\textasciitilde{}}\FunctionTok{bevholt}\NormalTok{(}\AttributeTok{CV=}\FloatTok{0.16}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/obsmissing2-1.png}
\caption{\label{fig:obsmissing2}Stock estimates with missing observations.}
\end{figure}

Another point to note, is that if observations are systematically missing, for example due to the actual observation being below a detection limit, or zero, then the model may overestimate the true catch at age. This is a common problem in stock assessment models, and is not unique to the \texttt{a4a} framework. Proposed solutions to this issue are to replace zeros with a small number, or half of the smallest observed value.

\hypertarget{diagnostics}{%
\chapter{\texorpdfstring{Diagnostics \label{sec:diagn}}{Diagnostics }}\label{diagnostics}}

Statistical model diagnostics are essential to identify potential issues in the model, such as violations of assumptions, outliers, and influential data points. Without proper diagnostics, fitted models may provide misleading conclusions due to violated assumptions or undetected anomalies. For instance, residual analysis is a widely used diagnostic method that assesses the discrepancy between observed and fitted values, helping to validate underlying model assumptions (\protect\hyperlink{ref-hickey2019}{Hickey et al. 2019})

The \texttt{a4a} framework implements several analysis of residuals, visualizations and statistics, that can be used to evaluate the fit quality and chose across multiple fits.

For demonstration purposes we'll use the plaice in ICES area 4 stock with a plus group at age 9 and a single index ``BTS-Combined (all)''.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# use single indices and set plus group at 9}
\NormalTok{idx }\OtherTok{\textless{}{-}}\NormalTok{ ple4.indices[}\FunctionTok{c}\NormalTok{(}\StringTok{"BTS{-}Combined (all)"}\NormalTok{)]}
\NormalTok{idx[[}\DecValTok{1}\NormalTok{]] }\OtherTok{\textless{}{-}}\NormalTok{ idx[[}\DecValTok{1}\NormalTok{]][}\DecValTok{1}\SpecialCharTok{:}\DecValTok{9}\NormalTok{]}
\NormalTok{stk }\OtherTok{\textless{}{-}} \FunctionTok{setPlusGroup}\NormalTok{(ple4, }\DecValTok{9}\NormalTok{)}
\NormalTok{iy }\OtherTok{\textless{}{-}} \DecValTok{2008}
\CommentTok{\# fit}
\NormalTok{fmod }\OtherTok{\textless{}{-}} \ErrorTok{\textasciitilde{}} \FunctionTok{factor}\NormalTok{(age)}\SpecialCharTok{+}\FunctionTok{s}\NormalTok{(year, }\AttributeTok{k=}\DecValTok{15}\NormalTok{)}\SpecialCharTok{+}\FunctionTok{te}\NormalTok{(age, year, }\AttributeTok{k=}\FunctionTok{c}\NormalTok{(}\DecValTok{3}\NormalTok{,}\DecValTok{8}\NormalTok{))}
\NormalTok{qmod }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{(}\SpecialCharTok{\textasciitilde{}} \FunctionTok{factor}\NormalTok{(age))}
\NormalTok{n1mod }\OtherTok{\textless{}{-}} \ErrorTok{\textasciitilde{}}\FunctionTok{s}\NormalTok{(age, }\AttributeTok{k=}\DecValTok{5}\NormalTok{)}
\NormalTok{vmod }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\FunctionTok{s}\NormalTok{(age, }\AttributeTok{k=}\DecValTok{4}\NormalTok{), }\SpecialCharTok{\textasciitilde{}}\DecValTok{1}\NormalTok{)}
\NormalTok{fit }\OtherTok{\textless{}{-}} \FunctionTok{sca}\NormalTok{(stk, idx, }\AttributeTok{fmodel=}\NormalTok{fmod, }\AttributeTok{qmodel=}\NormalTok{qmod, }\AttributeTok{n1model=}\NormalTok{n1mod, }\AttributeTok{vmodel=}\NormalTok{vmod)}
\end{Highlighting}
\end{Shaded}

\hypertarget{residuals}{%
\section{Residuals}\label{residuals}}

Residuals are a ubiquos metrics to check quality of a fit. For \texttt{sca()} fits there are out-of-the-box methods to compute in the log scale, raw residuals (aka deviances), standardized residuals and pearson residuals. A set of plots to inspect residuals and evaluate fit quality and assumptions are implemented.

Let \(x_{ay}\) denote either an element of the catch-at-age matrix (\(C_{ay}\)) or the abundance index (\(I_{ay})\)\footnote{For simplicity of notation we'll avoid the subscript $s$ in $I$, since we're referring to individual indices} and let \(d_{ay}\) represent the corresponding residuals.

The raw residuals are computed by \[d_{ay} = \log{x_{ay}} - \log{\tilde{x}_{ay}}\] and follow a normal distribution, \(N(0,\upsilon^2_{a})\).

Standardized residuals are computed as \[d^s_{ay} = \frac{d_{ay}}{\hat{\upsilon}^2_{a}}\] where \[\hat{\upsilon}^2_{a} = (n-1)^{-1} \sum_y(d_{ay})^2\] the variance of the residuals for age \(a\) over \(n\) years.

Pearson residuals scale raw residuals by the estimates of variance parameters and are given by
\[d^p_{ay} = \frac{d_{ay}}{\tilde{\upsilon}^2_{a}}\]
where \(\tilde{\upsilon}^2_{a} = \tilde{\sigma}^2_{a}\) for catches, or \(\tilde{\upsilon}^2_{a} = \tilde{\tau}^2_{a}\) for each index of abundance.

The \texttt{residuals()} method computes these residuals and generate a object which can be plotted using a set of out-of-the-box methods. The argument \texttt{type} will allow the user to chose which residuals will be computed. By default the method computes standardized residuals.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# residuals}
\NormalTok{d\_s }\OtherTok{\textless{}{-}} \FunctionTok{residuals}\NormalTok{(fit, stk, idx)}
\end{Highlighting}
\end{Shaded}

Figure \ref{fig:res} shows a scatterplot of standardized residuals with a smoother to guide (or mis-guide \ldots) your visual analysis. Note that the standardization should produce normal residuals with variance=1, which means that most residual values should roughly be between \(-2\) and \(2\).

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(d\_s)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/res-1.png}
\caption{\label{fig:res}Standardized residuals for abundance indices and catch numbers (catch.n). Each panel is coded by age class, dots represent standardized residuals and lines a simple smoother.}
\end{figure}

When plotting residuals, by default the auxiliary line is a smoother. However it's possible to use other type of lines by setting the argument \texttt{auxline} in \texttt{plot} (check \texttt{panel.xyplot} help page for more information), of which the relevant ones for residuals are shown in Table \ref{tab:auxargs}. If type has more than one element, an attempt is made to combine the effect of each of the components.

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 2\tabcolsep) * \real{0.2667}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 2\tabcolsep) * \real{0.7333}}@{}}
\caption{\label{tab:auxargs} Values for the argument \texttt{auxline} of residual plots}\tabularnewline
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Argument
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Description
\end{minipage} \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Argument
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Description
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\texttt{l} & lines \\
\texttt{h} & draws vertical (or horizontal if \texttt{horizontal\ =\ TRUE}) line segments from the points to the origin \\
\texttt{s} & like \texttt{l} in the sense that they join consecutive points, but instead of being joined by a straight line, points are connected by a vertical and a horizontal segment forming a `step', with the vertical segment coming first \\
\texttt{S} & same as s but the horizontal segment coming first \\
\texttt{g} & adds a reference grid \\
\texttt{r} & adds a linear regression line \\
\texttt{smooth} & adds a loess fit \\
\texttt{spline} & adds a cubic smoothing spline fit \\
\texttt{a} & draws line segments joining the average y value for each distinct x value \\
\end{longtable}

Figure \ref{fig:resaux} shows a regression line over the residuals instead of the loess smooother with a grid on the background.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# shorten time series}
\FunctionTok{plot}\NormalTok{(d\_s[}\DecValTok{1}\NormalTok{], }\AttributeTok{auxline=}\FunctionTok{c}\NormalTok{(}\StringTok{"r"}\NormalTok{,}\StringTok{"g"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/resaux-1.png}
\caption{\label{fig:resaux}Standardized residuals for catch numbers (catch.n). Each panel is coded by age class, dots represent standardized residuals and lines a regression fit.}
\end{figure}

Pearson residuals can be computed and plotted the same way as standardized residuals by setting \texttt{type=\textquotesingle{}pearson\textquotesingle{}} (Figure \ref{fig:resp}).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{d\_p }\OtherTok{\textless{}{-}} \FunctionTok{residuals}\NormalTok{(fit, stk, idx, }\AttributeTok{type=}\StringTok{\textquotesingle{}pearson\textquotesingle{}}\NormalTok{)}
\FunctionTok{plot}\NormalTok{(d\_p)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/resp-1.png}
\caption{\label{fig:resp}Pearson residuals for abundance indices and catch numbers (catch.n). Each panel is coded by age class, dots represent standardized residuals and lines a simple smoother.}
\end{figure}

Finally, the raw residuals are computed by setting \texttt{type=\textquotesingle{}deviances\textquotesingle{}} and plotted the same way as before (Figure \ref{fig:resr}). These residuals are useful to identify which data points are not well modelled, showing a large dispersion of the residuals and requiring more attention from the analyst.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{d\_r }\OtherTok{\textless{}{-}} \FunctionTok{residuals}\NormalTok{(fit, stk, idx, }\AttributeTok{type=}\StringTok{\textquotesingle{}deviances\textquotesingle{}}\NormalTok{)}
\FunctionTok{plot}\NormalTok{(d\_r)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/resr-1.png}
\caption{\label{fig:resr}Raw residuals for abundance indices and catch numbers (catch.n). Each panel is coded by age class, dots represent standardized residuals and lines a simple smoother.}
\end{figure}

The above plots can be done by age while grouping by year, instead of by year grouping by ages, the default, in which case it can help distinguish non-modeled structural year effects. The \texttt{plot} argument \texttt{by} needs to be set as \texttt{age}.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# shorten time series for demonstration purposes}
\NormalTok{d\_ss }\OtherTok{\textless{}{-}} \FunctionTok{window}\NormalTok{(d\_s, }\AttributeTok{start=}\NormalTok{iy)}
\FunctionTok{plot}\NormalTok{(d\_ss, }\AttributeTok{by=}\StringTok{\textquotesingle{}age\textquotesingle{}}\NormalTok{, }\AttributeTok{auxline=}\FunctionTok{c}\NormalTok{(}\StringTok{"h"}\NormalTok{, }\StringTok{"g"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/resy-1.png}
\caption{\label{fig:resy}Standardized residuals for abundance indices and catch numbers (catch.n). Each panel is coded by year, dots represent standardized residuals and lines a simple smoother.}
\end{figure}

The common bubble plot (\texttt{bubble()}) are shown in Figure \ref{fig:bub}. It shows the same information as Figure \ref{fig:res} but in a multivariate perspective.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{bubbles}\NormalTok{(d\_s)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/bub-1.png}
\caption{\label{fig:bub}Bubbles plot of standardized residuals for abundance indices and for catch numbers (catch.n).}
\end{figure}

Figure \ref{fig:qq} shows a quantile-quantile plot to assess how well standardized residuals match a normal distribution.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{qqmath}\NormalTok{(d\_s)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/qq-1.png}
\caption{\label{fig:qq}Quantile-quantile plot of standardized residuals for abundance indices and catch numbers (catch.n). Each panel is coded by age class, dots represent standardized residuals and lines the normal distribution quantiles.}
\end{figure}

\hypertarget{predictive-skill}{%
\section{Predictive skill}\label{predictive-skill}}

An important feature of stock assessment model fits is the capacity to predict, since one of the most important analysis done with these fits is forecasting future fishing opportunities under pre-defined conditions. The \texttt{a4a} framework implements a visualization of the fit's predictive skill for both catch-at-age and abundance indices. These are generated by the method \texttt{plot()} with the fit object and a \texttt{FLStock} (Figure \ref{fig:selplt}) or \texttt{FLIndices} (Figure \ref{fig:idxplt}) object as arguments. As before the objects will be shortened to the most recent 10 years for demonstration purposes.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(fit, stk)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/selplt-1.png}
\caption{\label{fig:selplt}Predict and observed catch-at-age}
\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(fit, idx)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/idxplt-1.png}
\caption{\label{fig:idxplt}Predict and observed abundance-at-age}
\end{figure}

\hypertarget{aggregated-catch-in-weight}{%
\section{Aggregated catch in weight}\label{aggregated-catch-in-weight}}

Although a statistical catch-at-age model assumes errors in catch-at-age and, as such, errors in the total catch in weight, there's still interest to evaluate how close the model estimates are of the observed catch in weight, even if reported catch in weight is one of the less reliable pieces of information available for stock assessment. The implementation of this diagnostics is done through the method \texttt{computeCatchDiagnostics()}, which can be visualized with \texttt{plot()} (Figure \ref{fig:catchdiag}).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fmod }\OtherTok{\textless{}{-}} \ErrorTok{\textasciitilde{}} \FunctionTok{factor}\NormalTok{(age) }\SpecialCharTok{+} \FunctionTok{factor}\NormalTok{(year) }\SpecialCharTok{+} \FunctionTok{te}\NormalTok{(age, year, }\AttributeTok{k =} \FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{15}\NormalTok{))}
\NormalTok{fit }\OtherTok{\textless{}{-}} \FunctionTok{sca}\NormalTok{(ple4, ple4.indices, }\AttributeTok{fmodel=}\NormalTok{fmod)}
\NormalTok{c\_d }\OtherTok{\textless{}{-}} \FunctionTok{computeCatchDiagnostics}\NormalTok{(fit, ple4)}
\FunctionTok{plot}\NormalTok{(c\_d)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\includegraphics[width=1\linewidth]{_bookdown_files/_main_files/figure-html/catchdiag-1} \caption{Diagnostics for age aggregated catch in weight}\label{fig:catchdiag}
\end{figure}

The \texttt{plot} method takes 2 important arguments in this case, \texttt{type} and \texttt{probs}. The first allows the analyst to choose between \texttt{all}, the plot in Figure \ref{fig:catchdiag}, and \texttt{prediction} (Figure \ref{fig:cpred}), which reports prediction error, median estimates and observations. The latter, a vector of 2 values, refers to the confidence intervals to be computed.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(c\_d, }\AttributeTok{type=}\StringTok{"prediction"}\NormalTok{, }\AttributeTok{probs=}\FunctionTok{c}\NormalTok{(}\FloatTok{0.025}\NormalTok{, }\FloatTok{0.975}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/cpred-1.png}
\caption{\label{fig:cpred}Prediction of aggregated catch in weight}
\end{figure}

\hypertarget{fit-summary-information-and-cross-validation-metrics}{%
\section{Fit summary, information and cross-validation metrics}\label{fit-summary-information-and-cross-validation-metrics}}

To get information about the likelihood fit the method \texttt{fitSumm()} can be used to report number of parameters (\texttt{npar}), negative log-likelkihood (\texttt{nlogl}), \texttt{ADMB} maximum gradient par (\texttt{maxgrad}), number of observations (\texttt{nobs}), generalized cross validation score (\texttt{gcv}), convergence flag (\texttt{convergence}) and acceptance rate (\texttt{accrate}) relevant for MCMC fits only.

The GCV is implemented as described by S. N. Wood (\protect\hyperlink{ref-Wood2017}{2017}), where the author explains that minimizing the GCV score helps balance the trade-off between model fit and smoothness, effectively preventing overfitting by penalizing excessive complexity. For more information on the other metrics check Project (\protect\hyperlink{ref-admb123manual}{2013}) and Cole C. Monnahan, Muradian, and Kuriyama (\protect\hyperlink{ref-monnahan2014admbmcmc}{2014}).

The second part refers to the likelihood value for each component. The first component is catch-at-age, components after the first are for indices and the last component is for the recruitment model, if set.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit }\OtherTok{\textless{}{-}} \FunctionTok{sca}\NormalTok{(ple4, ple4.indices, }\AttributeTok{srmodel=}\SpecialCharTok{\textasciitilde{}}\FunctionTok{bevholt}\NormalTok{(}\AttributeTok{CV=}\FloatTok{0.2}\NormalTok{))}
\FunctionTok{fitSumm}\NormalTok{(fit)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##              iters
##                           1
##   nopar        2.890000e+02
##   nlogl       -2.458172e+02
##   maxgrad      2.514104e-05
##   nobs         1.728000e+03
##   gcv          1.240412e-01
##   convergence  0.000000e+00
##   accrate                NA
##   nlogl_comp1 -1.054070e+03
##   nlogl_comp2  6.733170e+01
##   nlogl_comp3  5.910930e+01
##   nlogl_comp4  3.965180e+02
##   nlogl_comp5  6.138520e+01
##   nlogl_comp6  6.335820e+01
##   nlogl_comp7  2.962780e+01
##   nlogl_comp8  1.309180e+02
\end{verbatim}

Information criteria based metrics are reported with the methods \texttt{AIC} and \texttt{BIC}, check Ding (\protect\hyperlink{ref-ding2023information}{2023}) for a primer on these metrics. According to Ding (\protect\hyperlink{ref-ding2023information}{2023}) the AIC can lead to the selection of more complex models that may fit the data better, especially in smaller sample sizes, while the BIC incorporates a stronger penalty for model complexity. In both cases, when comparing models, the lower the score the better the model fits according to these information criteria.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{AIC}\NormalTok{(fit)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 86.36567
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{BIC}\NormalTok{(fit)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1662.78
\end{verbatim}

\hypertarget{retrospective-analysis}{%
\section{Retrospective analysis}\label{retrospective-analysis}}

Retrospective analysis involves sequentially removing the most recent year of data, refitting the model, and comparing key metric estimates, \emph{e.g.} the estimate of fishing mortality in year \(y_{-1}\) across different fits, using a statistic like Mohn's rho (\protect\hyperlink{ref-mohn1999retrospective}{Mohn 1999}). The rationale is that a well-fitted, stable model should yield consistent estimates despite changes in the data.

This method originated from Virtual Population Analysis (VPA) (\protect\hyperlink{ref-pope1972}{Pope 1972}), which estimates fishing mortality and abundance by working backward from the most recent years. In contrast, retrospective analysis is less directly applicable to statistical catch-at-age models, as these models typically start from the beginning of the time series and the youngest age class, working forward through time. As noted by Cadrin (\protect\hyperlink{ref-cadrin2025misinterpreting}{2025}), there is a risk of circular reasoning when this method is used to both diagnose and validate stock assessment models. Nevertheless, many experts still rely on retrospective analysis to evaluate model performance.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit0 }\OtherTok{\textless{}{-}} \FunctionTok{sca}\NormalTok{(ple4, ple4.indices)}
\NormalTok{n }\OtherTok{\textless{}{-}} \DecValTok{5}
\NormalTok{nret }\OtherTok{\textless{}{-}} \FunctionTok{as.list}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\NormalTok{n)}
\NormalTok{stks }\OtherTok{\textless{}{-}} \FunctionTok{FLStocks}\NormalTok{(}\FunctionTok{lapply}\NormalTok{(nret, }\ControlFlowTok{function}\NormalTok{(x)\{}\FunctionTok{window}\NormalTok{(ple4, }\AttributeTok{end=}\NormalTok{(}\FunctionTok{range}\NormalTok{(ple4)[}\StringTok{"maxyear"}\NormalTok{]}\SpecialCharTok{{-}}\NormalTok{x))\}))}
\NormalTok{idxs }\OtherTok{\textless{}{-}} \FunctionTok{lapply}\NormalTok{(nret, }\ControlFlowTok{function}\NormalTok{(x)\{}\FunctionTok{window}\NormalTok{(ple4.indices, }\AttributeTok{end=}\NormalTok{(}\FunctionTok{range}\NormalTok{(ple4)[}\StringTok{"maxyear"}\NormalTok{]}\SpecialCharTok{{-}}\NormalTok{x))\})}
\NormalTok{fits }\OtherTok{\textless{}{-}} \FunctionTok{scas}\NormalTok{(stks, idxs, }\AttributeTok{fmodel=}\FunctionTok{list}\NormalTok{(}\FunctionTok{fmodel}\NormalTok{(fit0)))}
\NormalTok{stks }\OtherTok{\textless{}{-}}\NormalTok{ stks }\SpecialCharTok{+}\NormalTok{ fits}
\NormalTok{stks[[}\DecValTok{6}\NormalTok{]] }\OtherTok{\textless{}{-}}\NormalTok{ ple4 }\SpecialCharTok{+} \FunctionTok{simulate}\NormalTok{(fit0, }\DecValTok{250}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Note fmodel doesn't change:

\begin{verbatim}
## $fit1
## ~te(age, year, k = c(6, 30), bs = "tp") + s(age, k = 6)
## <environment: 0x6447c39ef058>
## 
## $fit2
## ~te(age, year, k = c(6, 30), bs = "tp") + s(age, k = 6)
## <environment: 0x6447c39ef058>
## 
## $fit3
## ~te(age, year, k = c(6, 30), bs = "tp") + s(age, k = 6)
## <environment: 0x6447c39ef058>
## 
## $fit4
## ~te(age, year, k = c(6, 30), bs = "tp") + s(age, k = 6)
## <environment: 0x6447c39ef058>
## 
## $fit5
## ~te(age, year, k = c(6, 30), bs = "tp") + s(age, k = 6)
## <environment: 0x6447c39ef058>
\end{verbatim}

The retrospective plot shown below presents the current fit with uncertainty and each retrospective fit on top. If the retrospective fit is not within the confidence interval of the current fit the analyst can argue that the estimate is different and as such reflecting a ``poor'' fit.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(}\FunctionTok{window}\NormalTok{(stks, }\AttributeTok{start=}\DecValTok{2005}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/retro-1.png}
\caption{\label{fig:retro}Retrospective analysis of the plaice in ICES area IV stock. Fixed F model.}
\end{figure}

One could use specific submodels and pass them to the fitting function \texttt{scas()}, including with some adjustments to take into account the data reduction. In the next example the fishing mortality model is set reducing the smoothness taking into account the length of the dataset. Not considering the adjustment of the model to the new dataset may result in comparisons across models which are very different due to the relationship between information contained in the data and the number of parameters in the model. This issue is more relevant for stocks with shorter time series.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{n }\OtherTok{\textless{}{-}} \DecValTok{5}
\NormalTok{nret }\OtherTok{\textless{}{-}} \FunctionTok{as.list}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\NormalTok{n)}
\NormalTok{stks }\OtherTok{\textless{}{-}} \FunctionTok{FLStocks}\NormalTok{(}\FunctionTok{lapply}\NormalTok{(nret, }\ControlFlowTok{function}\NormalTok{(x)\{}\FunctionTok{window}\NormalTok{(ple4, }\AttributeTok{end=}\NormalTok{(}\FunctionTok{range}\NormalTok{(ple4)[}\StringTok{"maxyear"}\NormalTok{]}\SpecialCharTok{{-}}\NormalTok{x))\}))}
\NormalTok{idxs }\OtherTok{\textless{}{-}} \FunctionTok{lapply}\NormalTok{(nret, }\ControlFlowTok{function}\NormalTok{(x)\{}\FunctionTok{window}\NormalTok{(ple4.indices, }\AttributeTok{end=}\NormalTok{(}\FunctionTok{range}\NormalTok{(ple4)[}\StringTok{"maxyear"}\NormalTok{]}\SpecialCharTok{{-}}\NormalTok{x))\})}
\CommentTok{\# each model will have smootheness scaled to length of time series}
\NormalTok{fmod }\OtherTok{\textless{}{-}} \FunctionTok{lapply}\NormalTok{(stks, defaultFmod)}
\NormalTok{fits }\OtherTok{\textless{}{-}} \FunctionTok{scas}\NormalTok{(stks, idxs, }\AttributeTok{fmodel=}\NormalTok{fmod)}
\NormalTok{stks }\OtherTok{\textless{}{-}}\NormalTok{ stks }\SpecialCharTok{+}\NormalTok{ fits}
\NormalTok{stks[[}\DecValTok{6}\NormalTok{]] }\OtherTok{\textless{}{-}}\NormalTok{ ple4 }\SpecialCharTok{+} \FunctionTok{simulate}\NormalTok{(fit0, }\DecValTok{250}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Note fmodel changes:

\begin{verbatim}
## $fit1
## ~te(age, year, k = c(6, 30), bs = "tp") + s(age, k = 6)
## <environment: 0x6447cccd15e0>
## 
## $fit2
## ~te(age, year, k = c(6, 29), bs = "tp") + s(age, k = 6)
## <environment: 0x6447d167f840>
## 
## $fit3
## ~te(age, year, k = c(6, 29), bs = "tp") + s(age, k = 6)
## <environment: 0x6447cd71d988>
## 
## $fit4
## ~te(age, year, k = c(6, 28), bs = "tp") + s(age, k = 6)
## <environment: 0x6447c4209328>
## 
## $fit5
## ~te(age, year, k = c(6, 28), bs = "tp") + s(age, k = 6)
## <environment: 0x6447caaae960>
\end{verbatim}

And the retrospective plot

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(}\FunctionTok{window}\NormalTok{(stks, }\AttributeTok{start=}\DecValTok{2005}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/retro2-1.png}
\caption{\label{fig:retro2}Retrospective analysis of the plaice in ICES area IV stock. Updating F model.}
\end{figure}

\hypertarget{hindcast}{%
\section{Hindcast}\label{hindcast}}

A hindcast is a method used in modeling and simulation where historical data is used to test and validate predictive models. In a hindcast, known outcomes from the past are compared with the model's predictions to assess the model's accuracy and performance. The primary goal of hindcasting is to improve the reliability and accuracy of predictive models by identifying discrepancies between predicted and actual outcomes and adjusting model parameters accordingly (\protect\hyperlink{ref-hc2002}{Mason and Mimmack 2002}). The term retroactive forecasting is used by Mason and Mimmack (\protect\hyperlink{ref-hc2002}{2002}) to denote the form of hindcasting in which forecasts are made for past years (e.g.~2006--2010) using data prior to those years (perhaps 1970--2005). The terminology ex-post is used in business forecasting, referring to predictions for historical periods for which verification data are already available at the time of forecast.

For this exercise we'll use the package \texttt{a4adiags} hindcast method, which follows the suggestions by Carvalho et al. (\protect\hyperlink{ref-cookbook2021}{2021}) and Laurence T. Kell, Kimoto, and Kitakado (\protect\hyperlink{ref-KELL2016119}{2016}). The hindcast is carried out by sequentially removing the most recent year in the data, similar to a retrospective analysis, refit the stock assessment model and project one year ahead. The Mean Absolute Scale Error (MASE) (\protect\hyperlink{ref-cookbook2021}{Carvalho et al. 2021}) is used to assess the predictive skill, a score higher than 1 indicates that the model forecasts have less skill than a random walk.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(a4adiags)}
\FunctionTok{theme\_set}\NormalTok{(}\FunctionTok{theme\_bw}\NormalTok{())}
\NormalTok{nyears }\OtherTok{\textless{}{-}} \DecValTok{5}
\CommentTok{\# set number of year for average biology and selectivity}
\NormalTok{nsq }\OtherTok{\textless{}{-}} \DecValTok{3}
\NormalTok{hc }\OtherTok{\textless{}{-}} \FunctionTok{a4ahcxval}\NormalTok{(ple4, ple4.indices, }\AttributeTok{nyears =}\NormalTok{ nyears, }\AttributeTok{nsq =}\NormalTok{ nsq)}
\end{Highlighting}
\end{Shaded}

Figure \ref{fig:hc} depicts the hincast results for the abundance indices used in the assessment. The MASE value is included in the strip above the plot. In this case one can see that 3 out of the 5 surveys are not better predictors than a random walk.

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/hc-1.png}
\caption{\label{fig:hc}Survey predictions of year ahead indices in hindcast process. The MASE is presented in the strip about the index and is related to the predictive skill of the index.}
\end{figure}

\hypertarget{uncertainty}{%
\chapter{\texorpdfstring{Uncertainty \label{sec:predsim}}{Uncertainty }}\label{uncertainty}}

Uncertainty is a fundamental aspect of scientific advice, serving as a reflection of the inherent limitations within the knowledge base used to construct evidence and support scientific opinions. It highlights the gaps, variability, and potential biases present in data, methods, and modeling assumptions that underlie scientific conclusions.

In fisheries science, a field that has evolved primarily to provide evidence-based advice for the sustainable exploitation of marine resources, acknowledging and addressing uncertainty is of major importance. Given the dynamic, complex, and partially observable nature of aquatic ecosystems, the need to systematically characterize and communicate uncertainty is paramount to ensuring robust and credible assessments (\protect\hyperlink{ref-privitera2019}{Privitera-Johnson and Punt 2019}).

In this section we'll address two important elements of quantifying uncertainty in stock assessment results, prediction error\footnote{Work in progress} and propagation of uncertainty across modelling stages.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(FLa4a)}
\FunctionTok{library}\NormalTok{(ggplot2)}
\FunctionTok{data}\NormalTok{(hke1567)}
\FunctionTok{data}\NormalTok{(hke1567.idx)}
\end{Highlighting}
\end{Shaded}

The two workhorses for this topic are \texttt{predict()} and \texttt{simulate()} which are implemented to work with \texttt{sca} fits of type \texttt{"assessment"}. Note \texttt{fit\ =\ "MP"} doesn't compute the variance-covariance matrix of the parameters, which is essential for simulating.

This chapter is based on the following model:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nsim }\OtherTok{\textless{}{-}} \DecValTok{250}
\NormalTok{fmod }\OtherTok{\textless{}{-}} \ErrorTok{\textasciitilde{}}\FunctionTok{s}\NormalTok{(age, }\AttributeTok{k =} \DecValTok{4}\NormalTok{) }\SpecialCharTok{+}
    \FunctionTok{s}\NormalTok{(year, }\AttributeTok{k =} \DecValTok{8}\NormalTok{) }\SpecialCharTok{+}
    \FunctionTok{s}\NormalTok{(year, }\AttributeTok{k =} \DecValTok{8}\NormalTok{, }\AttributeTok{by =} \FunctionTok{as.numeric}\NormalTok{(age }\SpecialCharTok{==} \DecValTok{0}\NormalTok{)) }\SpecialCharTok{+}
    \FunctionTok{s}\NormalTok{(year, }\AttributeTok{k =} \DecValTok{8}\NormalTok{, }\AttributeTok{by =} \FunctionTok{as.numeric}\NormalTok{(age }\SpecialCharTok{==} \DecValTok{4}\NormalTok{))}
\NormalTok{qmod }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\FunctionTok{I}\NormalTok{(}\DecValTok{1}\SpecialCharTok{/}\NormalTok{(}\DecValTok{1} \SpecialCharTok{+} \FunctionTok{exp}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{age))))}
\NormalTok{fit0 }\OtherTok{\textless{}{-}} \FunctionTok{sca}\NormalTok{(hke1567, hke1567.idx, }\AttributeTok{fmodel=}\NormalTok{fmod, }\AttributeTok{qmodel=}\NormalTok{qmod)}
\NormalTok{stk0 }\OtherTok{\textless{}{-}}\NormalTok{ hke1567 }\SpecialCharTok{+}\NormalTok{ fit0}
\end{Highlighting}
\end{Shaded}

\hypertarget{the-simulate-and-predict-methods}{%
\section{\texorpdfstring{The \texttt{simulate} and \texttt{predict} methods}{The simulate and predict methods}}\label{the-simulate-and-predict-methods}}

\hypertarget{predict}{%
\subsection{\texorpdfstring{\texttt{predict()}}{predict()}}\label{predict}}

The predict method computes the quantities of interest using the estimated coefficients and the design matrix of the model, defined via the formulas in the submodels. The method uses a fitted model object, created by a call to \texttt{sca}, and returns a list with one element for each submodel, where each element is a \texttt{FLQuants} object.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit.pred }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(fit0)}
\FunctionTok{lapply}\NormalTok{(fit.pred, names)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## $stkmodel
## [1] "harvest" "rec"     "ny1"    
## 
## $qmodel
## [1] "IND"
## 
## $vmodel
## [1] "catch" "IND"
\end{verbatim}

The \texttt{stkmodel} element reports \texttt{harvest}, \texttt{rec} and \texttt{ny1}. The \texttt{qmodel} reports one \texttt{FLQuant} for each index, and the \texttt{vmodel} element returns one \texttt{FLQuant} for catch (in fact \texttt{catch.n}) and one for each index. This allows easy access to the parameterised parts of the model, for example the initial population structure, \texttt{ny1}, can be accessed via \texttt{fit.pred\$stkmodel\$ny1}.

\begin{verbatim}
## An object of class "FLQuant"
## , , unit = unique, season = all, area = unique
## 
##    year
## age 2007  
##   0 366994
##   1  33695
##   2   4107
##   3    803
##   4    306
##   5    187
## 
## units:  1000
\end{verbatim}

If the fitted object has iterations, as after using the \texttt{simulate} method, which will be discussed in the next section, predict will be applied to each iter, generating distributions of the above mentioned quantities (Figure \ref{fig:simny1}).

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/simny1-1.png}
\caption{\label{fig:simny1}Simulations from the model prediction of initial age structure}
\end{figure}

\hypertarget{simulate}{%
\subsection{\texorpdfstring{\texttt{simulate()}}{simulate()}}\label{simulate}}

As the name implies \texttt{simulate} is used to generate simulations of the fit. It operates over objects of class \texttt{a4aFitSA} using the method \texttt{mvrnorm()} provided by the R package MASS (\protect\hyperlink{ref-mass}{Venables and Ripley 2002}). The method generates random draws from a multivariate normal distribution with mean given by the coefficients of the model, and variance matrix given by the estimated covariance matrix of the coefficients. The method approximates the joint distribution of the model parameters as a multivariate normal in the log space, which is inline with the assumption made by \texttt{ADMB} when fitting the model. This approach is called `parametric bootstrap', and it's a common method for generating uncertainty in the parameters of a model.

\texttt{simulate()} operates at the submodel level, \emph{e.g.} \texttt{simulate(fit0@pars@qmodel,\ nsim=250)}, when called over a \texttt{a4aFitSA} object the method simply runs \texttt{simulate()} over each of the submodels. In this case it returns an object of the same class with model parameters replaced by \texttt{nsim} simulated parameters and updated slots \texttt{stock.n}, \texttt{catch.n} and \texttt{harvest}. Figure \ref{fig:predsimhist} depicts the distribution of a parameter, the observation error of the first survey index.

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/predsimhist-1.png}
\caption{\label{fig:predsimhist}Histogram of 250 draws from the approximate distribution of the estimate of survey observation error.}
\end{figure}

In some simulation studies one needs to make sure the random draws are the same, which in \texttt{R} is obtained by explicitly setting the random seed with the method \texttt{set.seed()}. The same is achieved in this case as the example below shows.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1234}\NormalTok{)}
\NormalTok{fit.sim1 }\OtherTok{\textless{}{-}} \FunctionTok{simulate}\NormalTok{(fit0, }\AttributeTok{nsim =} \DecValTok{250}\NormalTok{)}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1234}\NormalTok{)}
\NormalTok{fit.sim2 }\OtherTok{\textless{}{-}} \FunctionTok{simulate}\NormalTok{(fit0, }\AttributeTok{nsim =} \DecValTok{250}\NormalTok{)}
\FunctionTok{all.equal}\NormalTok{(fit.sim1, fit.sim2)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] TRUE
\end{verbatim}

If the whole stock is of interest, for example, to inspect model predictions of \(SSB\), the user should use the \texttt{+} method with a fitted object including iterations. In such case the \texttt{stock.n}, \texttt{catch.n} and \texttt{harvest} slots of the stock object will be updated and the usual metrics can be computed and extracted, \emph{e.g.} \texttt{ssb(stk.pred)}. Figure \ref{fig:sim2} depicts the stock summary plot after adding estimation uncertainty through \texttt{simulate}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{stk.pred }\OtherTok{\textless{}{-}}\NormalTok{ hke1567 }\SpecialCharTok{+}\NormalTok{ fit.sim}
\FunctionTok{plot}\NormalTok{(}\FunctionTok{FLStocks}\NormalTok{(}\AttributeTok{simulated=}\NormalTok{stk.pred, }\AttributeTok{fitted=}\NormalTok{stk0))}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/sim2-1.png}
\caption{\label{fig:sim2}Stock summary of the simulated and fitted data}
\end{figure}

\hypertarget{prediction-error}{%
\section{Prediction error}\label{prediction-error}}

To address this topic we'll borrow from state-space modelling to define prediction error as the combination of observation error and estimation error (REF). Although \texttt{sca()} is not a state-space model, some of the inherent concepts of statistical catch at age models are similar to state-space models. \texttt{sca()} estimates parameters to model underlying unobserved processes, \emph{e.g.} recruitment, catchability or fishing mortality, based on indirect observations of those processes, number of fish caught by the fleet and changes in abundance at sea.

Another similar approach can be found in statistical learning model. Hastie, Tibshirani, and Friedman (\protect\hyperlink{ref-hastie2009}{2009}) decomposes prediction error into irreducible error, square bias and variance. Where the first term refers to variance that cannot be avoided, in our case estimated by residual variance. The second term, bias is ignored as the true value isn't known and the fits are assumed to be unbiased. The last term is the variance of the prediction due to the training dataset samples, which we're approximating with parameter estimation variance.

However, \texttt{sca}'s residuals are estimates of observation error (measurement noise) and model error (misspecification, omitted variables), which means it will be an overestimate of observation error.

Nevertheless, in this section we'll assume prediction error to be the sum of residual variance and estimation variance, and will describe how to compute both elements and bringing them together in a \texttt{FLStock} object.

We'll make extensive use of \texttt{+} for this analysis. When operating between a \texttt{FLStock} object and a \texttt{a4aFit} object, the method replaces the slots estimated by the model with its estimates. If operating between a \texttt{FLStock} object and a \texttt{a4aFitResiduals} object, the method will use the values in the \texttt{FLStock} object and add lognormal multiplicative error. When computing prediction uncertainty both sources need to be added, which means the sequence matters. To perform the computations correctly, residual uncertainty needs to be added after estimation uncertainty, so it will add uncertainty to the updated estimates.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nsim }\OtherTok{\textless{}{-}} \DecValTok{250}
\NormalTok{fmod }\OtherTok{\textless{}{-}} \ErrorTok{\textasciitilde{}}\FunctionTok{s}\NormalTok{(age, }\AttributeTok{k =} \DecValTok{4}\NormalTok{) }\SpecialCharTok{+}
    \FunctionTok{s}\NormalTok{(year, }\AttributeTok{k =} \DecValTok{8}\NormalTok{) }\SpecialCharTok{+}
    \FunctionTok{s}\NormalTok{(year, }\AttributeTok{k =} \DecValTok{8}\NormalTok{, }\AttributeTok{by =} \FunctionTok{as.numeric}\NormalTok{(age }\SpecialCharTok{==} \DecValTok{0}\NormalTok{)) }\SpecialCharTok{+}
    \FunctionTok{s}\NormalTok{(year, }\AttributeTok{k =} \DecValTok{8}\NormalTok{, }\AttributeTok{by =} \FunctionTok{as.numeric}\NormalTok{(age }\SpecialCharTok{==} \DecValTok{4}\NormalTok{))}
\NormalTok{qmod }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\FunctionTok{I}\NormalTok{(}\DecValTok{1}\SpecialCharTok{/}\NormalTok{(}\DecValTok{1} \SpecialCharTok{+} \FunctionTok{exp}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{age))))}
\NormalTok{fit0 }\OtherTok{\textless{}{-}} \FunctionTok{sca}\NormalTok{(hke1567, hke1567.idx, }\AttributeTok{fmodel=}\NormalTok{fmod, }\AttributeTok{qmodel=}\NormalTok{qmod)}
\NormalTok{stk0 }\OtherTok{\textless{}{-}}\NormalTok{ hke1567 }\SpecialCharTok{+}\NormalTok{ fit0}

\CommentTok{\# compute deviances}
\NormalTok{res0 }\OtherTok{\textless{}{-}} \FunctionTok{residuals}\NormalTok{(fit0, hke1567, hke1567.idx, }\AttributeTok{type=}\StringTok{"deviances"}\NormalTok{)}
\CommentTok{\# build object with estimation uncertainty}
\NormalTok{stk.eu }\OtherTok{\textless{}{-}}\NormalTok{ hke1567 }\SpecialCharTok{+} \FunctionTok{simulate}\NormalTok{(fit0, nsim)}
\CommentTok{\# build object with residual uncertainty}
\NormalTok{stk.ru }\OtherTok{\textless{}{-}} \FunctionTok{propagate}\NormalTok{(stk0, nsim) }\SpecialCharTok{+}\NormalTok{ res0}
\CommentTok{\# build object with prediction uncertainty}
\NormalTok{stk.pu }\OtherTok{\textless{}{-}}\NormalTok{ hke1567 }\SpecialCharTok{+} \FunctionTok{simulate}\NormalTok{(fit0, nsim) }\SpecialCharTok{+}\NormalTok{ res0}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/preduncert-1.png}
\caption{\label{fig:preduncert}Prediction (pu), residual (ru) and estimation (eu) uncertainty}
\end{figure}

\hypertarget{confidence-interval-coverage}{%
\section{Confidence interval coverage}\label{confidence-interval-coverage}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cv }\OtherTok{\textless{}{-}} \FloatTok{0.5}
\NormalTok{sn }\OtherTok{\textless{}{-}} \FunctionTok{genFLQuant}\NormalTok{(fit0}\SpecialCharTok{@}\NormalTok{stock.n, }\AttributeTok{cv=}\NormalTok{cv)}
\NormalTok{ff }\OtherTok{\textless{}{-}} \FunctionTok{genFLQuant}\NormalTok{(fit0}\SpecialCharTok{@}\NormalTok{harvest, }\AttributeTok{cv=}\NormalTok{cv, }\AttributeTok{niter=}\NormalTok{nsim)}
\NormalTok{stk00 }\OtherTok{\textless{}{-}} \FunctionTok{genFLStock}\NormalTok{(stk0, }\AttributeTok{R=}\NormalTok{sn[}\DecValTok{1}\NormalTok{], }\AttributeTok{F=}\NormalTok{ff, }\AttributeTok{ny1=}\NormalTok{sn[,}\DecValTok{1}\NormalTok{])}
\NormalTok{idx00 }\OtherTok{\textless{}{-}}\NormalTok{ hke1567.idx}
\FunctionTok{index}\NormalTok{(idx00) }\OtherTok{\textless{}{-}}  \FunctionTok{predict}\NormalTok{(}\FunctionTok{simulate}\NormalTok{(fit0, nsim))}\SpecialCharTok{$}\NormalTok{qmodel[[}\DecValTok{1}\NormalTok{]]}\SpecialCharTok{*}\NormalTok{sn[}\FunctionTok{ac}\NormalTok{(}\DecValTok{0}\SpecialCharTok{:}\DecValTok{4}\NormalTok{)]}
\NormalTok{fit00 }\OtherTok{\textless{}{-}} \FunctionTok{sca}\NormalTok{(stk00, idx00, }\AttributeTok{fmodel=}\NormalTok{fmod, }\AttributeTok{qmodel=}\NormalTok{qmod)}
\NormalTok{stk00 }\OtherTok{\textless{}{-}}\NormalTok{ stk00 }\SpecialCharTok{+}\NormalTok{ fit00}

\CommentTok{\# objects to store results}
\NormalTok{flq }\OtherTok{\textless{}{-}} \FunctionTok{ssb}\NormalTok{(stk00) }\CommentTok{\#expand(ssb(stk0), unit=c("eu", "ru", "pu"), iter=1:nsim)}
\NormalTok{flq[] }\OtherTok{\textless{}{-}} \ConstantTok{NA}
\NormalTok{ssb.cicvg }\OtherTok{\textless{}{-}} \FunctionTok{FLQuants}\NormalTok{(}\StringTok{"eu"}\OtherTok{=}\NormalTok{flq, }\StringTok{"ru"}\OtherTok{=}\NormalTok{flq, }\StringTok{"pu"}\OtherTok{=}\NormalTok{flq)}
\NormalTok{flq }\OtherTok{\textless{}{-}} \FunctionTok{expand}\NormalTok{(flq, }\AttributeTok{age=}\FunctionTok{c}\NormalTok{(}\StringTok{"l"}\NormalTok{, }\StringTok{"u"}\NormalTok{))}
\NormalTok{ssb.ci }\OtherTok{\textless{}{-}} \FunctionTok{FLQuants}\NormalTok{(}\StringTok{"eu"}\OtherTok{=}\NormalTok{flq, }\StringTok{"ru"}\OtherTok{=}\NormalTok{flq, }\StringTok{"pu"}\OtherTok{=}\NormalTok{flq)}

\CommentTok{\# remove iters that failed}
\NormalTok{vv }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\SpecialCharTok{!}\FunctionTok{is.na}\NormalTok{(fit00}\SpecialCharTok{@}\NormalTok{stock.n[}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{]))}

\CommentTok{\# loop through iters, compute CI, check if OM value is within interval}
\ControlFlowTok{for}\NormalTok{(i }\ControlFlowTok{in}\NormalTok{ (}\DecValTok{1}\SpecialCharTok{:}\NormalTok{nsim)[vv])\{}

  \CommentTok{\# residual uncertainty}
\NormalTok{  res00 }\OtherTok{\textless{}{-}} \FunctionTok{residuals}\NormalTok{(}\FunctionTok{iter}\NormalTok{(fit00, i), }\FunctionTok{iter}\NormalTok{(stk00, i), }\FunctionTok{iter}\NormalTok{(idx00, i), }\AttributeTok{type=}\StringTok{"deviances"}\NormalTok{)}
\NormalTok{  stk }\OtherTok{\textless{}{-}} \FunctionTok{propagate}\NormalTok{(}\FunctionTok{iter}\NormalTok{(stk00, i), nsim) }\SpecialCharTok{+}\NormalTok{ res00}
\NormalTok{  qtl }\OtherTok{\textless{}{-}} \FunctionTok{quantile}\NormalTok{(}\FunctionTok{ssb}\NormalTok{(stk), }\AttributeTok{probs=}\FunctionTok{c}\NormalTok{(}\FloatTok{0.025}\NormalTok{, }\FloatTok{0.975}\NormalTok{), }\AttributeTok{na.rm=}\ConstantTok{TRUE}\NormalTok{)}
\NormalTok{  ssb.cicvg[[}\StringTok{"eu"}\NormalTok{]][,,,,, i] }\OtherTok{\textless{}{-}} \FunctionTok{ssb}\NormalTok{(stk0)}\SpecialCharTok{\textgreater{}=}\FunctionTok{iter}\NormalTok{(qtl, }\DecValTok{1}\NormalTok{) }\SpecialCharTok{\&} \FunctionTok{ssb}\NormalTok{(stk0)}\SpecialCharTok{\textless{}=}\FunctionTok{iter}\NormalTok{(qtl, }\DecValTok{2}\NormalTok{)}
\NormalTok{  ssb.ci[[}\StringTok{"eu"}\NormalTok{]][}\StringTok{"l"}\NormalTok{,,,,, i] }\OtherTok{\textless{}{-}} \FunctionTok{iter}\NormalTok{(qtl,}\DecValTok{1}\NormalTok{)}
\NormalTok{  ssb.ci[[}\StringTok{"eu"}\NormalTok{]][}\StringTok{"u"}\NormalTok{,,,,, i] }\OtherTok{\textless{}{-}} \FunctionTok{iter}\NormalTok{(qtl,}\DecValTok{2}\NormalTok{)}

  \CommentTok{\# estimation uncertainty}
\NormalTok{  stk }\OtherTok{\textless{}{-}} \FunctionTok{iter}\NormalTok{(stk00, i) }\SpecialCharTok{+} \FunctionTok{simulate}\NormalTok{(}\FunctionTok{iter}\NormalTok{(fit00, i), }\DecValTok{250}\NormalTok{)}
\NormalTok{  qtl }\OtherTok{\textless{}{-}} \FunctionTok{quantile}\NormalTok{(}\FunctionTok{ssb}\NormalTok{(stk), }\AttributeTok{probs=}\FunctionTok{c}\NormalTok{(}\FloatTok{0.025}\NormalTok{, }\FloatTok{0.975}\NormalTok{), }\AttributeTok{na.rm=}\ConstantTok{TRUE}\NormalTok{)}
\NormalTok{  ssb.cicvg[[}\StringTok{"ru"}\NormalTok{]][,,,,, i] }\OtherTok{\textless{}{-}} \FunctionTok{ssb}\NormalTok{(stk0)}\SpecialCharTok{\textgreater{}=}\FunctionTok{iter}\NormalTok{(qtl, }\DecValTok{1}\NormalTok{) }\SpecialCharTok{\&} \FunctionTok{ssb}\NormalTok{(stk0)}\SpecialCharTok{\textless{}=}\FunctionTok{iter}\NormalTok{(qtl, }\DecValTok{2}\NormalTok{)}
\NormalTok{  ssb.ci[[}\StringTok{"ru"}\NormalTok{]][}\StringTok{"l"}\NormalTok{,,,,, i] }\OtherTok{\textless{}{-}} \FunctionTok{iter}\NormalTok{(qtl,}\DecValTok{1}\NormalTok{)}
\NormalTok{  ssb.ci[[}\StringTok{"ru"}\NormalTok{]][}\StringTok{"u"}\NormalTok{,,,,, i] }\OtherTok{\textless{}{-}} \FunctionTok{iter}\NormalTok{(qtl,}\DecValTok{2}\NormalTok{)}

  \CommentTok{\# prediction uncertainty}
\NormalTok{  stk }\OtherTok{\textless{}{-}}\NormalTok{ stk }\SpecialCharTok{+}\NormalTok{ res00}
\NormalTok{  qtl }\OtherTok{\textless{}{-}} \FunctionTok{quantile}\NormalTok{(}\FunctionTok{ssb}\NormalTok{(stk), }\AttributeTok{probs=}\FunctionTok{c}\NormalTok{(}\FloatTok{0.025}\NormalTok{, }\FloatTok{0.975}\NormalTok{), }\AttributeTok{na.rm=}\ConstantTok{TRUE}\NormalTok{)}
\NormalTok{  ssb.cicvg[[}\StringTok{"pu"}\NormalTok{]][,,,,, i] }\OtherTok{\textless{}{-}} \FunctionTok{ssb}\NormalTok{(stk0)}\SpecialCharTok{\textgreater{}=}\FunctionTok{iter}\NormalTok{(qtl, }\DecValTok{1}\NormalTok{) }\SpecialCharTok{\&} \FunctionTok{ssb}\NormalTok{(stk0)}\SpecialCharTok{\textless{}=}\FunctionTok{iter}\NormalTok{(qtl, }\DecValTok{2}\NormalTok{)}
\NormalTok{  ssb.ci[[}\StringTok{"pu"}\NormalTok{]][}\StringTok{"l"}\NormalTok{,,,,, i] }\OtherTok{\textless{}{-}} \FunctionTok{iter}\NormalTok{(qtl,}\DecValTok{1}\NormalTok{)}
\NormalTok{  ssb.ci[[}\StringTok{"pu"}\NormalTok{]][}\StringTok{"u"}\NormalTok{,,,,, i] }\OtherTok{\textless{}{-}} \FunctionTok{iter}\NormalTok{(qtl,}\DecValTok{2}\NormalTok{)}

\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\hypertarget{propagate-uncertainty-into-stock-assessment}{%
\section{Propagate uncertainty into stock assessment}\label{propagate-uncertainty-into-stock-assessment}}

In a multistage stock assessment process as described in this book, it's important to be able to propagate uncertainty across the different stages. This section describes methods to propagate uncertainty across stages and compares their outcomes in terms of stock assessment outputs.

The idea is to add uncertainty as one moves from one stage to the next. If a stock has uncertainty on it's growth parameters, or natural mortality, or any other quantity estimated or set during the input data preparation, the model fit uncertainty will be added to it by generating iterations in the input data which are then used to fit the stock assessment model. The suggested workflow is:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Add uncertainty in growth or M parameters.
\item
  Draw from the parameters distribution.
\item
  Compute metrics for stock assessment.

  \begin{enumerate}
  \def\labelenumii{\arabic{enumii}.}
  \tightlist
  \item
    If there's uncertainty in growth parameters use slicing to created iterations of metrics by age, e.g.~catch at age and index at age.
  \item
    If there's uncertainty in M parameters draw from the distribution and generate iterations of the M matrix.
  \item
    If both draw from growth and M parameters, potentially having into account correlation between those parameters, and generate iterations of age based metrics and M.
  \end{enumerate}
\item
  Fit the stock assessment model to each iteration
\item
  Simulate from each fit
\item
  Aggregate results in single \texttt{FLStock} object.
\end{enumerate}

In this section we give an example of how uncertainty in natural mortality, set up using the \texttt{m()} method and the class \texttt{a4aM}, is propagated through the stock assessment. We'll use the stock of Red Mullet in the Mediterranean GSA 1 (see Introduction for details) and 3 methods to add estimation uncertainty (step 5 above):

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Take one draw of the fit
\item
  Take n draws of the fit and summarize with the median
\item
  Take n draws of the fit and combine all
\end{enumerate}

These outcomes will be compared with a fit across M iterations without any sampling from the fit.

Using \texttt{a4a} methods we'll model natural mortality using a negative exponential model by age, Jensen's estimator for the level and no time trend. We include multivariate normal uncertainty using the \texttt{mvrnorm()} method and create 250 iterations.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nits }\OtherTok{\textless{}{-}} \DecValTok{25}

\NormalTok{shape }\OtherTok{\textless{}{-}} \FunctionTok{FLModelSim}\NormalTok{(}\AttributeTok{model=}\SpecialCharTok{\textasciitilde{}}\FunctionTok{exp}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{age}\FloatTok{{-}0.5}\NormalTok{))}
\NormalTok{level }\OtherTok{\textless{}{-}} \FunctionTok{FLModelSim}\NormalTok{(}\AttributeTok{model=}\SpecialCharTok{\textasciitilde{}}\NormalTok{k}\SpecialCharTok{\^{}}\FloatTok{0.66}\SpecialCharTok{*}\NormalTok{t}\SpecialCharTok{\^{}}\FloatTok{0.57}\NormalTok{, }\AttributeTok{params =} \FunctionTok{FLPar}\NormalTok{(}\AttributeTok{k=}\FloatTok{0.4}\NormalTok{, }\AttributeTok{t=}\DecValTok{10}\NormalTok{),}
                     \AttributeTok{vcov=}\FunctionTok{matrix}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\FloatTok{0.001}\NormalTok{, }\FloatTok{0.01}\NormalTok{,}\FloatTok{0.01}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{ncol=}\DecValTok{2}\NormalTok{))}
\CommentTok{\#trend \textless{}{-} FLModelSim(model=\textasciitilde{}b, params=FLPar(b=0.5), vcov=matrix(0.02))}

\NormalTok{m4 }\OtherTok{\textless{}{-}} \FunctionTok{a4aM}\NormalTok{(}\AttributeTok{shape=}\NormalTok{shape, }\AttributeTok{level=}\NormalTok{level)}
\NormalTok{m4 }\OtherTok{\textless{}{-}} \FunctionTok{mvrnorm}\NormalTok{(nits, m4)}
\FunctionTok{range}\NormalTok{(m4)[] }\OtherTok{\textless{}{-}} \FunctionTok{range}\NormalTok{(stk00)[]}
\FunctionTok{range}\NormalTok{(m4)[}\FunctionTok{c}\NormalTok{(}\StringTok{"minmbar"}\NormalTok{,}\StringTok{"maxmbar"}\NormalTok{)]}\OtherTok{\textless{}{-}}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{)}
\NormalTok{flq }\OtherTok{\textless{}{-}} \FunctionTok{m}\NormalTok{(m4)[]}
\FunctionTok{quant}\NormalTok{(flq) }\OtherTok{\textless{}{-}} \StringTok{"age"}
\NormalTok{stk0 }\OtherTok{\textless{}{-}} \FunctionTok{propagate}\NormalTok{(stk00, nits)}
\FunctionTok{m}\NormalTok{(stk0) }\OtherTok{\textless{}{-}}\NormalTok{ flq}
\end{Highlighting}
\end{Shaded}

The M matrix for this stock is shown in Figure\ref{fig:m}).

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/m-1.png}
\caption{\label{fig:m}Natural mortality generated from M model's parameter uncertainty}
\end{figure}

We fit the same model to the new stock object which has uncertainty in the natural mortality and add estimation uncertainty following the methods described above.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# create objects to store the results}
\NormalTok{stk01 }\OtherTok{\textless{}{-}}\NormalTok{ stk0}
\NormalTok{stk02 }\OtherTok{\textless{}{-}}\NormalTok{ stk0}
\NormalTok{stk03 }\OtherTok{\textless{}{-}} \FunctionTok{propagate}\NormalTok{(stk00, nits}\SpecialCharTok{*}\NormalTok{nits)}

\CommentTok{\# run without estimation uncertainty}
\NormalTok{stk04 }\OtherTok{\textless{}{-}}\NormalTok{ stk00 }\SpecialCharTok{+} \FunctionTok{sca}\NormalTok{(stk0, idx00)}
\CommentTok{\# update M, the "+" method doesn\textquotesingle{}t do it automatically}
\FunctionTok{m}\NormalTok{(stk04) }\OtherTok{\textless{}{-}}\NormalTok{ flq}

\ControlFlowTok{for}\NormalTok{(i }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\NormalTok{nits)\{}
\NormalTok{    stk }\OtherTok{\textless{}{-}} \FunctionTok{iter}\NormalTok{(stk0, i)}
\NormalTok{    fit }\OtherTok{\textless{}{-}} \FunctionTok{sca}\NormalTok{(stk, idx00)}
    \CommentTok{\# Method 1}
    \FunctionTok{iter}\NormalTok{(stk01, i) }\OtherTok{\textless{}{-}}\NormalTok{ stk }\SpecialCharTok{+} \FunctionTok{simulate}\NormalTok{(fit, }\DecValTok{1}\NormalTok{)}
    \CommentTok{\# Method 2}
    \FunctionTok{iter}\NormalTok{(stk02, i) }\OtherTok{\textless{}{-}} \FunctionTok{qapply}\NormalTok{(stk }\SpecialCharTok{+} \FunctionTok{simulate}\NormalTok{(fit, nits), iterMedians)}
    \CommentTok{\# Method 3}
    \FunctionTok{iter}\NormalTok{(stk03, (nits}\SpecialCharTok{*}\NormalTok{(i}\DecValTok{{-}1}\NormalTok{)}\SpecialCharTok{+}\DecValTok{1}\NormalTok{)}\SpecialCharTok{:}\NormalTok{(nits}\SpecialCharTok{*}\NormalTok{i)) }\OtherTok{\textless{}{-}}\NormalTok{ stk }\SpecialCharTok{+} \FunctionTok{simulate}\NormalTok{(fit, nits)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/mprop-1.png}
\caption{\label{fig:mprop}Stock summary. Stock metrics computed over fits including uncertainty in M and estimation uncertainty}
\end{figure}

Method 1 and method 3 are the best propagating uncertainty and both give similar results. Method 1 will be faster since only one sample per fit is drawn, while method 3 will better describe the distribution but will be more computationally intensive.

\hypertarget{the-statistical-catch-at-age-stock-assessment-framework-with-markov-chain-monte-carlo-mcmc}{%
\chapter{\texorpdfstring{The statistical catch-at-age stock assessment framework with Markov Chain Monte Carlo (MCMC) \label{sec:mcmc}}{The statistical catch-at-age stock assessment framework with Markov Chain Monte Carlo (MCMC) }}\label{the-statistical-catch-at-age-stock-assessment-framework-with-markov-chain-monte-carlo-mcmc}}

The previous methods were demonstrated using maximum likelihood estimation (MLE). However, \texttt{ADMB} also supports Markov Chain Monte Carlo (MCMC) methods, which provide significant advantages, particularly when working with complex models that involve many parameters. The key difference is that while MLE finds a single best estimate of parameters by maximizing the likelihood function, MCMC offers a broader perspective by generating an entire distribution of possible values. This approach is more informative because it does not just give the most likely estimate but also helps us understand the uncertainty surrounding it. With MCMC, researchers can incorporate prior knowledge and obtain results that are often more realistic and reliable (\protect\hyperlink{ref-gelman2013bayesian}{A. Gelman et al. 2013}). This is especially useful when dealing with complicated models where traditional likelihood-based methods struggle, as MCMC allows for efficient exploration of possible solutions without requiring an exact mathematical formulation (\protect\hyperlink{ref-gilks1995markov}{Gilks, Richardson, and Spiegelhalter 1995}; \protect\hyperlink{ref-robert2005monte}{Robert and Casella 2005}).

One of the biggest advantages of MCMC is its flexibility when working with models that have irregular behavior, such as those with multiple peaks or abrupt changes in likelihood. Standard MLE methods assume that the likelihood function behaves smoothly, but this is rarely true in real-world applications. In fisheries, ecology, and other applied sciences, models often have parameters that interact in complex ways, creating likelihood surfaces with ridges and multiple solutions. In these cases, MLE optimizers can easily get stuck in a local peak, failing to find the best possible estimate or underestimating the real uncertainty in the system (\protect\hyperlink{ref-neal1993probabilistic}{Neal 1993}). Since MCMC uses a probabilistic sampling approach instead of strict optimization, it moves freely across the entire space of possible values, making it more robust and adaptable to challenging problems (\protect\hyperlink{ref-robert2005monte}{Robert and Casella 2005}).

Traditional MLE-based uncertainty estimation relies on the Hessian matrix, which essentially measures how quickly the likelihood function changes as parameters vary. This method assumes that the shape of the likelihood function is quadratic and roughly the same everywhere. However, this assumption is often unrealistic, especially in models with many parameters or strong correlations among them, as is common in fisheries stock assessment models.

In fields like fisheries science, where models often involve multiple correlated parameters, MCMC provides a much more flexible and realistic way to estimate uncertainty. Unlike MLE, which assumes uncertainty follows a simple symmetrical pattern, MCMC can handle more complex distributions, giving a better representation of real-world variability. This is especially important when estimating key fisheries management indicators, such as spawning stock biomass (\(SSB\)) or fishing mortality (\(F\)), which influence critical policy decisions. Because MCMC does not impose strict mathematical assumptions about the shape of uncertainty, it produces estimates that are more reflective of real-world conditions, ultimately leading to more informed and reliable management strategies.

When running MCMC, \texttt{ADMB} uses automatic differentiation to improve sampling efficiency and speed (\protect\hyperlink{ref-Fournier2012}{Fournier et al. 2012}). It supports various sampling algorithms, including Metropolis-Hastings and Hamiltonian Monte Carlo, which help navigate high-dimensional parameter spaces and complex likelihood structures more effectively. This makes \texttt{ADMB} particularly useful in applied sciences like fisheries and ecology, where uncertainty estimation is crucial for decision-making. Additionally, \texttt{ADMB} provides built-in diagnostics to assess MCMC convergence and reliability, ensuring that posterior distributions are well-explored and results are robust (\protect\hyperlink{ref-gelman2013bayesian}{A. Gelman et al. 2013}).

The manual ``A Guide for Bayesian Analysis in AD Model Builder'' (\protect\hyperlink{ref-monnahan2014admbmcmc}{Cole C. Monnahan, Muradian, and Kuriyama 2014}) describes and explain a larger group of arguments that can be set when running MCMC with \texttt{ADMB}, which the method \texttt{sca()} uses.

\hypertarget{the-mcmc-method-for-sca}{%
\section{\texorpdfstring{The MCMC method for \texttt{sca}}{The MCMC method for sca}}\label{the-mcmc-method-for-sca}}

This section shows how the \texttt{sca()} method interfaces with \texttt{ADMB} to use MCMC. For this section we'll use the hake assessment in Mediterranean areas (gsa) 1, 5, 6 and 7.

We start by fitting the MLE model and calling afterwards the necessary MCMC methods. The outcomes of the MCMC fit need to be inspected to make sure the chain converged and the results are robust. A set of diagnostics are available to do this.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# load libraries and data}
\FunctionTok{library}\NormalTok{(FLa4a)}
\FunctionTok{library}\NormalTok{(ggplotFL)}
\FunctionTok{data}\NormalTok{(hke1567)}
\FunctionTok{data}\NormalTok{(hke1567.idx)}
\NormalTok{nsim }\OtherTok{\textless{}{-}} \DecValTok{250}
\CommentTok{\# MLE estimate}
\NormalTok{fmod }\OtherTok{\textless{}{-}} \ErrorTok{\textasciitilde{}}\FunctionTok{s}\NormalTok{(age, }\AttributeTok{k =} \DecValTok{4}\NormalTok{) }\SpecialCharTok{+}
    \FunctionTok{s}\NormalTok{(year, }\AttributeTok{k =} \DecValTok{8}\NormalTok{) }\SpecialCharTok{+}
    \FunctionTok{s}\NormalTok{(year, }\AttributeTok{k =} \DecValTok{8}\NormalTok{, }\AttributeTok{by =} \FunctionTok{as.numeric}\NormalTok{(age }\SpecialCharTok{==} \DecValTok{0}\NormalTok{)) }\SpecialCharTok{+}
    \FunctionTok{s}\NormalTok{(year, }\AttributeTok{k =} \DecValTok{8}\NormalTok{, }\AttributeTok{by =} \FunctionTok{as.numeric}\NormalTok{(age }\SpecialCharTok{==} \DecValTok{4}\NormalTok{))}
\NormalTok{qmod }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\FunctionTok{I}\NormalTok{(}\DecValTok{1}\SpecialCharTok{/}\NormalTok{(}\DecValTok{1} \SpecialCharTok{+} \FunctionTok{exp}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{age))))}
\NormalTok{fit }\OtherTok{\textless{}{-}} \FunctionTok{sca}\NormalTok{(hke1567, hke1567.idx, }\AttributeTok{fmodel=}\NormalTok{fmod, }\AttributeTok{qmodel=}\NormalTok{qmod)}
\NormalTok{fit }\OtherTok{\textless{}{-}} \FunctionTok{simulate}\NormalTok{(fit, nsim)}
\end{Highlighting}
\end{Shaded}

To run the MCMC method, one needs to configure a set of arguments, which is done by creating an object of class \texttt{SCAMCMC}. Table \ref{tab:mcargs} describes the arguments available to run the MCMC method, extracted from Monnahan (\protect\hyperlink{ref-monnahan2019}{Cole C. Monnahan et al. 2019}). For more details on the MCMC configuration in \texttt{ADMB} visit the \texttt{ADMB} website.

\begin{longtable}[]{@{}rll@{}}
\caption{\label{tab:mcargs} \texttt{ADMB} MCMC arguments}\tabularnewline
\toprule\noalign{}
Argument & Default value & Description \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
Argument & Default value & Description \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\texttt{mcmc} & \texttt{10000} & Run N MCMC iterations \\
\texttt{mcsave} & \texttt{100} & Save every N th MCMC iteration \\
\texttt{mcscale} & & Rescale step size for first N iterations \\
\texttt{mcmult} & & Rescale the covariance matrix \\
\texttt{mcrb} & & Reduce high parameter correlations \\
\texttt{mcprobe} & \texttt{0.05} & Use a fat-tailed proposal distribution \\
\texttt{mcdiag} & \texttt{FALSE} & Use a diagonal covariance matrix \\
\texttt{mcnoscale} & \texttt{FALSE} & Do not scale the algorithm during \\
\texttt{mcu} & \texttt{FALSE} & Use a uniform distribution as proposal distribution \\
\texttt{hybrid} & \texttt{FALSE} & Use the hybrid method \\
\texttt{hynstep} & & Mean number of steps for the leapfrog method \\
\texttt{hyeps} & & The stepsize for the leapfrog method {[}X numeric and \textgreater{} 0{]} \\
\end{longtable}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# mcmc}
\NormalTok{mc }\OtherTok{\textless{}{-}} \FunctionTok{SCAMCMC}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

Defaults provide a good starting point, so let's fit first the model. Note that the argument \texttt{fit} must be set to \texttt{MCMC} while the argument \texttt{mcmc} takes the \texttt{SCAMCMC} object just created.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# fit the model}
\NormalTok{fitmc00 }\OtherTok{\textless{}{-}} \FunctionTok{sca}\NormalTok{(hke1567, hke1567.idx, }\AttributeTok{fmodel=}\NormalTok{fmod, }\AttributeTok{qmodel=}\NormalTok{qmod, }\AttributeTok{fit =} \StringTok{"MCMC"}\NormalTok{, }\AttributeTok{mcmc=}\NormalTok{mc)}
\CommentTok{\# check acceptance rate}
\FunctionTok{fitSumm}\NormalTok{(fitmc00)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##              iters
##                      1
##   nopar        52.0000
##   nlogl             NA
##   maxgrad           NA
##   nobs        176.0000
##   gcv               NA
##   convergence       NA
##   accrate       0.3271
\end{verbatim}

As usual \texttt{fitSumm} store relevant information about the model fit. In the case of an MCMC fit, the information stored includes the number of model parameters (\texttt{nopar}), the number of observations (\texttt{nobs}) and the acceptance rate (\texttt{accrate}).

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(}\FunctionTok{FLStocks}\NormalTok{(}\AttributeTok{mle=}\NormalTok{hke1567 }\SpecialCharTok{+}\NormalTok{ fit, }\AttributeTok{mc=}\NormalTok{hke1567 }\SpecialCharTok{+}\NormalTok{ fitmc00))}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/unnamed-chunk-88-1.png}
\caption{\label{fig:unnamed-chunk-88}Stock assessment summaries of maximum likelihood (mle) and monte carlo (mc) fits.}
\end{figure}

\hypertarget{diagnostics-with-coda}{%
\section{Diagnostics with CODA}\label{diagnostics-with-coda}}

MCMC diagnostics are used to give the analyst confidence that the posterior distribution of the parameters is unbiased, with symmetric non-correlated distributions of each parameter over which one can make inference.

There exists a large body of literature about MCMC convergence. In this section we will focus on the out-of-the-box methods for metropolis hastings algorithm available to the stock assessment scientist: trace plots, autocorrelation and cross correlation analysis, Geweke diagnostic, Gelman and Rubin's convergence diagnostic, cumulative means, distribution density and acceptance rate. These tools should be used together to evaluate proper mixing and convergence.

\texttt{ADMB} has an hybrid algorithm based on Hamiltonian dynamics which will not be employed here. The reader is invited to consult Cole C. Monnahan et al. (\protect\hyperlink{ref-monnahan2019}{2019}) for more information.

We use the package \texttt{CODA} (\protect\hyperlink{ref-coda}{Plummer et al. 2006}) to run the diagnostics on MCMC fits. One needs to convert the \texttt{sca} output into a \texttt{mcmc} \texttt{CODA} object over which several diagnostics can be ran. The \texttt{mcmc} object is a matrix with the parameters (row = iters, cols= pars).

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(coda)}
\end{Highlighting}
\end{Shaded}

For demonstration purposes we create a chain with 1000 samples (\texttt{mcmc=1000}) and save every iter (\texttt{mcsave=1}), which will create a highly correlated and unstable chain, and update the initial MCMC fit to also have 1000 samples but obtained by keeping every 100th sample (\texttt{mcmc=100000}, \texttt{mcsave=100}). The latter will have a lower correlation due to the higher thinning.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# update initial fit, control random seed}
\NormalTok{mc }\OtherTok{\textless{}{-}} \FunctionTok{SCAMCMC}\NormalTok{(}\AttributeTok{mcmc=}\DecValTok{100000}\NormalTok{, }\AttributeTok{mcsave=}\DecValTok{100}\NormalTok{, }\AttributeTok{mcseed=}\DecValTok{10}\NormalTok{)}
\NormalTok{fitmc01 }\OtherTok{\textless{}{-}} \FunctionTok{sca}\NormalTok{(hke1567, hke1567.idx, }\AttributeTok{fmodel=}\NormalTok{fmod, }\AttributeTok{qmodel=}\NormalTok{qmod, }\AttributeTok{fit =} \StringTok{"MCMC"}\NormalTok{, }\AttributeTok{mcmc=}\NormalTok{mc)}
\NormalTok{fitmc01.mc }\OtherTok{\textless{}{-}}\NormalTok{ FLa4a}\SpecialCharTok{::}\FunctionTok{as.mcmc}\NormalTok{(fitmc01)}
\CommentTok{\# highly correlated fit, control random seed}
\NormalTok{mc }\OtherTok{\textless{}{-}} \FunctionTok{SCAMCMC}\NormalTok{(}\AttributeTok{mcmc=}\DecValTok{1000}\NormalTok{, }\AttributeTok{mcsave=}\DecValTok{1}\NormalTok{, }\AttributeTok{mcseed=}\DecValTok{10}\NormalTok{)}
\NormalTok{fitmc02 }\OtherTok{\textless{}{-}} \FunctionTok{sca}\NormalTok{(hke1567, hke1567.idx, }\AttributeTok{fmodel=}\NormalTok{fmod, }\AttributeTok{qmodel=}\NormalTok{qmod, }\AttributeTok{fit =} \StringTok{"MCMC"}\NormalTok{, }\AttributeTok{mcmc=}\NormalTok{mc)}
\NormalTok{fitmc02.mc }\OtherTok{\textless{}{-}}\NormalTok{ FLa4a}\SpecialCharTok{::}\FunctionTok{as.mcmc}\NormalTok{(fitmc02)}
\end{Highlighting}
\end{Shaded}

\hypertarget{traceplots}{%
\subsection{Traceplots}\label{traceplots}}

Trace plots (\texttt{traceplot()}) show the sampled values of a parameter over iterations. A plot that looks like a random, stable ``cloud'' of points with no trends or drifts, with rapid fluctuations, is a signal of convergence, meaning the chain mixes well and is stationary. If the trace plot shows a strong trend or periodicity, drifts, or long autocorrelated stretches, it means the chain has not converged as expected. Figure \ref{fig:chain01} cleary depicts this difference between the two runs.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# use mcmc.list() to create a list with both runs so they\textquotesingle{}re plot together}
\FunctionTok{traceplot}\NormalTok{(}\FunctionTok{mcmc.list}\NormalTok{(}\AttributeTok{mc01=}\NormalTok{fitmc01.mc[,}\DecValTok{1}\NormalTok{], }\AttributeTok{mc02=}\NormalTok{fitmc02.mc[,}\DecValTok{2}\NormalTok{]), }\AttributeTok{lwd=}\FloatTok{1.5}\NormalTok{, }\AttributeTok{col=}\FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{4}\NormalTok{), }\AttributeTok{lty=}\DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/chain01-1.png}
\caption{\label{fig:chain01}MCMC chain's trace for the first parameter. High correlation chain in blue, low correlation chain in red.}
\end{figure}

Plotting the chains for the parameter clearly shows autocorrelation for the first parameter in the blue chain. This initial phase, when the parameter seems to be stuck in a fixed position, is called the ``burn-in'' phase. These iterations can be dropped by using the \texttt{burnin()} function. Note however that this does not decrease the autocorrelation (Figure \ref{fig:chain01b}).

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{traceplot}\NormalTok{(FLa4a}\SpecialCharTok{::}\FunctionTok{as.mcmc}\NormalTok{(}\FunctionTok{burnin}\NormalTok{(fitmc02, }\DecValTok{250}\NormalTok{))[,}\DecValTok{1}\NormalTok{], }\AttributeTok{lwd=}\FloatTok{1.5}\NormalTok{, }\AttributeTok{col=}\DecValTok{4}\NormalTok{, }\AttributeTok{lty=}\DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/chain01b-1.png}
\caption{\label{fig:chain01b}MCMC chain with high autocorrelation after removing the initial 250 samples (burnin period).}
\end{figure}

\hypertarget{autocorrelation-and-crosscorrelation-analysis}{%
\subsection{Autocorrelation and crosscorrelation analysis}\label{autocorrelation-and-crosscorrelation-analysis}}

Autocorrelation analysis (\texttt{acf()} and \texttt{acfplot()}) is an useful tool to assess stationarity. A stationary chain should have low autocorrelation, meaning that each sample is approximately independent. On the opposite, high autocorrelation indicates slow mixing and possible non-stationarity. Furthermore, in a well mixed chain autocorrelation drops quickly to near zero, while a poor mixing one will display high autocorrelation, which also reduces the efficiency of the search.

The autocorrelation plot will show correlation along the chain for each parameter at different lags. Figure \ref{fig:acf01hc} shows that there is a strong autocorrelation for the first parameter which we would like to avoid, while Figure \ref{fit:acf01} shows much lower correlation.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{acfplot}\NormalTok{(fitmc02.mc[,}\DecValTok{1}\NormalTok{], }\AttributeTok{lwd=}\DecValTok{3}\NormalTok{, }\AttributeTok{main=}\StringTok{"High correlation chain"}\NormalTok{, }\AttributeTok{ylim=}\FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/acf01hc-1.png}
\caption{\label{fig:acf01hc}Autocorrelation plot of the first parameter in the MCMC chain}
\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{acfplot}\NormalTok{(fitmc01.mc[,}\DecValTok{1}\NormalTok{], }\AttributeTok{lwd=}\DecValTok{3}\NormalTok{, }\AttributeTok{main=}\StringTok{"Low correlation chain"}\NormalTok{, }\AttributeTok{ylim=}\FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/acf01-1.png}
\caption{\label{fig:acf01}Autocorrelation plot of the first parameter in the MCMC chain}
\end{figure}

Cross-correlation (\texttt{crosscorr()} and \texttt{crosscorr.plot()}) inspects the pairwise correlation of all parameters, which is a useful tool to assess the efficiency of the sampling process and the independence of the generated samples. If cross-correlations are high, it often means that transitions between states are slow, leading to an increased running time and requiring a larger number of samples to achieve effective independent samples. Conversely, low cross-correlation implies that parameters are explored more independently, leading to faster convergence and better mixing.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{crosscorr.plot}\NormalTok{(fitmc01.mc, }\AttributeTok{main=}\StringTok{"Low correlation chain"}\NormalTok{)}
\FunctionTok{crosscorr.plot}\NormalTok{(fitmc02.mc, }\AttributeTok{main=}\StringTok{"High correlation chain"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\includegraphics[width=0.5\linewidth]{_bookdown_files/_main_files/figure-html/ccr01-1} \includegraphics[width=0.5\linewidth]{_bookdown_files/_main_files/figure-html/ccr01-2} \caption{Crosscorrelation plots}\label{fig:ccr01}
\end{figure}

\hypertarget{geweke-diagnostic}{%
\subsection{Geweke diagnostic}\label{geweke-diagnostic}}

The Geweke diagnostic (\texttt{geweke.diag()} and \texttt{geweke.plot()}) computes the Geweke-Brooks Z-score (\protect\hyperlink{ref-Geweke1992}{Geweke 1992}), which indicates if the first and following parts of a sample from a Markov chain are drawn from the same distribution as the last part of the chain, usually the last 50\% of the samples.

It is an useful way to decide if the first few iterations should be discarded, while also provides information about the stability of the chain. Figure \ref{fig:gew01} shows the Geweke plot for the two MCMC runs.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{geweke.plot}\NormalTok{(fitmc01.mc[,}\DecValTok{1}\NormalTok{], }\AttributeTok{main=}\StringTok{"Low correlation chain"}\NormalTok{)}
\FunctionTok{geweke.plot}\NormalTok{(fitmc02.mc[,}\DecValTok{1}\NormalTok{], }\AttributeTok{main=}\StringTok{"High correlation chain"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\includegraphics[width=0.5\linewidth]{_bookdown_files/_main_files/figure-html/gew01-1} \includegraphics[width=0.5\linewidth]{_bookdown_files/_main_files/figure-html/gew01-2} \caption{Geweke plot of the first parameter in the MCMC chains}\label{fig:gew01}
\end{figure}

The panel on the left shows a much more regular chain, where the different blocks of data show similar distributions. The panel on the right clearly shows the z-score statistic changing out of the confidence intervals until about 400 samples are discarded, which points to the need to drop a set of initial samples.

The Geweke diagnostic is also a good way to look at mixing by comparing the mean and variance of the first part of the chain to the last part. Good mixing will show no significant difference between early and late samples. Poor mixing will show large differences, indicating the chain has not explored the posterior fully.

\hypertarget{cumulative-means}{%
\subsection{Cumulative means}\label{cumulative-means}}

Inspecting the cumulative mean along the chain is another good way to check for the stability of the chain. When the mixing is good the mean stabilizes quickly, and vice-versa if not.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cm01 }\OtherTok{\textless{}{-}}\NormalTok{ fitmc01.mc[,}\DecValTok{1}\NormalTok{]}
\NormalTok{cm01 }\OtherTok{\textless{}{-}} \FunctionTok{cumsum}\NormalTok{(cm01) }\SpecialCharTok{/} \FunctionTok{seq\_along}\NormalTok{(cm01)}
\NormalTok{cm02 }\OtherTok{\textless{}{-}}\NormalTok{ fitmc02.mc[,}\DecValTok{1}\NormalTok{]}
\NormalTok{cm02 }\OtherTok{\textless{}{-}} \FunctionTok{cumsum}\NormalTok{(cm02) }\SpecialCharTok{/} \FunctionTok{seq\_along}\NormalTok{(cm02)}
\FunctionTok{plot}\NormalTok{(cm01, }\AttributeTok{type=}\StringTok{"l"}\NormalTok{, }\AttributeTok{xlab=}\StringTok{"samples"}\NormalTok{, }\AttributeTok{ylab=}\StringTok{"mean"}\NormalTok{, }\AttributeTok{main=}\StringTok{"Low correlation chain"}\NormalTok{, }\AttributeTok{ylim=}\FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\FloatTok{0.52}\NormalTok{, }\SpecialCharTok{{-}}\FloatTok{0.42}\NormalTok{))}
\FunctionTok{plot}\NormalTok{(cm02, }\AttributeTok{type=}\StringTok{"l"}\NormalTok{, }\AttributeTok{xlab=}\StringTok{"samples"}\NormalTok{, }\AttributeTok{ylab=}\StringTok{"mean"}\NormalTok{, }\AttributeTok{main=}\StringTok{"High correlation chain"}\NormalTok{, }\AttributeTok{ylim=}\FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\FloatTok{0.52}\NormalTok{, }\SpecialCharTok{{-}}\FloatTok{0.42}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\includegraphics[width=0.5\linewidth]{_bookdown_files/_main_files/figure-html/cmean01-1} \includegraphics[width=0.5\linewidth]{_bookdown_files/_main_files/figure-html/cmean01-2} \caption{Cumulative mean plots of the first parameter in the MCMC chains}\label{fig:cmean01}
\end{figure}

\hypertarget{distribution-density}{%
\subsection{Distribution density}\label{distribution-density}}

An important element of MCMC is to produce symmetric posterior distributions, for one it's a sign that the chain explored the space of the parameter, for other it makes inference about the parameters a lot more robust. If the distributions are skewed or multimodal, estimating the expected value and variance becomes a lot more complicated. As such having symmetric distributions is preferred and should be checked before computing statistics of interest.

Figure \ref{fig:dens01} shows the density plots (\texttt{densplot()}) for both runs, where it shows the symmetric distribution of the uncorrelated chain (left panel) and the bimodal distribution of the correlated chain.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{densplot}\NormalTok{(fitmc01.mc[,}\DecValTok{1}\NormalTok{], }\AttributeTok{main=}\StringTok{"Low correlation chain"}\NormalTok{)}
\FunctionTok{densplot}\NormalTok{(fitmc02.mc[,}\DecValTok{1}\NormalTok{], }\AttributeTok{main=}\StringTok{"High correlation chain"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\includegraphics[width=0.5\linewidth]{_bookdown_files/_main_files/figure-html/dens01-1} \includegraphics[width=0.5\linewidth]{_bookdown_files/_main_files/figure-html/dens01-2} \caption{Density plots of the first parameter in the MCMC chains}\label{fig:dens01}
\end{figure}

\hypertarget{gelman-rubin-statistic}{%
\subsection{Gelman-Rubin statistic}\label{gelman-rubin-statistic}}

The Gelman-Rubin statistic (\(\hat{R}\)) (\protect\hyperlink{ref-gelman1992inference}{Andrew Gelman and Rubin 1992}) can be used to check if multiple chains have reached a stable state and are properly exploring the target distribution. It compares how much variation exists within each chain to the variation between different chains. If all chains are sampling from the same distribution, these variations should be similar, and \(\hat{R}\) will be close to 1, otherwise, if it's greater than 1.1 it suggests that the chains have not yet converged.

To compute \(\hat{R}\), multiple chains are run with different starting points. The algorithm measures how spread out the samples are within each chain and compares it to how much the chains differ from each other. If the chains have not mixed well, they will appear too different from each other, and \(\hat{R}\) will be large. If the chains have mixed properly, they will have a similar spread, and the statistic will be close to 1.

To run another chain one makes use of the \texttt{mcseed} argument to make sure the 2 chains start from different places. The Gelman-Rubin statistics is computed by the \texttt{gelman.diag()} method and depicted with \texttt{gelman.plot()}. It's easy to see the difference between the two fits. While the low corrrelation fit shows values close to 1 for most parameters, the high correlation fit shows a number of large values.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# low correlation}
\NormalTok{mc }\OtherTok{\textless{}{-}} \FunctionTok{SCAMCMC}\NormalTok{(}\AttributeTok{mcmc=}\DecValTok{100000}\NormalTok{, }\AttributeTok{mcsave=}\DecValTok{100}\NormalTok{, }\AttributeTok{mcseed=}\DecValTok{30}\NormalTok{)}
\NormalTok{fitmc01b }\OtherTok{\textless{}{-}} \FunctionTok{sca}\NormalTok{(hke1567, hke1567.idx, }\AttributeTok{fmodel=}\NormalTok{fmod, }\AttributeTok{qmodel=}\NormalTok{qmod, }\AttributeTok{fit =} \StringTok{"MCMC"}\NormalTok{, }\AttributeTok{mcmc=}\NormalTok{mc)}
\NormalTok{fitmc01b.mc }\OtherTok{\textless{}{-}}\NormalTok{ FLa4a}\SpecialCharTok{::}\FunctionTok{as.mcmc}\NormalTok{(fitmc01b)}
\CommentTok{\# highly correlated fit}
\NormalTok{mc }\OtherTok{\textless{}{-}} \FunctionTok{SCAMCMC}\NormalTok{(}\AttributeTok{mcmc=}\DecValTok{1000}\NormalTok{, }\AttributeTok{mcsave=}\DecValTok{1}\NormalTok{, }\AttributeTok{mcseed=}\DecValTok{30}\NormalTok{)}
\NormalTok{fitmc02b }\OtherTok{\textless{}{-}} \FunctionTok{sca}\NormalTok{(hke1567, hke1567.idx, }\AttributeTok{fmodel=}\NormalTok{fmod, }\AttributeTok{qmodel=}\NormalTok{qmod, }\AttributeTok{fit =} \StringTok{"MCMC"}\NormalTok{, }\AttributeTok{mcmc=}\NormalTok{mc)}
\NormalTok{fitmc02b.mc }\OtherTok{\textless{}{-}}\NormalTok{ FLa4a}\SpecialCharTok{::}\FunctionTok{as.mcmc}\NormalTok{(fitmc02b)}
\CommentTok{\# create lists for comparison}
\NormalTok{mclst01 }\OtherTok{\textless{}{-}} \FunctionTok{mcmc.list}\NormalTok{(}\AttributeTok{a=}\NormalTok{fitmc01.mc, }\AttributeTok{b=}\NormalTok{fitmc01b.mc)}
\NormalTok{mclst02 }\OtherTok{\textless{}{-}} \FunctionTok{mcmc.list}\NormalTok{(}\AttributeTok{a=}\NormalTok{fitmc02.mc, }\AttributeTok{b=}\NormalTok{fitmc02b.mc)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Potential scale reduction factors:
## 
##                               Point est. Upper C.I.
## fMod:(Intercept)                   1.001      1.001
## fMod:s(age).1                      1.024      1.112
## fMod:s(age).2                      1.002      1.005
## fMod:s(age).3                      1.021      1.099
## fMod:s(year).1                     1.001      1.011
## fMod:s(year).2                     1.004      1.020
## fMod:s(year).3                     1.011      1.051
## fMod:s(year).4                     1.008      1.040
## fMod:s(year).5                     1.002      1.013
## fMod:s(year).6                     1.004      1.024
## fMod:s(year).7                     1.001      1.007
## fMod:s(year):by1..1                0.999      1.000
## fMod:s(year):by1..2                1.003      1.011
## fMod:s(year):by1..3                1.001      1.005
## fMod:s(year):by1..4                1.003      1.013
## fMod:s(year):by1..5                1.005      1.006
## fMod:s(year):by1..6                1.018      1.088
## fMod:s(year):by1..7                0.999      0.999
## fMod:s(year):by1..8                0.999      1.000
## fMod:s(year):by2..1                1.008      1.039
## fMod:s(year):by2..2                0.999      1.001
## fMod:s(year):by2..3                1.008      1.040
## fMod:s(year):by2..4                1.000      1.004
## fMod:s(year):by2..5                1.003      1.018
## fMod:s(year):by2..6                1.003      1.003
## fMod:s(year):by2..7                1.007      1.037
## fMod:s(year):by2..8                1.000      1.001
## n1Mod:(Intercept)                  1.002      1.013
## n1Mod:s(age).1                     1.000      1.003
## n1Mod:s(age).2                     1.001      1.006
## rMod:(Intercept)                   1.000      1.000
## rMod:factor(year)1                 0.999      0.999
## rMod:factor(year)2                 1.000      1.001
## rMod:factor(year)3                 1.002      1.002
## rMod:factor(year)4                 1.002      1.005
## rMod:factor(year)5                 1.000      1.000
## rMod:factor(year)6                 1.005      1.008
## rMod:factor(year)7                 0.999      0.999
## rMod:factor(year)8                 1.010      1.045
## rMod:factor(year)9                 1.001      1.003
## rMod:factor(year)10                1.000      1.004
## rMod:factor(year)11                1.001      1.008
## rMod:factor(year)12                1.011      1.053
## rMod:factor(year)13                1.003      1.003
## rMod:factor(year)14                1.004      1.019
## rMod:factor(year)15                1.008      1.034
## qMod:IND:(Intercept)               1.003      1.017
## qMod:IND:I(1/(1 + exp(-age)))      1.004      1.017
## vMod:catch:(Intercept)             0.999      0.999
## vMod:catch:s(age).1                1.002      1.013
## vMod:catch:s(age).2                1.001      1.010
## vMod:IND:(Intercept)               1.000      1.000
## 
## Multivariate psrf
## 
## 1.11
\end{verbatim}

\begin{verbatim}
## Potential scale reduction factors:
## 
##                               Point est. Upper C.I.
## fMod:(Intercept)                    1.11       1.12
## fMod:s(age).1                       1.09       1.12
## fMod:s(age).2                       1.12       1.20
## fMod:s(age).3                       1.13       1.27
## fMod:s(year).1                      1.11       1.41
## fMod:s(year).2                      2.04       4.32
## fMod:s(year).3                      2.75       6.01
## fMod:s(year).4                      1.72       3.40
## fMod:s(year).5                      1.11       1.41
## fMod:s(year).6                      1.82       3.62
## fMod:s(year).7                      1.08       1.27
## fMod:s(year):by1..1                 2.55       5.44
## fMod:s(year):by1..2                 2.44       6.05
## fMod:s(year):by1..3                 2.41       5.03
## fMod:s(year):by1..4                 1.19       1.38
## fMod:s(year):by1..5                 2.17       4.27
## fMod:s(year):by1..6                 2.27       4.39
## fMod:s(year):by1..7                 2.49       5.58
## fMod:s(year):by1..8                 1.23       1.87
## fMod:s(year):by2..1                 1.08       1.27
## fMod:s(year):by2..2                 1.01       1.01
## fMod:s(year):by2..3                 1.14       1.50
## fMod:s(year):by2..4                 1.87       3.41
## fMod:s(year):by2..5                 1.13       1.33
## fMod:s(year):by2..6                 1.45       2.41
## fMod:s(year):by2..7                 1.08       1.30
## fMod:s(year):by2..8                 1.33       2.03
## n1Mod:(Intercept)                   1.04       1.06
## n1Mod:s(age).1                      1.23       1.46
## n1Mod:s(age).2                      1.19       1.22
## rMod:(Intercept)                    1.15       1.53
## rMod:factor(year)1                  2.19       5.80
## rMod:factor(year)2                  1.12       1.40
## rMod:factor(year)3                  1.26       2.10
## rMod:factor(year)4                  1.19       1.20
## rMod:factor(year)5                  1.78       3.19
## rMod:factor(year)6                  2.32       4.62
## rMod:factor(year)7                  1.07       1.16
## rMod:factor(year)8                  2.15       4.22
## rMod:factor(year)9                  1.07       1.16
## rMod:factor(year)10                 1.21       1.29
## rMod:factor(year)11                 3.29       7.95
## rMod:factor(year)12                 2.67       5.39
## rMod:factor(year)13                 1.32       2.01
## rMod:factor(year)14                 1.03       1.04
## rMod:factor(year)15                 1.98       3.69
## qMod:IND:(Intercept)                1.18       1.62
## qMod:IND:I(1/(1 + exp(-age)))       1.49       2.53
## vMod:catch:(Intercept)              1.75       4.09
## vMod:catch:s(age).1                 1.13       1.36
## vMod:catch:s(age).2                 1.26       1.99
## vMod:IND:(Intercept)                1.54       2.57
## 
## Multivariate psrf
## 
## 16.2
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mclst01 }\OtherTok{\textless{}{-}} \FunctionTok{mcmc.list}\NormalTok{(}\AttributeTok{a=}\NormalTok{fitmc01.mc[,}\DecValTok{1}\NormalTok{], }\AttributeTok{b=}\NormalTok{fitmc01b.mc[,}\DecValTok{1}\NormalTok{])}
\NormalTok{mclst02 }\OtherTok{\textless{}{-}} \FunctionTok{mcmc.list}\NormalTok{(}\AttributeTok{a=}\NormalTok{fitmc02.mc[,}\DecValTok{1}\NormalTok{], }\AttributeTok{b=}\NormalTok{fitmc02b.mc[,}\DecValTok{1}\NormalTok{])}
\FunctionTok{gelman.plot}\NormalTok{(mclst01, }\AttributeTok{main=}\StringTok{"Low correlation chain"}\NormalTok{, }\AttributeTok{ylim=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{5}\NormalTok{))}
\FunctionTok{gelman.plot}\NormalTok{(mclst02, }\AttributeTok{main=}\StringTok{"High correlation chain"}\NormalTok{, }\AttributeTok{ylim=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{5}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\includegraphics[width=0.5\linewidth]{_bookdown_files/_main_files/figure-html/gelm01-1} \includegraphics[width=0.5\linewidth]{_bookdown_files/_main_files/figure-html/gelm01-2} \caption{Gelman-Rubin's diagnostic plots for the first parameter.}\label{fig:gelm01}
\end{figure}

\hypertarget{acceptance-rate}{%
\subsection{Acceptance rate}\label{acceptance-rate}}

The acceptance rate in Markov Chain Monte Carlo (MCMC) methods plays a crucial role in balancing exploration and efficiency when sampling from a posterior distribution. It represents the proportion of proposed states that are accepted in the Markov chain and directly influences mixing, convergence, and the quality of inference.

A low acceptance rate (e.g., \textless20\%) means that most proposed moves are rejected, leading to slow exploration of the posterior distribution. This can result in poor mixing and high autocorrelation between samples (\protect\hyperlink{ref-gelman2013bayesian}{A. Gelman et al. 2013}). A high acceptance rate (e.g., \textgreater80\%) suggests that the proposals are too conservative, leading to small moves and highly correlated samples.

Cole C. Monnahan et al. (\protect\hyperlink{ref-monnahan2019}{2019}) suggests that the optimal acceptance rate varies by model size, among other things, but is roughly 40\%, although models with more parameters should have a lower optimal acceptance rate. A. Gelman, Gilks, and Roberts (\protect\hyperlink{ref-gelman97}{1997}) complementary suggest that for Random Walk Metropolis-Hastings (RWMH) in high-dimensional spaces an optimal acceptance rate is about 25\%.

The acceptance rate is reported out of the MCMC fit and can be accessed with \texttt{fitSumm()}. Inspecting the acceptance rate for the models we're using shows a higher acceptance rate for the high correlation model, although both are above the recommended optimal for high dimensional models, like the models used in stock assessment.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{data.frame}\NormalTok{(}\AttributeTok{hessian\_scale=}\FunctionTok{c}\NormalTok{(}\FunctionTok{fitSumm}\NormalTok{(fitmc01)),}
    \AttributeTok{hessian\_noscale=}\FunctionTok{c}\NormalTok{(}\FunctionTok{fitSumm}\NormalTok{(fitmc02)),}
    \AttributeTok{row.names=}\FunctionTok{rownames}\NormalTok{(}\FunctionTok{fitSumm}\NormalTok{(fitmc01)))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##             hessian_scale hessian_noscale
## nopar            52.00000          52.000
## nlogl                  NA              NA
## maxgrad                NA              NA
## nobs            176.00000         176.000
## gcv                    NA              NA
## convergence            NA              NA
## accrate           0.31914           0.372
\end{verbatim}

\hypertarget{admbs-arguments-to-tune-the-mcmc-algorithm}{%
\section{\texorpdfstring{\texttt{ADMB}'s arguments to tune the MCMC algorithm}{ADMB's arguments to tune the MCMC algorithm}}\label{admbs-arguments-to-tune-the-mcmc-algorithm}}

This section is based on Cole C. Monnahan et al. (\protect\hyperlink{ref-monnahan2019}{2019}) and describes a set of arguments and methods which the stock assessment analyst can use to tune the MCMC algorithm and be more confident on its convergence and follow up inference.

\hypertarget{thinning-rate}{%
\subsection{Thinning rate}\label{thinning-rate}}

For the Metropolis-Hastings algorithm, the most important tuning option available to the user is the saving rate (the inverse of the thinning rate). This is the rate at which parameters are saved, such that thinning is effectively discarding draws. This tuning option is critical since this algorithm generates auto-correlated parameters by design. The user controls the thinning rate with the argument \texttt{mcsave}.

If N = 1 every single draw is saved (none are thinned out), which generates high autocorrelation, suggesting the need to thin more (save fewer). This is the case of the \texttt{fitmc02} fit. In \texttt{fitmc01} \texttt{mcsave} was increased to 100, by increasing the total samples by 100 and saving every 100th. This helps reduce the autocorrelation and produces independent draws from the posterior of interest.

\hypertarget{mcscale-and-mcnoscale}{%
\subsection{mcscale and mcnoscale}\label{mcscale-and-mcnoscale}}

\texttt{ADMB} ``scales'' the covariance matrix up or down, depending on the current acceptance rate, during the first part of the chain. Scaling the covariance matrix down produces proposed sets closer to the current set, and vice versa for scaling up. By default, it scales during the first 500 iterations before thinning, but the user can specify this with \texttt{mcscale} or turn off scaling with \texttt{mcnoscale}. \texttt{ADMB} rescales the covariance matrix every 200 iterations until the acceptance rate is between 0.15 and 0.4, or the scaling period is exceeded. Draws from this tuning phase should be discarded as part of the burn-in.

The code below illustrates the effect in the acceptance rate of not scaling the hessian, the acceptance rate drops significantly, which means poor mixing and higher autocorrelation.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# no scale}
\NormalTok{mc }\OtherTok{\textless{}{-}} \FunctionTok{SCAMCMC}\NormalTok{(}\AttributeTok{mcmc=}\DecValTok{100000}\NormalTok{, }\AttributeTok{mcsave=}\DecValTok{100}\NormalTok{, }\AttributeTok{mcseed=}\DecValTok{10}\NormalTok{, }\AttributeTok{mcnoscale=}\ConstantTok{TRUE}\NormalTok{)}
\NormalTok{fitmc01ns }\OtherTok{\textless{}{-}} \FunctionTok{sca}\NormalTok{(hke1567, hke1567.idx, }\AttributeTok{fmodel=}\NormalTok{fmod, }\AttributeTok{qmodel=}\NormalTok{qmod, }\AttributeTok{fit =} \StringTok{"MCMC"}\NormalTok{, }\AttributeTok{mcmc=}\NormalTok{mc)}
\NormalTok{fitmc01ns.mc }\OtherTok{\textless{}{-}}\NormalTok{ FLa4a}\SpecialCharTok{::}\FunctionTok{as.mcmc}\NormalTok{(fitmc01ns)}
\FunctionTok{data.frame}\NormalTok{(}\AttributeTok{hessian\_scale=}\FunctionTok{c}\NormalTok{(}\FunctionTok{fitSumm}\NormalTok{(fitmc01)),}
    \AttributeTok{hessian\_noscale=}\FunctionTok{c}\NormalTok{(}\FunctionTok{fitSumm}\NormalTok{(fitmc01ns)),}
    \AttributeTok{row.names=}\FunctionTok{rownames}\NormalTok{(}\FunctionTok{fitSumm}\NormalTok{(fitmc01)))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##             hessian_scale hessian_noscale
## nopar            52.00000        52.00000
## nlogl                  NA              NA
## maxgrad                NA              NA
## nobs            176.00000       176.00000
## gcv                    NA              NA
## convergence            NA              NA
## accrate           0.31914         0.08582
\end{verbatim}

In the next analysis we show the autocorrelation statistics for lags of 0, 1, 5, 10 and 50. When the hessian is not scaled the autocorrelation of lag 1 increased from 0.33 to 0.43.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{data.frame}\NormalTok{(}\AttributeTok{hessian\_scale=}\FunctionTok{c}\NormalTok{(}\FunctionTok{autocorr.diag}\NormalTok{(fitmc01.mc[,}\DecValTok{1}\NormalTok{])),}
    \AttributeTok{hessian\_noscale=}\FunctionTok{c}\NormalTok{(}\FunctionTok{autocorr.diag}\NormalTok{(fitmc01ns.mc[,}\DecValTok{1}\NormalTok{])),}
    \AttributeTok{row.names=}\FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{10}\NormalTok{, }\DecValTok{50}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    hessian_scale hessian_noscale
## 0    1.000000000    1.0000000000
## 1    0.331021210    0.4283436263
## 5    0.020797197    0.0006163336
## 10   0.038728809    0.0067920000
## 50   0.005681063   -0.0193736621
\end{verbatim}

\hypertarget{mcprobe}{%
\subsection{mcprobe}\label{mcprobe}}

For some models, there may be concern of being ``stuck'' in a local minimum and simply never proposing a value far enough away to escape it and find other regions of high density. \texttt{ADMB} has a built-in algorithm which modifies the default proposal distribution so it occasionally proposes very distant parameters (i.e.~``probes''). The modified proposal distribution is a mixture distribution of Normal and Cauchy distributions.

The \texttt{mcprobe} argument controls how the two distributions are mixed, with larger values being more Cauchy (fatter tails, larger jumps). The range of valid inputs is 0.00001 to 0.499, and if no value is supplied a default of 0.05 is used.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# more Cauchy}
\NormalTok{mc }\OtherTok{\textless{}{-}} \FunctionTok{SCAMCMC}\NormalTok{(}\AttributeTok{mcmc=}\DecValTok{1000}\NormalTok{, }\AttributeTok{mcsave=}\DecValTok{1}\NormalTok{, }\AttributeTok{mcseed=}\DecValTok{10}\NormalTok{, }\AttributeTok{mcprobe=}\FloatTok{0.45}\NormalTok{)}
\NormalTok{fitmc02p }\OtherTok{\textless{}{-}} \FunctionTok{sca}\NormalTok{(hke1567, hke1567.idx, }\AttributeTok{fmodel=}\NormalTok{fmod, }\AttributeTok{qmodel=}\NormalTok{qmod, }\AttributeTok{fit =} \StringTok{"MCMC"}\NormalTok{, }\AttributeTok{mcmc=}\NormalTok{mc)}
\NormalTok{fitmc02p.mc }\OtherTok{\textless{}{-}}\NormalTok{ FLa4a}\SpecialCharTok{::}\FunctionTok{as.mcmc}\NormalTok{(fitmc02p)}
\FunctionTok{data.frame}\NormalTok{(}\AttributeTok{probe\_0.05=}\FunctionTok{c}\NormalTok{(}\FunctionTok{fitSumm}\NormalTok{(fitmc02)),}
    \AttributeTok{probe\_0.45=}\FunctionTok{c}\NormalTok{(}\FunctionTok{fitSumm}\NormalTok{(fitmc02p)),}
    \AttributeTok{row.names=}\FunctionTok{rownames}\NormalTok{(}\FunctionTok{fitSumm}\NormalTok{(fitmc02)))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##             probe_0.05 probe_0.45
## nopar           52.000     52.000
## nlogl               NA         NA
## maxgrad             NA         NA
## nobs           176.000    176.000
## gcv                 NA         NA
## convergence         NA         NA
## accrate          0.372      0.343
\end{verbatim}

In the next analysis we show the autocorrelation statistics for lags of 0, 1, 5, 10 and 50. When the hessian is not scaled the autocorrelation of lag 1 increased from 0.33 to 0.37.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{data.frame}\NormalTok{(}\AttributeTok{probe\_0.05=}\FunctionTok{c}\NormalTok{(}\FunctionTok{autocorr.diag}\NormalTok{(fitmc02.mc[,}\DecValTok{1}\NormalTok{])), }\AttributeTok{probe\_0.45=}\FunctionTok{c}\NormalTok{(}\FunctionTok{autocorr.diag}\NormalTok{(fitmc02p.mc[,}\DecValTok{1}\NormalTok{])))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   probe_0.05 probe_0.45
## 1 1.00000000  1.0000000
## 2 0.97474570  0.9771081
## 3 0.86670724  0.8964793
## 4 0.72167253  0.7867470
## 5 0.03102215  0.3936894
\end{verbatim}

\hypertarget{mcrb}{%
\subsection{mcrb}\label{mcrb}}

The \texttt{mcrb} option (which stands for ``rescaled bounded'') alters the covariance matrix used to propose new parameter sets in the Metropolis-Hastings algorithm. Its intended use is to create a more efficient MCMC sampler so the analyses run faster. This option reduces the estimated correlation between parameters. The value must be integer between 1 and 9, inclusive, with lower values leading to a bigger reduction in correlation.

The option will be most effective under circumstances where the correlation between parameters at the posterior mode is higher than other regions of the parameter space. In this case, the algorithm may make efficient proposals near the posterior mode, but inefficient proposals in other parts of the parameter space. By reducing the correlation using \texttt{mcrb} the proposal function may be more efficient on average across the entire parameter space and require less thinning (and hence run faster).

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# reduce correlation}
\NormalTok{mc }\OtherTok{\textless{}{-}} \FunctionTok{SCAMCMC}\NormalTok{(}\AttributeTok{mcmc=}\DecValTok{100000}\NormalTok{, }\AttributeTok{mcsave=}\DecValTok{100}\NormalTok{, }\AttributeTok{mcseed=}\DecValTok{10}\NormalTok{, }\AttributeTok{mcrb=}\DecValTok{9}\NormalTok{)}
\NormalTok{fitmc01r }\OtherTok{\textless{}{-}} \FunctionTok{sca}\NormalTok{(hke1567, hke1567.idx, }\AttributeTok{fmodel=}\NormalTok{fmod, }\AttributeTok{qmodel=}\NormalTok{qmod, }\AttributeTok{fit =} \StringTok{"MCMC"}\NormalTok{, }\AttributeTok{mcmc=}\NormalTok{mc)}
\NormalTok{fitmc01r.mc }\OtherTok{\textless{}{-}}\NormalTok{ FLa4a}\SpecialCharTok{::}\FunctionTok{as.mcmc}\NormalTok{(fitmc01r)}
\FunctionTok{data.frame}\NormalTok{(}\AttributeTok{mcrb\_no=}\FunctionTok{c}\NormalTok{(}\FunctionTok{fitSumm}\NormalTok{(fitmc01)),}
    \AttributeTok{mcrb\_high=}\FunctionTok{c}\NormalTok{(}\FunctionTok{fitSumm}\NormalTok{(fitmc01r)),}
    \AttributeTok{row.names=}\FunctionTok{rownames}\NormalTok{(}\FunctionTok{fitSumm}\NormalTok{(fitmc01)))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##               mcrb_no mcrb_high
## nopar        52.00000  52.00000
## nlogl              NA        NA
## maxgrad            NA        NA
## nobs        176.00000 176.00000
## gcv                NA        NA
## convergence        NA        NA
## accrate       0.31914   0.26789
\end{verbatim}

In the next analysis we show the cross-correlation plots (Figure \ref{fig:mcrp}).

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{crosscorr.plot}\NormalTok{(fitmc01.mc, }\AttributeTok{main=}\StringTok{"No mcrp"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\includegraphics[width=0.5\linewidth]{_bookdown_files/_main_files/figure-html/mcrp-1} \caption{Cross correlation for run without mcrp and mcrp of 9.}\label{fig:mcrp-1}
\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{crosscorr.plot}\NormalTok{(fitmc01r.mc, }\AttributeTok{main=}\StringTok{"mcrp = 9"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\includegraphics[width=0.5\linewidth]{_bookdown_files/_main_files/figure-html/mcrp-2} \caption{Cross correlation for run without mcrp and mcrp of 9.}\label{fig:mcrp-2}
\end{figure}

\hypertarget{reference-points}{%
\chapter{Reference Points}\label{reference-points}}

One of the primary objectives of stock assessment is the estimation of reference points. These serve as benchmarks for evaluating the outputs of assessment models and determining the status of a fish stock. Reference points are critical for effective fisheries management, supporting decision makers setting future levels of exploitation.

The most common classification of stock status is bidimensional, comparing exploitation levels and biomass sizes against target reference points. This framework allows for the assessment of whether a stock is overfished or experiencing overfishing:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Exploitation Levels: Typically represented by fishing mortality (\(F\)), overfishing occurs when \(F\) exceeds the target reference point.
\item
  Biomass Size: Commonly measured by spawning stock biomass (\(SSB\)), stocks are deemed overfished if the \(SSB\) falls below the reference point.
\end{enumerate}

These assessments often utilize tools like the Kobe plot, which visually represents stock status in relation to these metrics (\protect\hyperlink{ref-kell2016quantification}{Laurence T. Kell and Sharma 2016}).

In addition to target reference points, limit reference points (LRPs) are commonly included in stock assessments. These represent thresholds that should not be crossed, as they signal a high risk of stock collapse or significant uncertainty in population dynamics. Effective management aims to maintain fishing pressure and biomass levels away from these limits to ensure long-term sustainability and reduce the risk of adverse outcomes.

In 1982, the United Nations Convention on the Law of the Sea (UNCLOS, United Nations (\protect\hyperlink{ref-unclos1982}{1982})), in Article 61, required coastal states to determine and maintain, or restore, populations of harvested species at levels capable of producing the maximum sustainable yield (MSY). MSY is defined as the largest yield (catch) that can be taken from a specific fish stock over an indefinite period without causing stock depletion. Since then MSY and its proxies, such as \(B_{MSY}\) (biomass at MSY) and \(F_{MSY}\) (fishing mortality at MSY), remain widely used. These reference points are related with the stock's productivity, which results of a complex interaction between recruitment, individual growth and mortality processes.

Recruitment refers to the addition of new individuals to a fish population, specifically those that become vulnerable to fishing. It includes the process of spawning, which depends on the reproductive potential of adults, and the survival of larvae until they enter the fishery - a process largely influenced by environmental conditions. Individual growth determines how long it takes for a fish to gain weight, increase in length, and eventually reach maturity and reproduce. Mortality is typically divided into natural mortality and fishing mortality. Natural mortality includes all causes of death unrelated to fishing, such as predation by other species, and is influenced by both environmental factors and biological interactions. Fishing mortality, on the other hand, is primarily driven by human activity and depends on decisions related to fishing practices, including the effort exerted by the fleet, the selectivity of the gear used, and the availability of fish. For example, the productivity of a stock can differ significantly depending on whether a fleet fishes in an area with many juvenile fish using small-mesh nets, or in an area where juvenile fish are scarce and large-mesh nets are used. These processes are interconnected and influenced by a complex mix of environmental conditions and biological characteristics.

For this section we'll be using the package \texttt{FLBRP} (\protect\hyperlink{ref-flbrp}{Laurence T. Kell and Scott 2025}) from the FLR family of packages and its documentation for parts of the text.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(FLBRP)}
\FunctionTok{library}\NormalTok{(FLa4a)}
\FunctionTok{data}\NormalTok{(ple4)}
\FunctionTok{data}\NormalTok{(ple4.indices)}
\NormalTok{fit0 }\OtherTok{\textless{}{-}} \FunctionTok{sca}\NormalTok{(ple4, ple4.indices)}
\NormalTok{stk0 }\OtherTok{\textless{}{-}}\NormalTok{ ple4 }\SpecialCharTok{+}\NormalTok{ fit0}
\end{Highlighting}
\end{Shaded}

To proceed with the computation of reference points we must start by creating an \texttt{FLBRP} object and afterwards run the fitting process with \texttt{brp()}. The \texttt{FLBRP} class has information on selection pattern, mass at age, and biological parameters (see \texttt{?FLBRP} for a full description of this class).

Slots named \texttt{*.obs} will contain the related time series present in the original \texttt{FLStock} object, while other slots will contain averages across the year dimension over the last \(n\) years, where \(n\) is controlled by the arguments \texttt{biol.nyears}, \texttt{fbar.nyears} and \texttt{sel.nyears} (Table \ref{tab:brpargs})

\begin{longtable}[]{@{}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.2222}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.2222}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.5556}}@{}}
\caption{\label{tab:brpargs} Arguments available to create \texttt{FLBRP} object.}\tabularnewline
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedleft
Argument
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Default value
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Description
\end{minipage} \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedleft
Argument
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Default value
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Description
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\texttt{fbar} & \texttt{seq(0,\ 4,\ length.out\ =\ 101)} & Vector of Fs to find minimum or maximum value of metric, e.g.~MSY \\
\texttt{nyears} & \texttt{3} & Number of years to average across to estimate input quantities for reference points estimation \\
\texttt{biol.nyears} & \texttt{nyears} & Number of years to average across to estimate biological quantities, e.g.~maturity \\
\texttt{fbar.nyears} & \texttt{nyears} & Number of years to average across to scale F-at-age to 1 and compute selection pattern \\
\texttt{sel.nyears} & \texttt{nyears} & Number of years to average across to compute landings and discards in number of individual per age \\
\texttt{na.rm} & \texttt{TRUE} & Remove \texttt{NA} if existing \\
\texttt{mean} & \texttt{"arithmetic"} & Statistic to average quantities above, alternative is \texttt{"geometric"} for the geometric mean \\
\end{longtable}

By default \texttt{FLBRP} creates a harvest slot with 100 computations of fishing mortality at age scaled from \(\bar{F}=0\) up to \(F_{crash}\) or \(\bar{F}=4\), if the former isn't possible to compute, which is later used to find the reference points.

\hypertarget{yield-per-recruit-reference-points}{%
\section{Yield per recruit reference points}\label{yield-per-recruit-reference-points}}

In the case where no stock recruitment relationship exists, or was fitted, \texttt{brp()} will return yield per recruit reference points. By default it computes biomasses in the absence of fishing, also know as virgin biomass, \(F_{MAX}\), \(F_{0.1}\) and 40\% Spawning per recruit reference points.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{brp0 }\OtherTok{\textless{}{-}} \FunctionTok{FLBRP}\NormalTok{(stk0)}
\NormalTok{brp0 }\OtherTok{\textless{}{-}} \FunctionTok{brp}\NormalTok{(brp0)}
\FunctionTok{summary}\NormalTok{(brp0)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## An object of class "FLBRP"
## 
## Name:  
## Description:  
## Quant: age 
## Dims:  age   year    unit    season  area    iter
##  10  101 1   1   1   1   
## 
## Range:  min  max pgroup  minfbar maxfbar 
##  1   10  10  2   6   
## 
## 
## Model:   rec ~ a
##     params
## iter a
##    1 1
## 
## refpts:  calculated
\end{verbatim}

The selection pattern and other quantities can be depicted by calling \texttt{plot()} on the specific \texttt{FLBRP} object's slot.

\includegraphics{_bookdown_files/_main_files/figure-html/selection pattern-1.png}

\includegraphics{_bookdown_files/_main_files/figure-html/relevant quantities for reference points-1.png}

To extract a table with all reference points one uses the method \texttt{refpts()}. Note in this case \(F_{msy}\) is the same as \(F_{max}\), since the assumed stock recruitment is mean recruitment.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{refpts}\NormalTok{(brp0)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## An object of class "FLPar"
##         quant
## refpt    harvest  yield    rec      ssb      biomass  revenue  cost    
##   virgin 0.00e+00 0.00e+00 1.00e+00 3.42e+00 3.53e+00       NA       NA
##   msy    2.10e-01 7.08e-02 1.00e+00 9.44e-01 1.03e+00       NA       NA
##   crash  1.47e+01 6.02e-06 1.00e+00 4.38e-06 2.87e-02       NA       NA
##   f0.1   1.58e-01 6.85e-02 1.00e+00 1.28e+00 1.38e+00       NA       NA
##   fmax   2.10e-01 7.08e-02 1.00e+00 9.44e-01 1.03e+00       NA       NA
##   spr.30 1.96e-01 7.06e-02 1.00e+00 1.03e+00 1.12e+00       NA       NA
##   mey          NA       NA       NA       NA       NA       NA       NA
##         quant
## refpt    profit  
##   virgin       NA
##   msy          NA
##   crash        NA
##   f0.1         NA
##   fmax         NA
##   spr.30       NA
##   mey          NA
## units:  NA
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{refpts}\NormalTok{(brp0)[}\FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}msy\textquotesingle{}}\NormalTok{, (}\StringTok{\textquotesingle{}fmax\textquotesingle{}}\NormalTok{)), ]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## An object of class "FLPar"
##       quant
## refpt  harvest yield  rec    ssb    biomass revenue cost   profit
##   msy  0.2099  0.0708 1.0000 0.9436 1.0349      NA      NA     NA
##   fmax 0.2099  0.0708 1.0000 0.9436 1.0349      NA      NA     NA
## units:  NA
\end{verbatim}

The depiction of the reference points with the method \texttt{plot()} shows recruitment as constant over all levels of biomass and set to \(1\).

\includegraphics{_bookdown_files/_main_files/figure-html/reference points-1.png}

\hypertarget{stock-recruitment-relationship-based-reference-points}{%
\section{Stock recruitment relationship based reference points}\label{stock-recruitment-relationship-based-reference-points}}

An important way to improve reference points is to include stock recruitment dynamics. Yield per recruit, as in the previous section, ignores these dynamics and assumes recruitment will be the same no matter \(SSB\)'s size. To inform \texttt{brp()} to take stock recruitment dynamics into account, the stock recruitment model must be fitted and the resulting \texttt{FLSR} object passed to the \texttt{FLBRP} call when creating the \texttt{FLBRP} object.

There's two ways of fitting stock recruitment models: (i) after fitting the stock assessment model by using its outputs, \(SSB\) and recruitment, as data to fit the model; (ii) inside the stock assessment model together with all other quantities. There's pros and cons on both approaches, we're not going to dwell on those now though.

\hypertarget{stock-recruitment-after-fitting-the-stock-assessment-model}{%
\subsection{Stock recruitment after fitting the stock assessment model}\label{stock-recruitment-after-fitting-the-stock-assessment-model}}

In the following example we'll use a Beverton and Holt stock recruitment relationship. There are several other relationships that can be used, see \texttt{?bevholt} for more details.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sr0 }\OtherTok{\textless{}{-}} \FunctionTok{as.FLSR}\NormalTok{(stk0, }\AttributeTok{model=}\NormalTok{bevholt)}
\NormalTok{sr0 }\OtherTok{\textless{}{-}} \FunctionTok{fmle}\NormalTok{(sr0, }\AttributeTok{control =} \FunctionTok{list}\NormalTok{(}\AttributeTok{trace =} \DecValTok{0}\NormalTok{))}
\FunctionTok{plot}\NormalTok{(sr0)}
\end{Highlighting}
\end{Shaded}

\includegraphics{_bookdown_files/_main_files/figure-html/unnamed-chunk-103-1.png}

We now need to provide the \texttt{FLSR} object, \texttt{sr0}, to the \texttt{FLBRP()} and refit the reference points.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{brp0 }\OtherTok{\textless{}{-}} \FunctionTok{FLBRP}\NormalTok{(stk0, }\AttributeTok{sr=}\NormalTok{sr0)}
\FunctionTok{model}\NormalTok{(brp0)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## rec ~ a * ssb/(b + ssb)
## <environment: 0x6447df4d4fd0>
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{params}\NormalTok{(brp0)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## An object of class "FLPar"
## params
##       a       b 
## 1038832    9829 
## units:  NA
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{brp0 }\OtherTok{\textless{}{-}} \FunctionTok{brp}\NormalTok{(brp0)}
\end{Highlighting}
\end{Shaded}

The new reference points can now be extracted using \texttt{refpts()} with the \texttt{FLBRP} object as the main argument, and depict the relationships with \texttt{plot()}. Note this time by setting the flag \texttt{obs} to \texttt{TRUE} the plot will include the estimates of \(SSB\) and \(R\).

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{refpts}\NormalTok{(brp0)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## An object of class "FLPar"
##         quant
## refpt    harvest  yield    rec      ssb      biomass  revenue  cost    
##   virgin 0.00e+00 0.00e+00 1.04e+06 3.54e+06 3.65e+06       NA       NA
##   msy    2.07e-01 7.28e+04 1.03e+06 9.87e+05 1.08e+06       NA       NA
##   crash  2.25e+00 1.11e-06 3.87e-04 3.66e-06 1.83e-05       NA       NA
##   f0.1   1.58e-01 7.06e+04 1.03e+06 1.32e+06 1.42e+06       NA       NA
##   fmax   2.10e-01 7.28e+04 1.03e+06 9.70e+05 1.06e+06       NA       NA
##   spr.30 1.96e-01 7.27e+04 1.03e+06 1.06e+06 1.15e+06       NA       NA
##   mey          NA       NA       NA       NA       NA       NA       NA
##         quant
## refpt    profit  
##   virgin       NA
##   msy          NA
##   crash        NA
##   f0.1         NA
##   fmax         NA
##   spr.30       NA
##   mey          NA
## units:  NA
\end{verbatim}

Note \(MSY\) based reference points are no longer the same as \(F_{MAX}\), and recruitment is no longer constant over all \(SSB\) levels.

\includegraphics{_bookdown_files/_main_files/figure-html/unnamed-chunk-106-1.png}

\hypertarget{stock-recruitment-during-stock-assessment-model-fit}{%
\subsection{Stock recruitment during stock assessment model fit}\label{stock-recruitment-during-stock-assessment-model-fit}}

An alternative option, using \texttt{sca()}, its to fit the stock recruitment model together with the stock assessment model fit, and create the \texttt{FLSR} object from the fit object (Figure \ref{fig:a4asr}).

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# fit with Beverton and Holt model}
\NormalTok{fit1 }\OtherTok{\textless{}{-}} \FunctionTok{sca}\NormalTok{(ple4, ple4.indices, }\AttributeTok{srmodel =} \SpecialCharTok{\textasciitilde{}} \FunctionTok{bevholt}\NormalTok{(}\AttributeTok{CV =} \FloatTok{0.5}\NormalTok{))}
\CommentTok{\# create FLSR object}
\NormalTok{a4aflsr }\OtherTok{\textless{}{-}} \FunctionTok{as}\NormalTok{(fit1, }\StringTok{"FLSR"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(a4aflsr, }\AttributeTok{obs =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/a4asr-1.png}
\caption{\label{fig:a4asr}Stock recruitment model estimated by \texttt{sca()}}
\end{figure}

Create the \texttt{FLBRP} object with the new \texttt{FLSR} object with the stock recruitment model fitted with \texttt{sca()} and fit a new set of reference points (Figure \ref{fig:a4arp}). Note the reference points are slightly different. The stock recruitment parameters estimated with \texttt{sca()} take into account all the other parameters and as such are not exactly the same, ultimately resulting in a distinct set of reference points.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# create FLBRP object}
\NormalTok{a4abrp }\OtherTok{\textless{}{-}} \FunctionTok{FLBRP}\NormalTok{(stk0, a4aflsr)}
\NormalTok{a4abrp }\OtherTok{\textless{}{-}} \FunctionTok{brp}\NormalTok{(a4abrp)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(a4aflsr, }\AttributeTok{obs =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/a4arp-1.png}
\caption{\label{fig:a4arp}Reference points estimated with \texttt{sca()} stock recruitment fit}
\end{figure}

\hypertarget{economics-reference-points}{%
\section{Economics reference points}\label{economics-reference-points}}

We can add economic data to the \texttt{FLBRP} object to calculate economic based reference points, like maximum economic yield (MEY). We need to provide information about price, variable costs and fixed costs. The first in value at age per weight of fish, the others in value per unit of fishing mortality.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# price}
\FunctionTok{price}\NormalTok{(brp0) }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\FunctionTok{rep}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{3}\NormalTok{),}\FunctionTok{rep}\NormalTok{(}\FloatTok{1.5}\NormalTok{,}\DecValTok{2}\NormalTok{),}\FunctionTok{rep}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{5}\NormalTok{))}
\FunctionTok{price}\NormalTok{(brp0)}\SpecialCharTok{@}\NormalTok{units }\OtherTok{\textless{}{-}} \StringTok{"1000 euro per ton"}

\CommentTok{\# variable costs per F }
\FunctionTok{vcost}\NormalTok{(brp0) }\OtherTok{\textless{}{-}} \DecValTok{100000}
\FunctionTok{vcost}\NormalTok{(brp0)}\SpecialCharTok{@}\NormalTok{units }\OtherTok{\textless{}{-}} \StringTok{"1000 euro per F"}

\CommentTok{\# fixed costs per F }
\FunctionTok{fcost}\NormalTok{(brp0) }\OtherTok{\textless{}{-}} \DecValTok{50000}
\FunctionTok{fcost}\NormalTok{(brp0)}\SpecialCharTok{@}\NormalTok{units }\OtherTok{\textless{}{-}} \StringTok{"1000 euro per F"}

\CommentTok{\# reference points}
\NormalTok{brp0 }\OtherTok{\textless{}{-}} \FunctionTok{brp}\NormalTok{(brp0)}
\FunctionTok{refpts}\NormalTok{(brp0)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## An object of class "FLPar"
##         quant
## refpt    harvest   yield     rec       ssb       biomass   revenue   cost     
##   virgin  0.00e+00  0.00e+00  1.04e+06  3.54e+06  3.65e+06  0.00e+00  5.00e+04
##   msy     2.07e-01  7.28e+04  1.03e+06  9.87e+05  1.08e+06  1.21e+05  7.07e+04
##   crash   2.25e+00  1.11e-06  3.87e-04  3.66e-06  1.83e-05  1.15e-06  2.75e+05
##   f0.1    1.58e-01  7.06e+04  1.03e+06  1.32e+06  1.42e+06  1.20e+05  6.58e+04
##   fmax    2.10e-01  7.28e+04  1.03e+06  9.70e+05  1.06e+06  1.21e+05  7.10e+04
##   spr.30  1.96e-01  7.27e+04  1.03e+06  1.06e+06  1.15e+06  1.22e+05  6.96e+04
##   mey     1.64e-01  7.12e+04  1.03e+06  1.27e+06  1.37e+06  1.20e+05  6.64e+04
##         quant
## refpt    profit   
##   virgin -5.00e+04
##   msy     5.07e+04
##   crash  -2.75e+05
##   f0.1    5.38e+04
##   fmax    5.03e+04
##   spr.30  5.21e+04
##   mey     5.39e+04
## units:  NA
\end{verbatim}

The reference points table is now complete with values for \texttt{revenue}, \texttt{costs} and \texttt{profit}, as well as estimates for \(MEY\) based reference points. The point where \texttt{profits} are maximized, instead of the point where \texttt{catch} is maximized as in the case of \texttt{MSY} (Figure \ref{fig:ecorp}).

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(brp0)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/ecorp-1.png}
\caption{\label{fig:ecorp}Reference points including economic reference points}
\end{figure}

\hypertarget{computing-user-specific-reference-points}{%
\section{Computing user specific reference points}\label{computing-user-specific-reference-points}}

The user may want to calculate specific ``reference points'' given F levels. The example below shows how it can be done, having in mind that by specifying F levels the user may be computing arbitrary references.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{custom\_refs }\OtherTok{\textless{}{-}} \FunctionTok{FLPar}\NormalTok{(}\AttributeTok{Ftrgt1 =} \FloatTok{0.33}\NormalTok{, }\AttributeTok{Ftrgt2 =} \FloatTok{0.44}\NormalTok{)}
\NormalTok{brp1 }\OtherTok{\textless{}{-}}\NormalTok{ brp0 }\SpecialCharTok{+}\NormalTok{ custom\_refs}
\FunctionTok{refpts}\NormalTok{(brp1)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## An object of class "FLPar"
##         quant
## refpt    harvest   yield     rec       ssb       biomass   revenue   cost     
##   virgin  0.00e+00  0.00e+00  1.04e+06  3.54e+06  3.65e+06  0.00e+00  5.00e+04
##   msy     2.07e-01  7.28e+04  1.03e+06  9.87e+05  1.08e+06  1.21e+05  7.07e+04
##   crash   2.25e+00  1.11e-06  3.87e-04  3.66e-06  1.83e-05  1.15e-06  2.75e+05
##   f0.1    1.58e-01  7.06e+04  1.03e+06  1.32e+06  1.42e+06  1.20e+05  6.58e+04
##   fmax    2.10e-01  7.28e+04  1.03e+06  9.70e+05  1.06e+06  1.21e+05  7.10e+04
##   spr.30  1.96e-01  7.27e+04  1.03e+06  1.06e+06  1.15e+06  1.22e+05  6.96e+04
##   mey     1.64e-01  7.12e+04  1.03e+06  1.27e+06  1.37e+06  1.20e+05  6.64e+04
##   Ftrgt1  3.30e-01  6.53e+04  1.02e+06  4.95e+05  5.80e+05  1.05e+05  8.30e+04
##   Ftrgt2  4.40e-01  5.37e+04  1.00e+06  2.81e+05  3.58e+05  8.27e+04  9.40e+04
##         quant
## refpt    profit   
##   virgin -5.00e+04
##   msy     5.07e+04
##   crash  -2.75e+05
##   f0.1    5.38e+04
##   fmax    5.03e+04
##   spr.30  5.21e+04
##   mey     5.39e+04
##   Ftrgt1  2.16e+04
##   Ftrgt2 -1.13e+04
## units:  NA
\end{verbatim}

One specific case of user tailored reference points is to compute \(F_{MSY}\) ranges according to Hilborn (\protect\hyperlink{ref-HILBORN2010193}{2010}) and Rindorf et al. (\protect\hyperlink{ref-Rindorf_etal_2016}{2016}) ideas. For this case there's already the method \texttt{msyRanges()}, which takes as argument a fitted \texttt{FLBRP} object and delivers a \texttt{FLPar} object, similar to \texttt{refpts} with the lower and upper boundary of F according to the specified range multiplier, e.g.~if 0.05 the ranges will reflect \((1-0.05) \times F_{MSY}\) and \((1+0.05) \times F_{MSY}\).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rp.rngs }\OtherTok{\textless{}{-}} \FunctionTok{msyRange}\NormalTok{(brp0, }\AttributeTok{range=}\FloatTok{0.05}\NormalTok{)}
\NormalTok{rp.rngs}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## An object of class "FLPar"
##      quantity
## refpt harvest  yield    rec      ssb      biomass  revenue  cost     profit  
##   msy 2.07e-01 7.28e+04 1.03e+06 9.87e+05 1.08e+06 1.21e+05 7.07e+04 5.07e+04
##   min 1.45e-01 6.92e+04 1.03e+06 1.43e+06 1.53e+06 1.18e+05 6.45e+04 5.31e+04
##   max 2.87e-01 6.92e+04 1.02e+06 6.26e+05 7.14e+05 1.12e+05 7.87e+04 3.36e+04
## units:  NA
\end{verbatim}

\hypertarget{assessing-the-status-of-the-stock}{%
\section{Assessing the status of the stock}\label{assessing-the-status-of-the-stock}}

One of the most important outcomes of the stock assessment process is determining the status of the stock relative to the objectives for \(SSB\) and \(F\).

On one hand, these objectives reflect the level of risk policy makers are willing to accept, expressed as biomass levels intended to remain at sea, typically linked to the replenishing capacity of the stock and risk of collapse. For example, larger biomasses generally results in lower probability of collapse, increased recruitment and stock replenishing.

On the other hand, objectives consider food production, represented by the fishing mortality levels (\(F\)). At similar \(SSB\) levels, higher fishing mortality will result in larger catches but will also cause greater reductions in \(SSB\) after the fishing season.

Policy makers, with the support of scientific advisors, have to find a balance between these two objectives, food production and stock collapse, to guarantee the long term sustainability of the stocks. As such computing the status of the stock in relation to \(SSB\) and \(F\) becomes one of the most important pieces of information scientists can provide.

For this exercise we'll use the kobe plot (\protect\hyperlink{ref-kell2016quantification}{Laurence T. Kell and Sharma 2016}), which depicts estimates of \(SSB\) over \(SSB_{target}\) and \(F\) over \(F_{target}\) in a plot with \(SSB\) in the x axis and \(F\) in the y axis (Figure \ref{fig:kobeplot}). The inspection of the plot allows a quick overview of the exploitation history of the stock and the current status in relation to the objectives set.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# ssb and F relative to MSY reference points}
\NormalTok{ssb\_ssbmsy }\OtherTok{\textless{}{-}} \FunctionTok{ssb}\NormalTok{(ple4}\SpecialCharTok{+}\NormalTok{fit1)}\SpecialCharTok{/}\FunctionTok{refpts}\NormalTok{(a4abrp)[}\StringTok{"msy"}\NormalTok{, }\StringTok{"ssb"}\NormalTok{]}
\NormalTok{f\_fmsy }\OtherTok{\textless{}{-}} \FunctionTok{fbar}\NormalTok{(ple4}\SpecialCharTok{+}\NormalTok{fit1)}\SpecialCharTok{/}\FunctionTok{refpts}\NormalTok{(a4abrp)[}\StringTok{"msy"}\NormalTok{, }\StringTok{"harvest"}\NormalTok{]}

\CommentTok{\# code to compute kobe plot}
\FunctionTok{ggplot}\NormalTok{(}\AttributeTok{mapping=}\FunctionTok{aes}\NormalTok{(}\AttributeTok{y=}\FunctionTok{c}\NormalTok{(f\_fmsy), }\AttributeTok{x=}\FunctionTok{c}\NormalTok{(ssb\_ssbmsy))) }\SpecialCharTok{+}
  \CommentTok{\# Add quadrants}
  \FunctionTok{geom\_rect}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{xmin =} \DecValTok{1}\NormalTok{, }\AttributeTok{xmax =} \ConstantTok{Inf}\NormalTok{, }\AttributeTok{ymin =} \DecValTok{0}\NormalTok{, }\AttributeTok{ymax =} \DecValTok{1}\NormalTok{), }\AttributeTok{fill =} \StringTok{"green"}\NormalTok{, }\AttributeTok{alpha =} \FloatTok{0.5}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_rect}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{xmin =} \DecValTok{0}\NormalTok{, }\AttributeTok{xmax =} \DecValTok{1}\NormalTok{, }\AttributeTok{ymin =} \DecValTok{0}\NormalTok{, }\AttributeTok{ymax =} \DecValTok{1}\NormalTok{), }\AttributeTok{fill =} \StringTok{"yellow"}\NormalTok{, }\AttributeTok{alpha =} \FloatTok{0.5}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_rect}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{xmin =} \DecValTok{0}\NormalTok{, }\AttributeTok{xmax =} \DecValTok{1}\NormalTok{, }\AttributeTok{ymin =} \DecValTok{1}\NormalTok{, }\AttributeTok{ymax =} \ConstantTok{Inf}\NormalTok{), }\AttributeTok{fill =} \StringTok{"red"}\NormalTok{, }\AttributeTok{alpha =} \FloatTok{0.5}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_rect}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{xmin =} \DecValTok{1}\NormalTok{, }\AttributeTok{xmax =} \ConstantTok{Inf}\NormalTok{, }\AttributeTok{ymin =} \DecValTok{1}\NormalTok{, }\AttributeTok{ymax =} \ConstantTok{Inf}\NormalTok{), }\AttributeTok{fill =} \StringTok{"yellow"}\NormalTok{, }\AttributeTok{alpha =} \FloatTok{0.5}\NormalTok{) }\SpecialCharTok{+}
  \CommentTok{\# Reference lines}
  \FunctionTok{geom\_vline}\NormalTok{(}\AttributeTok{xintercept =} \DecValTok{1}\NormalTok{, }\AttributeTok{linetype =} \StringTok{"dashed"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_hline}\NormalTok{(}\AttributeTok{yintercept =} \DecValTok{1}\NormalTok{, }\AttributeTok{linetype =} \StringTok{"dashed"}\NormalTok{) }\SpecialCharTok{+}
  \CommentTok{\# Points}
  \FunctionTok{geom\_point}\NormalTok{(}\AttributeTok{size =} \DecValTok{2}\NormalTok{) }\SpecialCharTok{+}
  \CommentTok{\# lines}
  \FunctionTok{geom\_path}\NormalTok{(}\AttributeTok{arrow =} \FunctionTok{arrow}\NormalTok{(}\AttributeTok{type =} \StringTok{"open"}\NormalTok{, }\AttributeTok{length =} \FunctionTok{unit}\NormalTok{(}\FloatTok{0.15}\NormalTok{, }\StringTok{"inches"}\NormalTok{)), }\AttributeTok{linewidth =} \FloatTok{0.5}\NormalTok{) }\SpecialCharTok{+}
  \CommentTok{\# Labels and theme}
  \FunctionTok{labs}\NormalTok{(}
    \AttributeTok{x =} \FunctionTok{expression}\NormalTok{(B }\SpecialCharTok{/}\NormalTok{ B[MSY]),}
    \AttributeTok{y =} \FunctionTok{expression}\NormalTok{(F }\SpecialCharTok{/}\NormalTok{ F[MSY]),}
\NormalTok{  ) }\SpecialCharTok{+}
  \FunctionTok{theme\_minimal}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/kobeplot-1.png}
\caption{\label{fig:kobeplot}Kobe plot trajectory}
\end{figure}

\hypertarget{projections-and-harvest-control-rules}{%
\chapter{Projections and harvest control rules}\label{projections-and-harvest-control-rules}}

Prediction in general science can be categorized into two main components: forecasting and projection (\protect\hyperlink{ref-massad2005}{Massad et al. 2005}). According to this definition, a forecast is an attempt to predict what will happen, whereas a projection describes what would happen given certain hypotheses.

This distinction is also reflected by the Organisation for Economic Co-operation and Development (OECD) (\protect\hyperlink{ref-OECD}{OECD 2009}), which notes that ``forecasting'' and ``prediction'' are often used interchangeably when estimating the future value of a given variable. The term projection is generally used in two interrelated senses: (1) as a future value of a time series computed based on specific assumptions about environmental changes, and (2) in probability theory, as the conditional expectation of a variable (\protect\hyperlink{ref-OECD}{OECD 2009}).

Applying this conceptual framework to fisheries science, the process of advising on future fishing opportunities is best viewed as a projection exercise. Predicting future outcomes is always conditioned on assumptions about the future, e.g., recruitment, or used to test hypotheses, e.g.~regarding levels of extraction.

In the multi-stage stock assessment process described in this book, projections are not part of the stock assessment modeling itself. The assessment concludes when analysts compare estimates of biomass and fishing mortality with reference points, determining whether a stock is overfished or subject to overfishing (\protect\hyperlink{ref-hilborn2013quantitative}{Hilborn and Walters 2013}). Projections typically follow this assessment and incorporate estimates or assumptions about population dynamics---such as growth, reproduction, and natural mortality---to predict future catches, biomass, and abundance under specific conditions and quantified uncertainty. This final stage aims at providing scientific advice to decision-makers about potential consequences of the decisions they need to make.

For this section we will be using the package \texttt{FLasher} (\protect\hyperlink{ref-flasher}{Mosqueira and Scott 2025}; \protect\hyperlink{ref-flasher2016}{Scott and Mosqueira 2016}) from the FLR toolset.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(FLa4a)}
\FunctionTok{library}\NormalTok{(FLasher)}
\FunctionTok{library}\NormalTok{(FLBRP)}
\FunctionTok{data}\NormalTok{(ple4)}
\FunctionTok{data}\NormalTok{(ple4.indices)}
\end{Highlighting}
\end{Shaded}

\hypertarget{simple-workflow}{%
\section{Simple workflow}\label{simple-workflow}}

The basic workflow for projection with \texttt{FLasher} is:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  extend the \texttt{FLStock} object to store future predictions, and to set assumed future values for certain quantities, by using the method \texttt{fwdWindow()}
\item
  set the targets and limits for the projection with the method \texttt{fwdControl()}
\item
  project with the method \texttt{fwd()} using both a \texttt{FLStock} and a \texttt{FLSR} object.
\end{enumerate}

We will start by fitting a model including a stock recruitment relationship which will be used to forecast recruitment. We will also set the number of iterations to work with and the time period we want to project.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# fit model}
\NormalTok{fmod }\OtherTok{\textless{}{-}} \ErrorTok{\textasciitilde{}} \FunctionTok{s}\NormalTok{(age, }\AttributeTok{k =} \DecValTok{8}\NormalTok{) }\SpecialCharTok{+} \FunctionTok{s}\NormalTok{(year, }\AttributeTok{k =} \DecValTok{25}\NormalTok{) }\SpecialCharTok{+} \FunctionTok{te}\NormalTok{(age, year, }\AttributeTok{k =} \FunctionTok{c}\NormalTok{(}\DecValTok{6}\NormalTok{, }\DecValTok{15}\NormalTok{))}
\NormalTok{fit00 }\OtherTok{\textless{}{-}} \FunctionTok{sca}\NormalTok{(ple4, ple4.indices, }\AttributeTok{srmodel=}\SpecialCharTok{\textasciitilde{}}\FunctionTok{geomean}\NormalTok{(}\AttributeTok{CV=}\FloatTok{0.5}\NormalTok{), }\AttributeTok{fmodel=}\NormalTok{fmod)}
\NormalTok{stk00 }\OtherTok{\textless{}{-}}\NormalTok{ ple4 }\SpecialCharTok{+}\NormalTok{ fit00}
\CommentTok{\# create stock recruitment model object}
\NormalTok{sr00 }\OtherTok{\textless{}{-}} \FunctionTok{as}\NormalTok{(fit00, }\StringTok{"FLSR"}\NormalTok{)}
\CommentTok{\# set projection}
\CommentTok{\# number of iterations}
\NormalTok{nsim }\OtherTok{\textless{}{-}} \DecValTok{250}
\CommentTok{\# most recent year in the data}
\NormalTok{maxy }\OtherTok{\textless{}{-}} \FunctionTok{range}\NormalTok{(ple4)[}\StringTok{"maxyear"}\NormalTok{]}
\CommentTok{\# number of years to project}
\NormalTok{projy }\OtherTok{\textless{}{-}} \DecValTok{5}
\CommentTok{\# last year for projections}
\NormalTok{endpy }\OtherTok{\textless{}{-}}\NormalTok{ maxy }\SpecialCharTok{+}\NormalTok{ projy}
\CommentTok{\# initial year for projections}
\NormalTok{inipy }\OtherTok{\textless{}{-}}\NormalTok{ maxy }\SpecialCharTok{+} \DecValTok{1}
\CommentTok{\# extend stock object to store projection\textquotesingle{}s results}
\NormalTok{stk00 }\OtherTok{\textless{}{-}} \FunctionTok{fwdWindow}\NormalTok{(stk00, }\AttributeTok{end =}\NormalTok{ endpy)}
\CommentTok{\# set the control for the projections, in this case a fixed f of 0.3}
\NormalTok{trg00 }\OtherTok{\textless{}{-}} \FunctionTok{fwdControl}\NormalTok{(}\AttributeTok{year =}\NormalTok{ inipy}\SpecialCharTok{:}\NormalTok{endpy, }\AttributeTok{quant =} \StringTok{"f"}\NormalTok{, }\AttributeTok{value =} \FloatTok{0.3}\NormalTok{)}
\CommentTok{\# project}
\NormalTok{stk01 }\OtherTok{\textless{}{-}} \FunctionTok{fwd}\NormalTok{(stk00, }\AttributeTok{control=}\NormalTok{trg00, }\AttributeTok{sr=}\NormalTok{sr00)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/unnamed-chunk-115-1.png}
\caption{\label{fig:unnamed-chunk-115}Projection of stock for 5 years with fixed fishing mortality and recruitment}
\end{figure}

A natural addition to this forecast is to add uncertainty. We will do that by generating uncertainty in population numbers, catch numbers and fishing mortality, through the \texttt{simulate()} function, and add stock recruitment uncertainty using the residuals of the fit.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{stk00 }\OtherTok{\textless{}{-}}\NormalTok{ ple4 }\SpecialCharTok{+} \FunctionTok{simulate}\NormalTok{(fit00, nsim)}
\NormalTok{stk00 }\OtherTok{\textless{}{-}} \FunctionTok{fwdWindow}\NormalTok{(stk00, }\AttributeTok{end =}\NormalTok{ endpy)}
\NormalTok{res00 }\OtherTok{\textless{}{-}} \FunctionTok{residuals}\NormalTok{(sr00)}
\NormalTok{rec00 }\OtherTok{\textless{}{-}} \FunctionTok{window}\NormalTok{(}\FunctionTok{rec}\NormalTok{(stk00), }\DecValTok{2018}\NormalTok{, }\DecValTok{2022}\NormalTok{)}
\NormalTok{rec00 }\OtherTok{\textless{}{-}} \FunctionTok{rlnorm}\NormalTok{(rec00, }\FunctionTok{mean}\NormalTok{(res00), }\FunctionTok{sqrt}\NormalTok{(}\FunctionTok{var}\NormalTok{(res00)))}
\NormalTok{stk02 }\OtherTok{\textless{}{-}} \FunctionTok{fwd}\NormalTok{(stk00, }\AttributeTok{control=}\NormalTok{trg00, }\AttributeTok{sr=}\NormalTok{sr00, }\AttributeTok{residuals=}\NormalTok{rec00)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/unnamed-chunk-117-1.png}
\caption{\label{fig:unnamed-chunk-117}Stochastic projection of stock for 5 years with fixed fishing mortality and recruitment}
\end{figure}

\hypertarget{initial-condition-assumptions}{%
\section{Initial condition assumptions}\label{initial-condition-assumptions}}

When projecting the stock forward one needs to make a number of assumptions about certain quantities and processes in the projection period, for example weights-at-age, maturity or selectivity . The method \texttt{fwdWindow()} has a set of options that allows the analyst to decide about those assumptions:

\begin{longtable}[]{@{}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.2500}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.1250}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.6250}}@{}}
\caption{\label{tab:initcond} Initial conditions}\tabularnewline
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedleft
Argument
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Default value
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Description
\end{minipage} \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedleft
Argument
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Default value
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Description
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\texttt{wt} & 3 & Number of years to average over to get the future mean weights at age \\
\texttt{mat} & 3 & Number of years to average over to get the future proportion mature at age \\
\texttt{m} & 3 & Number of years to average over to get the future natural mortality at age \\
\texttt{spwn} & 3 & Number of years to average over to get the future fraction of mortality before spawning \\
\texttt{discards.ratio} & 3 & Number of years to average over to get the future mean proportion of discards at age \\
\texttt{catch.sel} & 3 & Number of years to average over to get the future selection patern (fishing mortality at age which will be scaled based on changes in \(\bar{F}\)) \\
\end{longtable}

One can also define if those assumptions will be based on the mean value over the time period set, or randomly sampled from historical values, through setting the argument \texttt{fun} to \texttt{mean} or \texttt{sample}, respectively.

For the next examples we will use the approach of fitting the stock recruitment within the assessment together with other parameters. We will set to 20 the number of years to compute mean weights at age, to 10 the number of years to average across and estimate the selection pattern in terms of fishing mortality at age. Finally, we will use a 10 year period to compute the average discard ratio.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit00 }\OtherTok{\textless{}{-}} \FunctionTok{sca}\NormalTok{(ple4, ple4.indices, }\AttributeTok{srmodel=}\SpecialCharTok{\textasciitilde{}}\FunctionTok{geomean}\NormalTok{(), }\AttributeTok{fmodel=}\NormalTok{fmod)}
\NormalTok{sr00 }\OtherTok{\textless{}{-}} \FunctionTok{as}\NormalTok{(fit00, }\StringTok{"FLSR"}\NormalTok{)}
\NormalTok{stk00 }\OtherTok{\textless{}{-}}\NormalTok{ ple4 }\SpecialCharTok{+}\NormalTok{ fit00}
\NormalTok{stk00 }\OtherTok{\textless{}{-}} \FunctionTok{fwdWindow}\NormalTok{(stk00, }\AttributeTok{end =}\NormalTok{ endpy, }\AttributeTok{years =} \FunctionTok{list}\NormalTok{(}\AttributeTok{wt =} \DecValTok{20}\NormalTok{, }\AttributeTok{catch.sel =} \DecValTok{10}\NormalTok{, }\AttributeTok{discards.ratio =} \DecValTok{10}\NormalTok{), }\AttributeTok{fun =} \FunctionTok{list}\NormalTok{(}\AttributeTok{wt =} \StringTok{"sample"}\NormalTok{))}
\NormalTok{trg00 }\OtherTok{\textless{}{-}} \FunctionTok{fwdControl}\NormalTok{(}\AttributeTok{year =}\NormalTok{ inipy}\SpecialCharTok{:}\NormalTok{endpy, }\AttributeTok{quant =} \StringTok{"f"}\NormalTok{, }\AttributeTok{value =} \FloatTok{0.3}\NormalTok{)}
\NormalTok{stk04 }\OtherTok{\textless{}{-}} \FunctionTok{fwd}\NormalTok{(stk00, }\AttributeTok{control=}\NormalTok{trg00, }\AttributeTok{sr=}\NormalTok{sr00)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/unnamed-chunk-122-1.png}
\caption{\label{fig:unnamed-chunk-122}Stochastic projections of stock for 5 years with fixed fishing mortality and recruitment. Two scenarios with different assumptions about initial conditions}
\end{figure}

\hypertarget{scenarios}{%
\section{Scenarios}\label{scenarios}}

There's a wide range of scenarios that can be of interest to project in order to give advice to policy makers, or to better understand the fitted stock assessment model. For example, projecting the stock in the absence of fishing for a few generations, gives good insights about the dynamics of the population being modelled.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit00 }\OtherTok{\textless{}{-}} \FunctionTok{sca}\NormalTok{(ple4, ple4.indices, }\AttributeTok{srmodel=}\SpecialCharTok{\textasciitilde{}}\FunctionTok{geomean}\NormalTok{(), }\AttributeTok{fmodel=}\NormalTok{fmod)}
\NormalTok{sr00 }\OtherTok{\textless{}{-}} \FunctionTok{as}\NormalTok{(fit00, }\StringTok{"FLSR"}\NormalTok{)}
\NormalTok{stk00 }\OtherTok{\textless{}{-}}\NormalTok{ ple4 }\SpecialCharTok{+} \FunctionTok{simulate}\NormalTok{(fit00, nsim)}
\CommentTok{\# set projection}
\NormalTok{projy }\OtherTok{\textless{}{-}} \DecValTok{25}
\NormalTok{endpy }\OtherTok{\textless{}{-}}\NormalTok{ maxy }\SpecialCharTok{+}\NormalTok{ projy}
\NormalTok{inipy }\OtherTok{\textless{}{-}}\NormalTok{ maxy }\SpecialCharTok{+} \DecValTok{1}
\NormalTok{stk00 }\OtherTok{\textless{}{-}} \FunctionTok{fwdWindow}\NormalTok{(stk00, }\AttributeTok{end =}\NormalTok{ endpy)}
\NormalTok{trg00 }\OtherTok{\textless{}{-}} \FunctionTok{fwdControl}\NormalTok{(}\AttributeTok{year =}\NormalTok{ inipy}\SpecialCharTok{:}\NormalTok{endpy, }\AttributeTok{quant =} \StringTok{"f"}\NormalTok{, }\AttributeTok{value =} \DecValTok{0}\NormalTok{)}
\CommentTok{\# recruitment uncertainty}
\NormalTok{res00 }\OtherTok{\textless{}{-}} \FunctionTok{residuals}\NormalTok{(sr00)}
\NormalTok{rec00 }\OtherTok{\textless{}{-}} \FunctionTok{window}\NormalTok{(}\FunctionTok{rec}\NormalTok{(stk00), inipy, endpy)}
\NormalTok{rec00 }\OtherTok{\textless{}{-}} \FunctionTok{rlnorm}\NormalTok{(rec00, }\FunctionTok{mean}\NormalTok{(res00), }\FunctionTok{sqrt}\NormalTok{(}\FunctionTok{var}\NormalTok{(res00)))}
\CommentTok{\# project}
\NormalTok{stk05 }\OtherTok{\textless{}{-}} \FunctionTok{fwd}\NormalTok{(stk00, }\AttributeTok{control=}\NormalTok{trg00, }\AttributeTok{sr=}\NormalTok{sr00, }\AttributeTok{residuals=}\NormalTok{rec00)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/unnamed-chunk-124-1.png}
\caption{\label{fig:unnamed-chunk-124}Stochastic projection of stock for 25 years in the absence of fishing}
\end{figure}

These scenarios are defined by the target quantities set to be achieved. Table \ref{tab:trgqts} \texttt{FLasher} can currently solve for the following target quantities:

\begin{longtable}[]{@{}
  >{\raggedleft\arraybackslash}p{(\columnwidth - 2\tabcolsep) * \real{0.2857}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 2\tabcolsep) * \real{0.7143}}@{}}
\caption{\label{tab:trgqts} Target quantities and their description}\tabularnewline
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedleft
Target
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Description
\end{minipage} \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedleft
Target
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Description
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\texttt{ssb} & The Spawning Stock Biomass at spawning time \\
\texttt{ssb\_spawn} & The Spawning Stock Biomass at spawning time \\
\texttt{ssb\_end} & The Spawning Stock Biomass at the end of the time period \\
\texttt{ssb\_flash} & The Spawning Stock Biomass at the beginning of the following year, kept for retro compatibility with package \texttt{FLash} (\protect\hyperlink{ref-flash}{Laurence T. Kell 2025}) \\
\texttt{biomass\_spawn} & Total Stock Biomass at spawning time \\
\texttt{biomass\_end} & Total Stock Biomass at the end of the time period \\
\texttt{f} & Fishing mortality over the time period \\
\texttt{fbar} & Fishing mortality over the time period \\
\texttt{catch} & The total catch over the time period \\
\texttt{landings} & The total landings over the time period \\
\texttt{discards} & The total discards over the time period \\
\end{longtable}

When projecting the stock under the conditions defined by the scenario one can mix several quantities. For example it may be interesting to project an initial situation of growing the stock followed by a higher exploitation to evaluate how catches would behave.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{trg00 }\OtherTok{\textless{}{-}} \FunctionTok{fwdControl}\NormalTok{(}\AttributeTok{year =}\NormalTok{ inipy}\SpecialCharTok{:}\NormalTok{endpy, }\AttributeTok{quant =} \FunctionTok{c}\NormalTok{(}\FunctionTok{rep}\NormalTok{(}\StringTok{"ssb\_end"}\NormalTok{, }\DecValTok{15}\NormalTok{), }\FunctionTok{rep}\NormalTok{(}\StringTok{"f"}\NormalTok{, }\DecValTok{10}\NormalTok{)),}
    \AttributeTok{value =} \FunctionTok{c}\NormalTok{(}\FunctionTok{rep}\NormalTok{(}\DecValTok{2000000}\NormalTok{, }\DecValTok{15}\NormalTok{), }\FunctionTok{rep}\NormalTok{(}\FloatTok{0.3}\NormalTok{, }\DecValTok{10}\NormalTok{)))}
\NormalTok{stk06 }\OtherTok{\textless{}{-}} \FunctionTok{fwd}\NormalTok{(stk00, }\AttributeTok{control=}\NormalTok{trg00, }\AttributeTok{sr=}\NormalTok{sr00, }\AttributeTok{residuals=}\NormalTok{rec00)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/unnamed-chunk-126-1.png}
\caption{\label{fig:unnamed-chunk-126}Stochastic projection of stock for 25 years with fixed SSB for 15 years followed by fixed fishing mortality for 10 years and constant recruitment}
\end{figure}

\hypertarget{relative-scenarios}{%
\section{Relative scenarios}\label{relative-scenarios}}

Another scenario that is very useful when advising decision makers is to have objectives which are relative to previous values. For example one could increase spawning stock biomass by 10\% each year. This is done buy using the argument \texttt{relYear} and setting \texttt{value} in relative terms, 1.1.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit00 }\OtherTok{\textless{}{-}} \FunctionTok{sca}\NormalTok{(ple4, ple4.indices, }\AttributeTok{srmodel=}\SpecialCharTok{\textasciitilde{}}\FunctionTok{geomean}\NormalTok{())}
\NormalTok{sr00 }\OtherTok{\textless{}{-}} \FunctionTok{as}\NormalTok{(fit00, }\StringTok{"FLSR"}\NormalTok{)}
\NormalTok{stk00 }\OtherTok{\textless{}{-}}\NormalTok{ ple4 }\SpecialCharTok{+} \FunctionTok{simulate}\NormalTok{(fit00, nsim)}
\CommentTok{\# set projection}
\NormalTok{projy }\OtherTok{\textless{}{-}} \DecValTok{5}
\NormalTok{endpy }\OtherTok{\textless{}{-}}\NormalTok{ maxy }\SpecialCharTok{+}\NormalTok{ projy}
\NormalTok{inipy }\OtherTok{\textless{}{-}}\NormalTok{ maxy }\SpecialCharTok{+} \DecValTok{1}
\NormalTok{stk00 }\OtherTok{\textless{}{-}} \FunctionTok{fwdWindow}\NormalTok{(stk00, }\AttributeTok{end =}\NormalTok{ endpy)}
\NormalTok{trg00 }\OtherTok{\textless{}{-}} \FunctionTok{fwdControl}\NormalTok{(}\AttributeTok{year =}\NormalTok{ inipy}\SpecialCharTok{:}\NormalTok{endpy, }\AttributeTok{quant =} \StringTok{"ssb\_end"}\NormalTok{, }\AttributeTok{value =} \FloatTok{1.1}\NormalTok{, }\AttributeTok{relYear =}\NormalTok{ inipy}\SpecialCharTok{:}\NormalTok{endpy}\DecValTok{{-}1}\NormalTok{)}
\CommentTok{\# recruitment uncertainty}
\NormalTok{res00 }\OtherTok{\textless{}{-}} \FunctionTok{residuals}\NormalTok{(sr00)}
\NormalTok{rec00 }\OtherTok{\textless{}{-}} \FunctionTok{window}\NormalTok{(}\FunctionTok{rec}\NormalTok{(stk00), inipy, endpy)}
\NormalTok{rec00 }\OtherTok{\textless{}{-}} \FunctionTok{rlnorm}\NormalTok{(rec00, }\FunctionTok{mean}\NormalTok{(res00), }\FunctionTok{sqrt}\NormalTok{(}\FunctionTok{var}\NormalTok{(res00)))}
\CommentTok{\# project}
\NormalTok{stk07 }\OtherTok{\textless{}{-}} \FunctionTok{fwd}\NormalTok{(stk00, }\AttributeTok{control=}\NormalTok{trg00, }\AttributeTok{sr=}\NormalTok{sr00, }\AttributeTok{residuals=}\NormalTok{rec00)}
\end{Highlighting}
\end{Shaded}

Similar scenarios can be set for all quantities and any years to use as reference. The next example sets a scenario where \(SSB\) levels are set in relation to the most recent estimate out of the assessment.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{trg00 }\OtherTok{\textless{}{-}} \FunctionTok{fwdControl}\NormalTok{(}\AttributeTok{year =}\NormalTok{ inipy}\SpecialCharTok{:}\NormalTok{endpy, }\AttributeTok{quant =} \StringTok{"ssb\_end"}\NormalTok{, }\AttributeTok{value =} \FloatTok{1.1}\NormalTok{, }\AttributeTok{relYear =}\NormalTok{ maxy)}
\NormalTok{stk08 }\OtherTok{\textless{}{-}} \FunctionTok{fwd}\NormalTok{(stk00, }\AttributeTok{control=}\NormalTok{trg00, }\AttributeTok{sr=}\NormalTok{sr00, }\AttributeTok{residuals=}\NormalTok{rec00)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/unnamed-chunk-129-1.png}
\caption{\label{fig:unnamed-chunk-129}Stochastic projection of stock for 25 years with fixed SSB for 15 years followed by fixed fishing mortality for 10 years and constant recruitment. scn01 = 10\% SSB growth relative to previous year; scn02 = 10\% higher SSB relative to most recent estimate}
\end{figure}

\hypertarget{limits}{%
\section{Limits}\label{limits}}

An important element when projecting the stock forward is to keep the performance of the fishery within some boundaries. A common one requested by the industry is to keep catches within some stability. \texttt{fwd()} can include those constraints using the \texttt{min} and \texttt{max} arguments. The next example sets the minimum future catches to half of mean historical catches.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{minc }\OtherTok{\textless{}{-}} \FloatTok{0.2}\SpecialCharTok{*}\FunctionTok{mean}\NormalTok{(}\FunctionTok{catch}\NormalTok{(stk00), }\AttributeTok{na.rm=}\ConstantTok{TRUE}\NormalTok{)}
\NormalTok{trg00 }\OtherTok{\textless{}{-}} \FunctionTok{fwdControl}\NormalTok{(}\AttributeTok{year =}\NormalTok{ inipy}\SpecialCharTok{:}\NormalTok{endpy, }\AttributeTok{quant =} \FunctionTok{rep}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\StringTok{"ssb\_end"}\NormalTok{, }\StringTok{"catch"}\NormalTok{), projy), }\AttributeTok{value =} \FunctionTok{rep}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\DecValTok{1500000}\NormalTok{, }\ConstantTok{NA}\NormalTok{), projy), }\AttributeTok{min=}\FunctionTok{rep}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\ConstantTok{NA}\NormalTok{, minc), projy))}
\NormalTok{stk09 }\OtherTok{\textless{}{-}} \FunctionTok{fwd}\NormalTok{(stk00, }\AttributeTok{control=}\NormalTok{trg00, }\AttributeTok{sr=}\NormalTok{sr00, }\AttributeTok{residuals=}\NormalTok{rec00)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/unnamed-chunk-131-1.png}
\caption{\label{fig:unnamed-chunk-131}Stochastic projection of stock for 25 years with SSB target of 1500000t and catch limit of 50\% historical catches}
\end{figure}

\hypertarget{harvest-control-rules-hcr}{%
\section{Harvest Control Rules (HCR)}\label{harvest-control-rules-hcr}}

Harvest Control Rules (HCR) can be complex and of many shapes (REF). We'll keep our examples simple to demonstrate the mechanism of coding HCR.

HCR are decision algorithms that can be used to codify the decision making process, allowing for longer term stability of management decisions in fisheries.

The HCR we're going to explore is based on a target and a limit. The target is applied to the management objective and represents the intent of management. The limit is applied to the process we want to use as trigger for protective actions. For example, the objective of the management system is to extract the highest catches possible for a very long time (aka equilibrium). However, due to natural variability and scientific uncertainty, it can happen that the stock's biomass decreases below what's expected, in which case decision makers want to make sure the stock stays healthy and productive. This situation can be translated into a target of fishing mortality at the level that extracts the Maximum Sustainable Yield, and a biomass limit of \emph{e.g.} half the biomass that would produce the referred catches, everything being in a stable equilibrium. If \(SSB\) falls below the limit then fishing mortality is set at 80\% of the target.

Such HCR could be written as

\(\text{if} \quad SSB_y > 0.5 \times B_{MSY} \quad \text{then} \quad F_{y+1} = F_{MSY} \quad \text{or else} \quad F_{y+1} = 0.8 \times F_{MSY}\)

and coded like

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# fit model}
\NormalTok{fit00 }\OtherTok{\textless{}{-}} \FunctionTok{sca}\NormalTok{(ple4, ple4.indices, }\AttributeTok{srmodel=}\SpecialCharTok{\textasciitilde{}}\FunctionTok{geomean}\NormalTok{())}
\NormalTok{stk00 }\OtherTok{\textless{}{-}}\NormalTok{ ple4 }\SpecialCharTok{+}\NormalTok{ fit00}
\CommentTok{\# create stock recruitment model object}
\NormalTok{sr00 }\OtherTok{\textless{}{-}} \FunctionTok{as}\NormalTok{(fit00, }\StringTok{"FLSR"}\NormalTok{)}
\CommentTok{\# estimate reference points}
\NormalTok{brp00 }\OtherTok{\textless{}{-}} \FunctionTok{FLBRP}\NormalTok{(stk00, }\AttributeTok{sr=}\NormalTok{sr00)}
\NormalTok{brp00 }\OtherTok{\textless{}{-}} \FunctionTok{brp}\NormalTok{(brp00)}
\NormalTok{ftrg }\OtherTok{\textless{}{-}} \FunctionTok{refpts}\NormalTok{(brp00)[}\StringTok{\textquotesingle{}msy\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}harvest\textquotesingle{}}\NormalTok{]}
\NormalTok{blim }\OtherTok{\textless{}{-}} \FloatTok{0.5}\SpecialCharTok{*}\FunctionTok{refpts}\NormalTok{(brp00)[}\StringTok{\textquotesingle{}msy\textquotesingle{}}\NormalTok{,}\StringTok{\textquotesingle{}biomass\textquotesingle{}}\NormalTok{]}
\CommentTok{\# set projection}
\CommentTok{\# most recent year in the data}
\NormalTok{maxy }\OtherTok{\textless{}{-}} \FunctionTok{range}\NormalTok{(ple4)[}\StringTok{"maxyear"}\NormalTok{]}
\CommentTok{\# number of years to project}
\NormalTok{projy }\OtherTok{\textless{}{-}} \DecValTok{2}
\CommentTok{\# last year for projections}
\NormalTok{endpy }\OtherTok{\textless{}{-}}\NormalTok{ maxy }\SpecialCharTok{+}\NormalTok{ projy}
\CommentTok{\# initial year for projections}
\NormalTok{inipy }\OtherTok{\textless{}{-}}\NormalTok{ maxy }\SpecialCharTok{+} \DecValTok{1}
\CommentTok{\# extend stock object to store projection\textquotesingle{}s results}
\NormalTok{stk00 }\OtherTok{\textless{}{-}} \FunctionTok{fwdWindow}\NormalTok{(stk00, }\AttributeTok{end =}\NormalTok{ endpy)}
\CommentTok{\# set the controls for the projections}
\NormalTok{trg00 }\OtherTok{\textless{}{-}} \FunctionTok{fwdControl}\NormalTok{(}\AttributeTok{year =}\NormalTok{ inipy}\SpecialCharTok{:}\NormalTok{endpy, }\AttributeTok{quant =} \StringTok{"f"}\NormalTok{, }\AttributeTok{value =}\NormalTok{ ftrg)}
\NormalTok{trg01 }\OtherTok{\textless{}{-}} \FunctionTok{fwdControl}\NormalTok{(}\AttributeTok{year =}\NormalTok{ inipy}\SpecialCharTok{:}\NormalTok{endpy, }\AttributeTok{quant =} \StringTok{"f"}\NormalTok{, }\AttributeTok{value =} \FloatTok{0.8}\SpecialCharTok{*}\NormalTok{ftrg)}
\CommentTok{\# project}
\ControlFlowTok{if}\NormalTok{(}\FunctionTok{ssb}\NormalTok{(stk00)[,}\FunctionTok{ac}\NormalTok{(maxy)] }\SpecialCharTok{\textgreater{}}\NormalTok{ blim)\{}
\NormalTok{        stk10 }\OtherTok{\textless{}{-}} \FunctionTok{fwd}\NormalTok{(stk00, }\AttributeTok{control=}\NormalTok{trg00, }\AttributeTok{sr=}\NormalTok{sr00)}
\NormalTok{    \} }\ControlFlowTok{else}\NormalTok{ \{}
\NormalTok{        stk10 }\OtherTok{\textless{}{-}} \FunctionTok{fwd}\NormalTok{(stk00, }\AttributeTok{control=}\NormalTok{trg01, }\AttributeTok{sr=}\NormalTok{sr00)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

A full working HCR would require the above code to be looped throughout the projection years, evaluating each time if \(SSB\) was above \(B_{LIM}\) and if not decreasing \(F\) by 0.8.

\hypertarget{annex---stock-assessment-workflow}{%
\chapter{Annex - stock assessment workflow}\label{annex---stock-assessment-workflow}}

The following sections describes a potential workflow for fitting a \texttt{a4a} stock assessment model. The idea is to explore the age and year effects in isolation and adjust the model's smoothness to model those effects.

The procedure is heavily supported by residuals' analysis. In a well specified model residuals should show a random pattern, without any trend or very high values (outliers).

\hypertarget{the-mean-model}{%
\section{The ``mean'' model}\label{the-mean-model}}

To start the analysis we'll fit a ``mean'' model, where all submodels will be set to an overall average, by using the \texttt{\textasciitilde{}1} formula. This will be our reference model to see how adding age and year effects will show up in the diagnostic tools, in particular in the residuals.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(FLa4a)}
\FunctionTok{data}\NormalTok{(hke1567)}
\FunctionTok{data}\NormalTok{(hke1567.idx)}
\NormalTok{fit01 }\OtherTok{\textless{}{-}} \FunctionTok{sca}\NormalTok{(hke1567, hke1567.idx,}
    \AttributeTok{fmod=}\SpecialCharTok{\textasciitilde{}}\DecValTok{1}\NormalTok{,}
    \AttributeTok{qmod=}\FunctionTok{list}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\DecValTok{1}\NormalTok{),}
    \AttributeTok{srmod=}\SpecialCharTok{\textasciitilde{}}\DecValTok{1}\NormalTok{,}
    \AttributeTok{vmod=}\FunctionTok{list}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\DecValTok{1}\NormalTok{, }\SpecialCharTok{\textasciitilde{}}\DecValTok{1}\NormalTok{),}
    \AttributeTok{n1mod=}\SpecialCharTok{\textasciitilde{}}\DecValTok{1}\NormalTok{)}
\NormalTok{res01 }\OtherTok{\textless{}{-}} \FunctionTok{residuals}\NormalTok{(fit01, hke1567, hke1567.idx)}
\end{Highlighting}
\end{Shaded}

The common residuals plot clearly shows a time trend for each age (Figure \ref{fig:meanresbyage}) for both datasets. Furthermore, inspecting how catch at age residuals are positioned across ages, by comparing the level of residuals for each age, one can see the pattern of lower than 0 residuals in age 0, reversing the signal for ages 1 and 2, close to 0 in ages 3 and 4, and again below 0 in age 5.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(res01)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/meanresbyyear-1.png}
\caption{\label{fig:meanresbyyear}Mean fit residuals by year)}
\end{figure}

This pattern becomes more apparent when plotting the residuals by age across years.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(res01, }\AttributeTok{auxline=}\StringTok{"l"}\NormalTok{, }\AttributeTok{by=}\StringTok{"age"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/meanresbyage-1.png}
\caption{\label{fig:meanresbyage}Mean fit residuals by age}
\end{figure}

\hypertarget{the-age-effects}{%
\section{The age effects}\label{the-age-effects}}

The following models will introduce age effects in the fishing mortality submodel and catchability submodel. In the fishing mortality submodel we'll introduce a \texttt{factor} which means that there will be as many parameters as ages minus 1 and each parameters will be independent of each other.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit02 }\OtherTok{\textless{}{-}} \FunctionTok{sca}\NormalTok{(hke1567, hke1567.idx,}
    \AttributeTok{fmod=}\SpecialCharTok{\textasciitilde{}}\FunctionTok{factor}\NormalTok{(age),}
    \AttributeTok{qmod=}\FunctionTok{list}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\DecValTok{1}\NormalTok{),}
    \AttributeTok{srmod=}\SpecialCharTok{\textasciitilde{}}\DecValTok{1}\NormalTok{,}
    \AttributeTok{vmod=}\FunctionTok{list}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\DecValTok{1}\NormalTok{, }\SpecialCharTok{\textasciitilde{}}\DecValTok{1}\NormalTok{),}
    \AttributeTok{n1mod=}\SpecialCharTok{\textasciitilde{}}\DecValTok{1}\NormalTok{)}
\NormalTok{res02 }\OtherTok{\textless{}{-}} \FunctionTok{residuals}\NormalTok{(fit02, hke1567, hke1567.idx)}
\end{Highlighting}
\end{Shaded}

The residuals plot now shows catch at age residuals less staggered, reflecting the modelling of the age effect.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(res02)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/fageresbyyear-1.png}
\caption{\label{fig:fageresbyyear}Fishing mortality model with age effect residuals by year}
\end{figure}

The residuals plot by age shows the same outcome.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(res02, }\AttributeTok{auxline=}\StringTok{"l"}\NormalTok{, }\AttributeTok{by=}\StringTok{"age"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/fageresbyage-1.png}
\caption{\label{fig:fageresbyage}Fishing mortality model with age effect residuals by age}
\end{figure}

We'll now proceed adding an age effect to the catchability model while removing the catch at age effect.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit03 }\OtherTok{\textless{}{-}} \FunctionTok{sca}\NormalTok{(hke1567, hke1567.idx,}
    \AttributeTok{fmod=}\SpecialCharTok{\textasciitilde{}}\DecValTok{1}\NormalTok{,}
    \AttributeTok{qmod=}\FunctionTok{list}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\FunctionTok{factor}\NormalTok{(age)),}
    \AttributeTok{srmod=}\SpecialCharTok{\textasciitilde{}}\DecValTok{1}\NormalTok{,}
    \AttributeTok{vmod=}\FunctionTok{list}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\DecValTok{1}\NormalTok{, }\SpecialCharTok{\textasciitilde{}}\DecValTok{1}\NormalTok{),}
    \AttributeTok{n1mod=}\SpecialCharTok{\textasciitilde{}}\DecValTok{1}\NormalTok{)}
\NormalTok{res03 }\OtherTok{\textless{}{-}} \FunctionTok{residuals}\NormalTok{(fit03, hke1567, hke1567.idx)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(res03)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/qageresbyyear-1.png}
\caption{\label{fig:qageresbyyear}Index catchability model with age effect residuals by year}
\end{figure}

The residuals plot by age shows the same outcome.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(res03, }\AttributeTok{auxline=}\StringTok{"l"}\NormalTok{, }\AttributeTok{by=}\StringTok{"age"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/qageresbyage-1.png}
\caption{\label{fig:qageresbyage}Index catchability model with age effect residuals by age}
\end{figure}

Finally both effects are brought together.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit04 }\OtherTok{\textless{}{-}} \FunctionTok{sca}\NormalTok{(hke1567, hke1567.idx,}
    \AttributeTok{fmod=}\SpecialCharTok{\textasciitilde{}}\FunctionTok{factor}\NormalTok{(age),}
    \AttributeTok{qmod=}\FunctionTok{list}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\FunctionTok{factor}\NormalTok{(age)),}
    \AttributeTok{srmod=}\SpecialCharTok{\textasciitilde{}}\DecValTok{1}\NormalTok{,}
    \AttributeTok{vmod=}\FunctionTok{list}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\DecValTok{1}\NormalTok{, }\SpecialCharTok{\textasciitilde{}}\DecValTok{1}\NormalTok{),}
    \AttributeTok{n1mod=}\SpecialCharTok{\textasciitilde{}}\DecValTok{1}\NormalTok{)}
\NormalTok{res04 }\OtherTok{\textless{}{-}} \FunctionTok{residuals}\NormalTok{(fit04, hke1567, hke1567.idx)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(res04)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/fqageresbyyear-1.png}
\caption{\label{fig:fqageresbyyear}Fishing mortality and index catchability models with age effect residuals by year}
\end{figure}

The residuals plot by age shows the same outcome.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(res04, }\AttributeTok{auxline=}\StringTok{"l"}\NormalTok{, }\AttributeTok{by=}\StringTok{"age"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/fqageresbyage-1.png}
\caption{\label{fig:fqageresbyage}Fishing mortality and index catchability models with age effect residuals by age}
\end{figure}

\hypertarget{year-effect-on-fishing-mortality}{%
\section{Year effect on fishing mortality}\label{year-effect-on-fishing-mortality}}

This model will introduce an year effect in the fishing mortality submodel on top of the F age effect added before. Inspecting the last set of residuals (Figure \ref{fig:fqageresbyage}) one can easily see the pattern across years with more positive residuals in the beginning of the time series and more negative in the most recent years. As for age we're using a \texttt{factor} for years. The new model's residuals won't show such a pronounced effect anymore (Figures \ref{fig:fyearresbyyear} and \ref{fig:fyearresbyage}).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit05 }\OtherTok{\textless{}{-}} \FunctionTok{sca}\NormalTok{(hke1567, hke1567.idx,}
    \AttributeTok{fmod=}\SpecialCharTok{\textasciitilde{}}\FunctionTok{factor}\NormalTok{(age) }\SpecialCharTok{+} \FunctionTok{factor}\NormalTok{(year),}
    \AttributeTok{qmod=}\FunctionTok{list}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\DecValTok{1}\NormalTok{),}
    \AttributeTok{srmod=}\SpecialCharTok{\textasciitilde{}}\DecValTok{1}\NormalTok{,}
    \AttributeTok{vmod=}\FunctionTok{list}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\DecValTok{1}\NormalTok{, }\SpecialCharTok{\textasciitilde{}}\DecValTok{1}\NormalTok{),}
    \AttributeTok{n1mod=}\SpecialCharTok{\textasciitilde{}}\DecValTok{1}\NormalTok{)}
\NormalTok{res05 }\OtherTok{\textless{}{-}} \FunctionTok{residuals}\NormalTok{(fit05, hke1567, hke1567.idx)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(res05)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/fyearresbyyear-1.png}
\caption{\label{fig:fyearresbyyear}Fishing mortality model with year effect residuals by year}
\end{figure}

The residuals plot by age shows the same outcome.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(res05, }\AttributeTok{auxline=}\StringTok{"l"}\NormalTok{, }\AttributeTok{by=}\StringTok{"age"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/fyearresbyage-1.png}
\caption{\label{fig:fyearresbyage}Fishing mortality model with year effect residuals by age}
\end{figure}

We can see now that the residuals show a lot less patterns than before. There's still some issues, the survey catchability seems to have an year trend. However the model is not fully specified yet, stock recruitment is modelled as constant over time, the initial population abundance is also modelled as a constant as well as the variance models.

\hypertarget{year-effect-on-catchability}{%
\section{Year effect on catchability}\label{year-effect-on-catchability}}

It's uncommon to include year trends on the abundance index catchability model. Such decision needs to be considered carefully as the trend in the index, in the case of a well design scientific survey, should result from a change in abundance. Modelling that trend would attribute such change to the survey design and remove it from the abundance. If the survey index is based on a commercial CPUE it becomes more likely that changes in selectivity or fishing behaviour could show up in the index as changes in abundance. Although the common process of standardizing CPUEs should deal with technical issues.

In the case of adding year effects to the catchability submodel the same formulas can be used, to include period breaks, trends, etc.

\hypertarget{the-initial-year-population-abundance-model-aka-n1}{%
\section{The initial year population abundance model, aka N1}\label{the-initial-year-population-abundance-model-aka-n1}}

This model sets the n-at-age in the first year of the time series, which is needed due to the lack of previous data to reconstruct those cohorts. It will affect the population numbers in the lower triangle of the initial population matrix and catches.

The following model will introduce an age effect in the population abundance in the first year of the time series.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit06 }\OtherTok{\textless{}{-}} \FunctionTok{sca}\NormalTok{(hke1567, hke1567.idx,}
    \AttributeTok{fmod=}\SpecialCharTok{\textasciitilde{}}\FunctionTok{factor}\NormalTok{(age) }\SpecialCharTok{+} \FunctionTok{factor}\NormalTok{(year),}
    \AttributeTok{qmod=}\FunctionTok{list}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\FunctionTok{factor}\NormalTok{(age)),}
    \AttributeTok{srmod=}\SpecialCharTok{\textasciitilde{}}\DecValTok{1}\NormalTok{,}
    \AttributeTok{vmod=}\FunctionTok{list}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\DecValTok{1}\NormalTok{, }\SpecialCharTok{\textasciitilde{}}\DecValTok{1}\NormalTok{),}
    \AttributeTok{n1mod=}\SpecialCharTok{\textasciitilde{}}\FunctionTok{factor}\NormalTok{(age))}
\NormalTok{res06 }\OtherTok{\textless{}{-}} \FunctionTok{residuals}\NormalTok{(fit06, hke1567, hke1567.idx)}
\end{Highlighting}
\end{Shaded}

The best way to inspect the effect of this model is to zoom into the initial years of the time series.

Figure \ref{fig:n1resbyage05} zooms into the previous model, which used an intercept only model for N1, while Figure \ref{fig:n1resbyage06}.

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/n1resbyage05-1.png}
\caption{\label{fig:n1resbyage05}N1 fitted as an intercept only model: 2007 - 2010 residuals by age}
\end{figure}

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/n1resbyage06-1.png}
\caption{\label{fig:n1resbyage06}N1 fitted with an age effect model: 2007 - 2010 residuals by age}
\end{figure}

Comparing the two plots it can be seen the effect of modeling abundance in the initial year. Residuals for both catch at age and catchability improved considerably. The following years also improve to different levels.

\hypertarget{the-stock-recruitment-submodel}{%
\section{The stock recruitment submodel}\label{the-stock-recruitment-submodel}}

In this example we'll simply add a model to allow recruitment to vary over time and we'll see how to track potential improvements in the residuals.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit07 }\OtherTok{\textless{}{-}} \FunctionTok{sca}\NormalTok{(hke1567, hke1567.idx,}
    \AttributeTok{fmod=}\SpecialCharTok{\textasciitilde{}}\FunctionTok{factor}\NormalTok{(age) }\SpecialCharTok{+} \FunctionTok{factor}\NormalTok{(year),}
    \AttributeTok{qmod=}\FunctionTok{list}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\FunctionTok{factor}\NormalTok{(age)),}
    \AttributeTok{srmod=}\SpecialCharTok{\textasciitilde{}}\FunctionTok{factor}\NormalTok{(year),}
    \AttributeTok{vmod=}\FunctionTok{list}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\DecValTok{1}\NormalTok{, }\SpecialCharTok{\textasciitilde{}}\DecValTok{1}\NormalTok{),}
    \AttributeTok{n1mod=}\SpecialCharTok{\textasciitilde{}}\FunctionTok{factor}\NormalTok{(age))}
\NormalTok{res07 }\OtherTok{\textless{}{-}} \FunctionTok{residuals}\NormalTok{(fit07, hke1567, hke1567.idx)}
\end{Highlighting}
\end{Shaded}

The residuals plot by year are very useful to see the effect of adding a varying stock recruitment model. The year trends present in previous models are not absent. Recruitment variability when not modelled was being picked up by trends in the survey catchability and catch at age. And due to the cohort dynamics underlying the catch at age model, where propagating into other ages' estimates.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(res07)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/srresbyyear-1.png}
\caption{\label{fig:srresbyyear}Stock-recruitment model with year effect residuals by year}
\end{figure}

\hypertarget{the-variance-submodel}{%
\section{The variance submodel}\label{the-variance-submodel}}

Finally, we're testing the variance submodel, specifically the catch at age variance model. We won't dig into the catchability variance model though. It's common to accept that a scientific survey following a well designed sampling protocol will have equal variance across ages since no preferential areas should be sampled sampled.

The variance model will use a smoother with \texttt{k=3}. The expectation is that the variance model will have a U-shape, since younger and older ages are usually less caught and as such estimates of those ages will have larger variances than fully exploited ages.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit08 }\OtherTok{\textless{}{-}} \FunctionTok{sca}\NormalTok{(hke1567, hke1567.idx,}
    \AttributeTok{fmod=}\SpecialCharTok{\textasciitilde{}}\FunctionTok{factor}\NormalTok{(age) }\SpecialCharTok{+} \FunctionTok{s}\NormalTok{(year, }\AttributeTok{k=}\DecValTok{10}\NormalTok{),}
    \AttributeTok{qmod=}\FunctionTok{list}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\FunctionTok{factor}\NormalTok{(age)),}
    \AttributeTok{srmod=}\SpecialCharTok{\textasciitilde{}}\FunctionTok{s}\NormalTok{(year, }\AttributeTok{k=}\DecValTok{10}\NormalTok{),}
    \AttributeTok{vmod=}\FunctionTok{list}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\FunctionTok{s}\NormalTok{(age, }\AttributeTok{k=}\DecValTok{3}\NormalTok{), }\SpecialCharTok{\textasciitilde{}}\DecValTok{1}\NormalTok{),}
    \AttributeTok{n1mod=}\SpecialCharTok{\textasciitilde{}}\FunctionTok{factor}\NormalTok{(age))}
\end{Highlighting}
\end{Shaded}

We'll use the pearson residuals for this analysis since those are standardized by the predicted variances of the model and not the residual variance itself, like the more common standardized residuals. Figure \ref{fig:vresbyyear08} shows an improve set of residuals when compared to Figure \ref{fig:vresbyyear07} which add an intercept only model for the variance model.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{res07 }\OtherTok{\textless{}{-}} \FunctionTok{residuals}\NormalTok{(fit07, hke1567, hke1567.idx, }\AttributeTok{type=}\StringTok{"pearson"}\NormalTok{)}
\NormalTok{res08 }\OtherTok{\textless{}{-}} \FunctionTok{residuals}\NormalTok{(fit08, hke1567, hke1567.idx, }\AttributeTok{type=}\StringTok{"pearson"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(res07)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/vresbyyear07-1.png}
\caption{\label{fig:vresbyyear07}Variance model with intercept only age effect pearson residuals}
\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(res08)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/vresbyyear08-1.png}
\caption{\label{fig:vresbyyear08}Variance model with age effect pearson residuals}
\end{figure}

To see what's happening with the variance model one can use predict to plot the different models fitted.

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/vagepredbyage-1.png}
\caption{\label{fig:vagepredbyage}Variance models for catch at age}
\end{figure}

To see the effect these models have on the estimated quantities one can look at the variance of the estimates:

\begin{figure}
\centering
\includegraphics{_bookdown_files/_main_files/figure-html/vage-1.png}
\caption{\label{fig:vage}Estimates of population abundance with different variance models}
\end{figure}

\hypertarget{final-comments}{%
\section{Final comments}\label{final-comments}}

\begin{itemize}
\tightlist
\item
  The sequence presented here can be changed and applied in any order the user is interested or prefers to.
\item
  The approach of not allowing year effects in surveys and variance model can be modified if the user prefers to do so.
\item
  The (ab)use of \texttt{factor} is for demonstration purposes only. The user is incentivised to explore other model forms, in particular smoothers.
\end{itemize}

\hypertarget{references}{%
\chapter{References}\label{references}}

\hypertarget{refs}{}
\begin{CSLReferences}{1}{0}
\leavevmode\vadjust pre{\hypertarget{ref-gadget}{}}%
Begley, James, and Daniel Howell. 2004. {``An Overview of Gadget, the Globally Applicable Area-Disaggregated General Ecosystem Toolbox.''} In. ICES.

\leavevmode\vadjust pre{\hypertarget{ref-cadrin2025misinterpreting}{}}%
Cadrin, Steven X. 2025. {``Misinterpreting Retrospective Patterns in Fishery Stock Assessment.''} \emph{ICES Journal of Marine Science} 82 (2): 473--88. \url{https://doi.org/10.1093/icesjms/fsaf014}.

\leavevmode\vadjust pre{\hypertarget{ref-R-triangle}{}}%
Carnell, Rob. 2022. \emph{Triangle: Distribution Functions and Parameter Estimates for the Triangle Distribution}. \url{https://bertcarnell.github.io/triangle/}.

\leavevmode\vadjust pre{\hypertarget{ref-cookbook2021}{}}%
Carvalho, Felipe, Henning Winker, Dean Courtney, Maia Kapur, Laurence Kell, Massimiliano Cardinale, Michael Schirripa, et al. 2021. {``A Cookbook for Using Model Diagnostics in Integrated Stock Assessments.''} \emph{Fisheries Research} 240: 105959. \url{https://doi.org/10.1016/j.fishres.2021.105959}.

\leavevmode\vadjust pre{\hypertarget{ref-charnov1993}{}}%
Charnov, Eric L. 1993. \emph{Life History Invariants: Some Explorations of Symmetry in Evolutionary Ecology}. Oxford University Press.

\leavevmode\vadjust pre{\hypertarget{ref-ding2023information}{}}%
Ding, Jie. 2023. {``Information Criteria for Model Selection.''} \emph{Wiley Interdisciplinary Reviews: Computational Statistics} 15 (2): e1607. \url{https://doi.org/10.1002/wics.1607}.

\leavevmode\vadjust pre{\hypertarget{ref-fieldwle}{}}%
Field, C., and B. Smith. 1994. {``Robust Estimation: A Weighted Maximum Likelihood Approach.''} \emph{International Statistical Review} 62 (3): 405--24.

\leavevmode\vadjust pre{\hypertarget{ref-Fournier2012}{}}%
Fournier, David A., Hans J. Skaug, Johnoel Ancheta, James Ianelli, Arni Magnusson, Mark N. Maunder, Anders Nielsen, and John Sibert. 2012. {``A{D} Model Builder: Using Automatic Differentiation for Statistical Inference of Highly Parameterized Complex Nonlinear Models.''} \emph{Optim. Methods Softw.} 27 (2): 233--49. \url{https://doi.org/10.1080/10556788.2011.597854}.

\leavevmode\vadjust pre{\hypertarget{ref-fishbase}{}}%
Froese, R., and D. Pauly, eds. 2000. \emph{FishBase 2000: Concepts, Design and Data Sources.} ICLARM, Los BaÃ±os, Laguna, Philippines.

\leavevmode\vadjust pre{\hypertarget{ref-gelman2013bayesian}{}}%
Gelman, A., J. B. Carlin, H. S. Stern, D. B. Dunson, A. Vehtari, and D. B. Rubin. 2013. \emph{Bayesian Data Analysis, Third Edition}. Chapman \& Hall/CRC Texts in Statistical Science. Taylor \& Francis. \url{https://books.google.be/books?id=ZXL6AQAAQBAJ}.

\leavevmode\vadjust pre{\hypertarget{ref-gelman97}{}}%
Gelman, A., W. R. Gilks, and G. O. Roberts. 1997. {``{Weak convergence and optimal scaling of random walk Metropolis algorithms}.''} \emph{The Annals of Applied Probability} 7 (1): 110--20.

\leavevmode\vadjust pre{\hypertarget{ref-gelman1992inference}{}}%
Gelman, Andrew, and Donald B Rubin. 1992. {``Inference from Iterative Simulation Using Multiple Sequences.''} \emph{Statistical Science} 7 (4): 457--72.

\leavevmode\vadjust pre{\hypertarget{ref-copulahistory}{}}%
Genest, Christian, Ostap Okhrin, and Taras Bodnar. 2024. {``Copula Modeling from Abe Sklar to the Present Day.''} \emph{Journal of Multivariate Analysis} 201: 105278. \url{https://doi.org/10.1016/j.jmva.2023.105278}.

\leavevmode\vadjust pre{\hypertarget{ref-Geweke1992}{}}%
Geweke, John. 1992. {``Evaluating the Accuracy of Sampling-Based Approaches to the Calculation of Posterior Moments.''} In \emph{Bayesian Statistics, 4 ({P}eÃ±Ã­scola, 1991)}, 169--93. Oxford Univ. Press, New York.

\leavevmode\vadjust pre{\hypertarget{ref-gilks1995markov}{}}%
Gilks, W. R., S. Richardson, and D. Spiegelhalter. 1995. \emph{Markov Chain Monte Carlo in Practice}. Chapman \& Hall/CRC Interdisciplinary Statistics. Taylor \& Francis. \url{https://books.google.be/books?id=TRXrMWY_i2IC}.

\leavevmode\vadjust pre{\hypertarget{ref-gislason2010}{}}%
Gislason, Henrik, Niels Daan, Jake C Rice, and John G Pope. 2010. {``Size, Growth, Temperature and the Natural Mortality of Marine Fish.''} \emph{Fish and Fisheries} 11 (2): 149--58. \url{https://doi.org/10.1111/j.1467-2979.2009.00350.x}.

\leavevmode\vadjust pre{\hypertarget{ref-MCAPAM2023}{}}%
Hamel, Owen S., James N. Ianelli, Mark N. Maunder, and AndrÃ© E. Punt. 2023. {``Natural Mortality: Theory, Estimation and Application in Fishery Stock Assessment Models.''} \emph{Fisheries Research} 261: 106638. \url{https://doi.org/10.1016/j.fishres.2023.106638}.

\leavevmode\vadjust pre{\hypertarget{ref-hastie2009}{}}%
Hastie, Trevor, Robert Tibshirani, and Jerome Friedman. 2009. \emph{The Elements of Statistical Learning: Data Mining, Inference, and Prediction}. 2nd ed. Springer Science \& Business Media.

\leavevmode\vadjust pre{\hypertarget{ref-hickey2019}{}}%
Hickey, Graeme L., Evangelos Kontopantelis, Johanna J. M. Takkenberg, and Friedhelm Beyersdorf. 2019. {``Statistical Primer: Checking Model Assumptions with Regression Diagnostics.''} \emph{Interactive Cardiovascular and Thoracic Surgery}. \url{https://doi.org/10.1093/ICVTS/IVY207}.

\leavevmode\vadjust pre{\hypertarget{ref-HILBORN2010193}{}}%
Hilborn, Ray. 2010. {``Pretty Good Yield and Exploited Fishes.''} \emph{Marine Policy} 34 (1): 193--96. \url{https://doi.org/10.1016/j.marpol.2009.04.013}.

\leavevmode\vadjust pre{\hypertarget{ref-hilborn2013quantitative}{}}%
Hilborn, Ray, and Carl J Walters. 2013. \emph{Quantitative Fisheries Stock Assessment: Choice, Dynamics and Uncertainty}. Springer Science \& Business Media.

\leavevmode\vadjust pre{\hypertarget{ref-hu2002weighted}{}}%
Hu, Feifang, and James V. Zidek. 2002. {``The Weighted Likelihood.''} \emph{The Canadian Journal of Statistics / La Revue Canadienne de Statistique} 30 (3): 347--71.

\leavevmode\vadjust pre{\hypertarget{ref-Jacobsen_etal_2018}{}}%
Jacobsen, Nis Sand, and Timothy E. Essington. 2018. {``Natural Mortality Augments Population Fluctuations of Forage Fish.''} \emph{Fish and Fisheries} 19 (5): 791--97. \url{https://doi.org/10.1111/FAF.12290}.

\leavevmode\vadjust pre{\hypertarget{ref-EJ_etal_2014}{}}%
Jardim, Ernesto, Colin P. Millar, Iago Mosqueira, Finlay Scott, Giacomo Chato Osio, Marco Ferretti, Nekane Alzorriz, and Alessandro Orio. 2014. {``Food for Thought What If Stock Assessment Is as Simple as a Linear Model? The A4a Initiative.''} \emph{ICES Journal of Marine Science}, January.

\leavevmode\vadjust pre{\hypertarget{ref-R-copula}{}}%
Jun Yan. 2007. {``Enjoy the Joy of Copulas: With a Package {copula}.''} \emph{Journal of Statistical Software} 21 (4): 1--21. \url{https://www.jstatsoft.org/v21/i04/}.

\leavevmode\vadjust pre{\hypertarget{ref-flr}{}}%
Kell, L. T., I. Mosqueira, P. Grosjean, J-M. Fromentin, D. Garcia, R. Hillary, E. Jardim, et al. 2007. {``FLR: An Open-Source Framework for the Evaluation and Development of Management Strategies.''} \emph{ICES Journal of Marine Science} 64: 640--46.

\leavevmode\vadjust pre{\hypertarget{ref-flash}{}}%
Kell, Laurence T. 2025. \emph{FLash: Forecasting and Projection of Fish Stocks}. \url{https://github.com/flr/FLash}.

\leavevmode\vadjust pre{\hypertarget{ref-KELL2016119}{}}%
Kell, Laurence T., Ai Kimoto, and Toshihide Kitakado. 2016. {``Evaluation of the Prediction Skill of Stock Assessment Using Hindcasting.''} \emph{Fisheries Research} 183: 119--27. \url{https://doi.org/10.1016/j.fishres.2016.05.017}.

\leavevmode\vadjust pre{\hypertarget{ref-flbrp}{}}%
Kell, Laurence T., and Finlay Scott. 2025. \emph{FLBRP: Reference Points for Fisheries Management}. \url{http://flr-project.org/FLBRP}.

\leavevmode\vadjust pre{\hypertarget{ref-Kenchington2014}{}}%
Kenchington, Trevor J. 2014. {``Natural Mortality Estimators for Information-Limited Fisheries.''} \emph{Fish and Fisheries} 15 (4): 533--62. \url{https://doi.org/10.1111/faf.12027}.

\leavevmode\vadjust pre{\hypertarget{ref-kell2016quantification}{}}%
Laurence T. Kell, Campbell R. Davies, Polina Levontin, and Rishi Sharma. 2016. {``The Quantification and Presentation of Risk.''} In \emph{Management Science in Fisheries - an Introduction to Simulation-Basedmethods}, edited by Charles T. T. Edwards and Dorothy J. Dankel, 368--94. Routledge.

\leavevmode\vadjust pre{\hypertarget{ref-Luxf3pez_etal_2017}{}}%
LÃ³pez Quintero, Freddy Omar, Javier E. Contreras-Reyes, and Rodrigo Wiff. 2017. {``Incorporating Uncertainty into a Length-Based Estimator of Natural Mortality in Fish Populations.''} \emph{Fishery Bulletin} 115 (3): 355--64. \url{https://doi.org/10.7755/FB.115.3.6}.

\leavevmode\vadjust pre{\hypertarget{ref-Maceina_etal_2016}{}}%
Maceina, Michael J., and Steven M. Sammons. 2016. {``Assessing the Accuracy of Published Natural Mortality Estimators Using Rates Determined from Five Unexploited Freshwater Fish Populations.''} \emph{North American Journal of Fisheries Management} 36 (2): 433--46. \url{https://doi.org/10.1080/02755947.2015.1129002}.

\leavevmode\vadjust pre{\hypertarget{ref-hc2002}{}}%
Mason, Simon, and G. Mimmack. 2002. {``2001: Comparison of Some Statistical Methods of Probabilistic Forecasting of ENSO.''} \emph{Journal of Climate} 15 (February).

\leavevmode\vadjust pre{\hypertarget{ref-massad2005}{}}%
Massad, Eduardo, Marcelo N. Burattini, Luis F. Lopez, and Francisco A. B. Coutinho. 2005. {``Forecasting Versus Projection Models in Epidemiology: The Case of the SARS Epidemics.''} \emph{Medical Hypotheses} 65 (1): 17--22. \url{https://doi.org/10.1016/j.mehy.2004.09.029}.

\leavevmode\vadjust pre{\hypertarget{ref-maunder2023mrev}{}}%
Maunder, Mark N, Owen S Hamel, Hee-Haeng Lee, Kevin R Piner, Jason M Cope, AndrÃ© E Punt, James N Ianelli, Cristian Castillo-Jordan, and Manasa S Kapur. 2023. {``A Review of Estimation Methods for Natural Mortality and Their Performance in the Context of Fishery Stock Assessment.''} \emph{Fisheries Research} 257: 106489. \url{https://doi.org/10.1016/j.fishres.2022.106489}.

\leavevmode\vadjust pre{\hypertarget{ref-maunderPunt2013}{}}%
Maunder, Mark N., and AndrÃ© E. Punt. 2013. {``A Review of Integrated Analysis in Fisheries Stock Assessment.''} \emph{Fisheries Research} 142: 61--74. \url{https://doi.org/10.1016/j.fishres.2012.07.025}.

\leavevmode\vadjust pre{\hypertarget{ref-fla4a}{}}%
Millar, Colin, and Ernesto Jardim. 2025. \emph{FLa4a: A Flexible and Robust Stock Assessment Framework}.

\leavevmode\vadjust pre{\hypertarget{ref-mohn1999retrospective}{}}%
Mohn, R. 1999. {``The Retrospective Problem in Sequential Population Analysis: An Investigation Using Cod Fishery and Simulated Data.''} \emph{ICES Journal of Marine Science} 56 (4): 473--88. \url{https://doi.org/10.1006/jmsc.1999.0481}.

\leavevmode\vadjust pre{\hypertarget{ref-monnahan2019}{}}%
Monnahan, Cole C, Trevor A Branch, James T Thorson, Ian J Stewart, and Cody S Szuwalski. 2019. {``Overcoming Long {Bayesian} Run Times in Integrated Fisheries Stock Assessments.''} Edited by Shijie Zhou. \emph{ICES Journal of Marine Science} 76 (6): 1477--88. \url{https://doi.org/10.1093/icesjms/fsz059}.

\leavevmode\vadjust pre{\hypertarget{ref-monnahan2014admbmcmc}{}}%
Monnahan, Cole C., Melissa L. Muradian, and Peter T. Kuriyama. 2014. \emph{A Guide for Bayesian Analysis in AD Model Builder}. ADMB Project.

\leavevmode\vadjust pre{\hypertarget{ref-flasher}{}}%
Mosqueira, Iago, and Finlay Scott. 2025. \emph{FLasher: Projection and Forecasting of Fish Populations, Stocks and Fleets}.

\leavevmode\vadjust pre{\hypertarget{ref-neal1993probabilistic}{}}%
Neal, Radford M. 1993. {``Probabilistic Inference Using Markov Chain Monte Carlo Methods.''}

\leavevmode\vadjust pre{\hypertarget{ref-OECD}{}}%
OECD. 2009. {``OECD Economic Outlook.''} \url{https://doi.org/10.1787/eco_outlook-v2009-1-en}.

\leavevmode\vadjust pre{\hypertarget{ref-pauly1980}{}}%
Pauly, Daniel. 1980. {``On the Interrelationships Between Natural Mortality, Growth Parameters, and Mean Environmental Temperature in 175 Fish Stocks.''} \emph{ICES Journal of Marine Science} 39 (2): 175--92. \url{https://doi.org/10.1093/icesjms/39.2.175}.

\leavevmode\vadjust pre{\hypertarget{ref-coda}{}}%
Plummer, Martyn, Nicky Best, Kate Cowles, and Karen Vines. 2006. {``CODA: Convergence Diagnosis and Output Analysis for MCMC.''} \emph{R News} 6 (1): 7--11.

\leavevmode\vadjust pre{\hypertarget{ref-pope1972}{}}%
Pope, J. G. 1972. {``An Investigation of the Accuracy of Virtual Population Analysis Using Cohort Analysis.''} \emph{Research Bulletin of the International Commission for the Northwest Atlantic Fisheries} 9: 65--74.

\leavevmode\vadjust pre{\hypertarget{ref-privitera2019}{}}%
Privitera-Johnson, Kristin M, and AndrÃ© E Punt. 2019. {``Leveraging Scientific Uncertainty in Fisheries Management for Estimating Among-Assessment Variation in Overfishing Limits.''} \emph{ICES Journal of Marine Science} 77 (2): 515--26. \url{https://doi.org/10.1093/icesjms/fsz237}.

\leavevmode\vadjust pre{\hypertarget{ref-admb123manual}{}}%
Project, ADMB. 2013. \emph{ADMB 12.3 Manual}. ADMB Foundation.

\leavevmode\vadjust pre{\hypertarget{ref-puntmse}{}}%
Punt, AndrÃ© E, Doug S Butterworth, Carryn L de Moor, JosÃ© A A De Oliveira, and Malcolm Haddon. 2016. {``Management Strategy Evaluation: Best Practices.''} \emph{Fish and Fisheries} 17 (2): 303--34. \url{https://doi.org/10.1111/faf.12104}.

\leavevmode\vadjust pre{\hypertarget{ref-quinn1999}{}}%
Quinn, Terrance J, and Richard B Deriso. 1999. \emph{Quantitative Fish Dynamics}. Oxford University Press.

\leavevmode\vadjust pre{\hypertarget{ref-Rindorf_etal_2016}{}}%
Rindorf, Anna, Catherine Mary Dichmont, Phillip S. Levin, Pamela Mace, Sean Pascoe, Raul Prellezo, AndrÃ© E. Punt, et al. 2016. {``Food for Thought: Pretty Good Multispecies Yield.''} \emph{ICES Journal of Marine Science} 74 (2): 475--86. \url{https://doi.org/10.1093/icesjms/fsw071}.

\leavevmode\vadjust pre{\hypertarget{ref-robert2005monte}{}}%
Robert, C., and G. Casella. 2005. \emph{Monte Carlo Statistical Methods}. Springer Texts in Statistics. Springer New York. \url{https://books.google.be/books?id=HfhGAxn5GugC}.

\leavevmode\vadjust pre{\hypertarget{ref-Robertson_etal_2022}{}}%
Robertson, Matthew D., Paul M. Regular, and Noel G. Cadigan. 2022. {``Limited Temporal Variability in Natural Mortality for Juvenile American Plaice on the Grand Bank of Newfoundland.''} \emph{Journal of Northwest Atlantic Fishery Science} 53 (September): 47--56. \url{https://doi.org/10.2960/j.v53.m738}.

\leavevmode\vadjust pre{\hypertarget{ref-flasher2016}{}}%
Scott, Finlay, and Iago Mosqueira. 2016. {``Bioeconomic Modelling for Fisheries.''} EUR 28383 EN. European Union. \url{https://doi.org/10.2788/722156}.

\leavevmode\vadjust pre{\hypertarget{ref-sklar1959}{}}%
Sklar, M. 1959. {``Fonctions de r{Ã©}partition {Ã } n Dimensions Et Leurs Marges.''} In \emph{Annales de l'ISUP}, 8:229--31. 3.

\leavevmode\vadjust pre{\hypertarget{ref-unclos1982}{}}%
United Nations. 1982. {``United Nations Convention on the Law of the Sea.''} \url{https://www.un.org/depts/los/convention_agreements/texts/unclos/unclos_e.pdf}.

\leavevmode\vadjust pre{\hypertarget{ref-mass}{}}%
Venables, W. N., and B. D. Ripley. 2002. \emph{Modern Applied Statistics with s}. Fourth. New York: Springer. \url{https://www.stats.ox.ac.uk/pub/MASS4/}.

\leavevmode\vadjust pre{\hypertarget{ref-wang2004asymptotic}{}}%
Wang, Xiaogang, Constance van Eeden, and James V Zidek. 2004. {``Asymptotic Properties of Maximum Weighted Likelihood Estimators.''} \emph{Journal of Statistical Planning and Inference} 119 (1): 37--54.

\leavevmode\vadjust pre{\hypertarget{ref-Wood2017}{}}%
Wood, S. N. 2017. \emph{Generalized Additive Models: An Introduction with r}. 2nd ed. Chapman; Hall/CRC.

\leavevmode\vadjust pre{\hypertarget{ref-R-mgcv}{}}%
Wood, S. N. 2011. {``Fast Stable Restricted Maximum Likelihood and Marginal Likelihood Estimation of Semiparametric Generalized Linear Models.''} \emph{Journal of the Royal Statistical Society (B)} 73 (1): 3--36. \url{https://doi.org/10.1111/j.1467-9868.2010.00749.x}.

\end{CSLReferences}

\end{document}
